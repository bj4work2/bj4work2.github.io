<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>

<style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
h1, h2, h3, h4, h5 { white-space: pre-wrap; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
thead, tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
svg { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; border-color: transparent !important; padding-top: 0px !important; padding-bottom: 0px !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  #write > p:nth-child(1) { margin-top: 0px; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
  figure { overflow-x: visible; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.reversefootnote { font-family: ui-monospace, sans-serif; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.6; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex:2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; overflow-wrap: anywhere; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }
mjx-container { break-inside: avoid; }


.CodeMirror { height: auto; }
.CodeMirror.cm-s-inner { background: inherit; }
.CodeMirror-scroll { overflow: auto hidden; z-index: 3; }
.CodeMirror-gutter-filler, .CodeMirror-scrollbar-filler { background-color: rgb(255, 255, 255); }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); background: inherit; white-space: nowrap; }
.CodeMirror-linenumber { padding: 0px 3px 0px 5px; text-align: right; color: rgb(153, 153, 153); }
.cm-s-inner .cm-keyword { color: rgb(119, 0, 136); }
.cm-s-inner .cm-atom, .cm-s-inner.cm-atom { color: rgb(34, 17, 153); }
.cm-s-inner .cm-number { color: rgb(17, 102, 68); }
.cm-s-inner .cm-def { color: rgb(0, 0, 255); }
.cm-s-inner .cm-variable { color: rgb(0, 0, 0); }
.cm-s-inner .cm-variable-2 { color: rgb(0, 85, 170); }
.cm-s-inner .cm-variable-3 { color: rgb(0, 136, 85); }
.cm-s-inner .cm-string { color: rgb(170, 17, 17); }
.cm-s-inner .cm-property { color: rgb(0, 0, 0); }
.cm-s-inner .cm-operator { color: rgb(152, 26, 26); }
.cm-s-inner .cm-comment, .cm-s-inner.cm-comment { color: rgb(170, 85, 0); }
.cm-s-inner .cm-string-2 { color: rgb(255, 85, 0); }
.cm-s-inner .cm-meta { color: rgb(85, 85, 85); }
.cm-s-inner .cm-qualifier { color: rgb(85, 85, 85); }
.cm-s-inner .cm-builtin { color: rgb(51, 0, 170); }
.cm-s-inner .cm-bracket { color: rgb(153, 153, 119); }
.cm-s-inner .cm-tag { color: rgb(17, 119, 0); }
.cm-s-inner .cm-attribute { color: rgb(0, 0, 204); }
.cm-s-inner .cm-header, .cm-s-inner.cm-header { color: rgb(0, 0, 255); }
.cm-s-inner .cm-quote, .cm-s-inner.cm-quote { color: rgb(0, 153, 0); }
.cm-s-inner .cm-hr, .cm-s-inner.cm-hr { color: rgb(153, 153, 153); }
.cm-s-inner .cm-link, .cm-s-inner.cm-link { color: rgb(0, 0, 204); }
.cm-negative { color: rgb(221, 68, 68); }
.cm-positive { color: rgb(34, 153, 34); }
.cm-header, .cm-strong { font-weight: 700; }
.cm-del { text-decoration: line-through; }
.cm-em { font-style: italic; }
.cm-link { text-decoration: underline; }
.cm-error { color: red; }
.cm-invalidchar { color: red; }
.cm-constant { color: rgb(38, 139, 210); }
.cm-defined { color: rgb(181, 137, 0); }
div.CodeMirror span.CodeMirror-matchingbracket { color: rgb(0, 255, 0); }
div.CodeMirror span.CodeMirror-nonmatchingbracket { color: rgb(255, 34, 34); }
.cm-s-inner .CodeMirror-activeline-background { background: inherit; }
.CodeMirror { position: relative; overflow: hidden; }
.CodeMirror-scroll { height: 100%; outline: 0px; position: relative; box-sizing: content-box; background: inherit; }
.CodeMirror-sizer { position: relative; }
.CodeMirror-gutter-filler, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-vscrollbar { position: absolute; z-index: 6; display: none; outline: 0px; }
.CodeMirror-vscrollbar { right: 0px; top: 0px; overflow: hidden; }
.CodeMirror-hscrollbar { bottom: 0px; left: 0px; overflow: auto hidden; }
.CodeMirror-scrollbar-filler { right: 0px; bottom: 0px; }
.CodeMirror-gutter-filler { left: 0px; bottom: 0px; }
.CodeMirror-gutters { position: absolute; left: 0px; top: 0px; padding-bottom: 10px; z-index: 3; overflow-y: hidden; }
.CodeMirror-gutter { white-space: normal; height: 100%; box-sizing: content-box; padding-bottom: 30px; margin-bottom: -32px; display: inline-block; }
.CodeMirror-gutter-wrapper { position: absolute; z-index: 4; background: 0px 0px !important; border: none !important; }
.CodeMirror-gutter-background { position: absolute; top: 0px; bottom: 0px; z-index: 4; }
.CodeMirror-gutter-elt { position: absolute; cursor: default; z-index: 4; }
.CodeMirror-lines { cursor: text; }
.CodeMirror pre { border-radius: 0px; border-width: 0px; background: 0px 0px; font-family: inherit; font-size: inherit; margin: 0px; white-space: pre; overflow-wrap: normal; color: inherit; z-index: 2; position: relative; overflow: visible; }
.CodeMirror-wrap pre { overflow-wrap: break-word; white-space: pre-wrap; word-break: normal; }
.CodeMirror-code pre { border-right: 30px solid transparent; width: fit-content; }
.CodeMirror-wrap .CodeMirror-code pre { border-right: none; width: auto; }
.CodeMirror-linebackground { position: absolute; inset: 0px; z-index: 0; }
.CodeMirror-linewidget { position: relative; z-index: 2; overflow: auto; }
.CodeMirror-wrap .CodeMirror-scroll { overflow-x: hidden; }
.CodeMirror-measure { position: absolute; width: 100%; height: 0px; overflow: hidden; visibility: hidden; }
.CodeMirror-measure pre { position: static; }
.CodeMirror div.CodeMirror-cursor { position: absolute; visibility: hidden; border-right: none; width: 0px; }
.CodeMirror div.CodeMirror-cursor { visibility: hidden; }
.CodeMirror-focused div.CodeMirror-cursor { visibility: inherit; }
.cm-searching { background: rgba(255, 255, 0, 0.4); }
span.cm-underlined { text-decoration: underline; }
span.cm-strikethrough { text-decoration: line-through; }
.cm-tw-syntaxerror { color: rgb(255, 255, 255); background-color: rgb(153, 0, 0); }
.cm-tw-deleted { text-decoration: line-through; }
.cm-tw-header5 { font-weight: 700; }
.cm-tw-listitem:first-child { padding-left: 10px; }
.cm-tw-box { border-style: solid; border-right-width: 1px; border-bottom-width: 1px; border-left-width: 1px; border-color: inherit; border-top-width: 0px !important; }
.cm-tw-underline { text-decoration: underline; }
@media print {
  .CodeMirror div.CodeMirror-cursor { visibility: hidden; }
}


/*!
 * typora-themeable
 * v1.0.4
 * https://github.com/jhildenbiddle/typora-themeable
 * (c) 2022-2023 John Hildenbiddle <http://hildenbiddle.com>
 * MIT license
 */
:root{
    --red-50:#fef2f2;
    --red-100:#fee2e2;
    --red-200:#fecaca;
    --red-300:#fca5a5;
    --red-400:#f87171;
    --red-500:#ef4444;
    --red-600:#dc2626;
    --red-700:#b91c1c;
    --red-800:#991b1b;
    --red-900:#7f1d1d;

    --orange-50:#fff7ed;
    --orange-100:#ffedd5;
    --orange-200:#fed7aa;
    --orange-300:#fdba74;
    --orange-400:#fb923c;
    --orange-500:#f97316;
    --orange-600:#ea580c;
    --orange-700:#c2410c;
    --orange-800:#9a3412;
    --orange-900:#7c2d12;

    --amber-50:#fffbeb;
    --amber-100:#fef3c7;
    --amber-200:#fde68a;
    --amber-300:#fcd34d;
    --amber-400:#fbbf24;
    --amber-500:#f59e0b;
    --amber-600:#d97706;
    --amber-700:#b45309;
    --amber-800:#92400e;
    --amber-900:#78350f;

    --yellow-50:#fefce8;
    --yellow-100:#fef9c3;
    --yellow-200:#fef08a;
    --yellow-300:#fde047;
    --yellow-400:#facc15;
    --yellow-500:#eab308;
    --yellow-600:#ca8a04;
    --yellow-700:#a16207;
    --yellow-800:#854d0e;
    --yellow-900:#713f12;

    --lime-50:#f7fee7;
    --lime-100:#ecfccb;
    --lime-200:#d9f99d;
    --lime-300:#bef264;
    --lime-400:#a3e635;
    --lime-500:#84cc16;
    --lime-600:#65a30d;
    --lime-700:#4d7c0f;
    --lime-800:#3f6212;
    --lime-900:#365314;

    --green-50:#f0fdf4;
    --green-100:#dcfce7;
    --green-200:#bbf7d0;
    --green-300:#86efac;
    --green-400:#4ade80;
    --green-500:#22c55e;
    --green-600:#16a34a;
    --green-700:#15803d;
    --green-800:#166534;
    --green-900:#14532d;

    --emerald-50:#ecfdf5;
    --emerald-100:#d1fae5;
    --emerald-200:#a7f3d0;
    --emerald-300:#6ee7b7;
    --emerald-400:#34d399;
    --emerald-500:#10b981;
    --emerald-600:#059669;
    --emerald-700:#047857;
    --emerald-800:#065f46;
    --emerald-900:#064e3b;

    --teal-50:#f0fdfa;
    --teal-100:#ccfbf1;
    --teal-200:#99f6e4;
    --teal-300:#5eead4;
    --teal-400:#2dd4bf;
    --teal-500:#14b8a6;
    --teal-600:#0d9488;
    --teal-700:#0f766e;
    --teal-800:#115e59;
    --teal-900:#134e4a;

    --cyan-50:#ecfeff;
    --cyan-100:#cffafe;
    --cyan-200:#a5f3fc;
    --cyan-300:#67e8f9;
    --cyan-400:#22d3ee;
    --cyan-500:#06b6d4;
    --cyan-600:#0891b2;
    --cyan-700:#0e7490;
    --cyan-800:#155e75;
    --cyan-900:#164e63;

    --sky-50:#f0f9ff;
    --sky-100:#e0f2fe;
    --sky-200:#bae6fd;
    --sky-300:#7dd3fc;
    --sky-400:#38bdf8;
    --sky-500:#0ea5e9;
    --sky-600:#0284c7;
    --sky-700:#0369a1;
    --sky-800:#075985;
    --sky-900:#0c4a6e;

    --blue-50:#eff6ff;
    --blue-100:#dbeafe;
    --blue-200:#bfdbfe;
    --blue-300:#93c5fd;
    --blue-400:#60a5fa;
    --blue-500:#3b82f6;
    --blue-600:#2563eb;
    --blue-700:#1d4ed8;
    --blue-800:#1e40af;
    --blue-900:#1e3a8a;

    --indigo-50:#eef2ff;
    --indigo-100:#e0e7ff;
    --indigo-200:#c7d2fe;
    --indigo-300:#a5b4fc;
    --indigo-400:#818cf8;
    --indigo-500:#6366f1;
    --indigo-600:#4f46e5;
    --indigo-700:#4338ca;
    --indigo-800:#3730a3;
    --indigo-900:#312e81;

    --violet-50:#f5f3ff;
    --violet-100:#ede9fe;
    --violet-200:#ddd6fe;
    --violet-300:#c4b5fd;
    --violet-400:#a78bfa;
    --violet-500:#8b5cf6;
    --violet-600:#7c3aed;
    --violet-700:#6d28d9;
    --violet-800:#5b21b6;
    --violet-900:#4c1d95;

    --purple-50:#faf5ff;
    --purple-100:#f3e8ff;
    --purple-200:#e9d5ff;
    --purple-300:#d8b4fe;
    --purple-400:#c084fc;
    --purple-500:#a855f7;
    --purple-600:#9333ea;
    --purple-700:#7e22ce;
    --purple-800:#6b21a8;
    --purple-900:#581c87;

    --fuchsia-50:#fdf4ff;
    --fuchsia-100:#fae8ff;
    --fuchsia-200:#f5d0fe;
    --fuchsia-300:#f0abfc;
    --fuchsia-400:#e879f9;
    --fuchsia-500:#d946ef;
    --fuchsia-600:#c026d3;
    --fuchsia-700:#a21caf;
    --fuchsia-800:#86198f;
    --fuchsia-900:#701a75;

    --pink-50:#fdf2f8;
    --pink-100:#fce7f3;
    --pink-200:#fbcfe8;
    --pink-300:#f9a8d4;
    --pink-400:#f472b6;
    --pink-500:#ec4899;
    --pink-600:#db2777;
    --pink-700:#be185d;
    --pink-800:#9d174d;
    --pink-900:#831843;

    --rose-50:#fff1f2;
    --rose-100:#ffe4e6;
    --rose-200:#fecdd3;
    --rose-300:#fda4af;
    --rose-400:#fb7185;
    --rose-500:#f43f5e;
    --rose-600:#e11d48;
    --rose-700:#be123c;
    --rose-800:#9f1239;
    --rose-900:#881337;
    --slate-50:#f8fafc;
    --slate-100:#f1f5f9;
    --slate-200:#e2e8f0;
    --slate-300:#cbd5e1;
    --slate-400:#94a3b8;
    --slate-500:#64748b;
    --slate-600:#475569;
    --slate-700:#334155;
    --slate-800:#1e293b;
    --slate-900:#0f172a;

    --gray-50:#f9fafb;
    --gray-100:#f3f4f6;
    --gray-200:#e5e7eb;
    --gray-300:#d1d5db;
    --gray-400:#9ca3af;
    --gray-500:#6b7280;
    --gray-600:#4b5563;
    --gray-700:#374151;
    --gray-800:#1f2937;
    --gray-900:#111827;

    --zinc-50:#fafafa;
    --zinc-100:#f4f4f5;
    --zinc-200:#e4e4e7;
    --zinc-300:#d4d4d8;
    --zinc-400:#a1a1aa;
    --zinc-500:#71717a;
    --zinc-600:#52525b;
    --zinc-700:#3f3f46;
    --zinc-800:#27272a;
    --zinc-900:#18181b;

    --neutral-50:#fafafa;
    --neutral-100:#f5f5f5;
    --neutral-200:#e5e5e5;
    --neutral-300:#d4d4d4;
    --neutral-400:#a3a3a3;
    --neutral-500:#737373;
    --neutral-600:#525252;
    --neutral-700:#404040;
    --neutral-800:#262626;
    --neutral-900:#171717;

    --stone-50:#fafaf9;
    --stone-100:#f5f5f4;
    --stone-200:#e7e5e4;
    --stone-300:#d6d3d1;
    --stone-400:#a8a29e;
    --stone-500:#78716c;
    --stone-600:#57534e;
    --stone-700:#44403c;
    --stone-800:#292524;
    --stone-900:#1c1917;
}
:root{
    --color-primary:var(--sky-600);
    --color-secondary:var(--violet-500);
    --marked-background:var(--yellow-300);
    --search-match-background:var(--pink-100);
    --search-match-border-color:var(--pink-500);
    --selection-background:var(--sky-100);
    --mono-50:var(--neutral-50);
    --mono-100:var(--neutral-100);
    --mono-200:var(--neutral-200);
    --mono-300:var(--neutral-300);
    --mono-400:var(--neutral-400);
    --mono-500:var(--neutral-500);
    --mono-600:var(--neutral-600);
    --mono-700:var(--neutral-700);
    --mono-800:var(--neutral-800);
    --mono-900:var(--neutral-900);
    --font-family:"Inter var", "Inter", system, -apple-system, ".SFNSText-Regular", "San Francisco", "Segoe UI", Roboto, Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
    --font-family-mono:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    --font-size:16px;
    --font-size-mono:15px;
    --font-size-ui:14px;
    --font-weight:400;
    --font-weight-mono:500;
}
:root{
    --color-hover:var(--mono-200);
    --color-hover-content:inherit;
    --color-primary-content:#fff;
    --color-status:var(--mono-500);
    --color-status-content:#fff;
    --font-family-diagram:var(--font-family);
    --font-family-ui:var(--font-family);
    --font-size-xxl:calc(var(--font-size-xl) * var(--modular-scale));
    --font-size-xl:calc(var(--font-size-l) * var(--modular-scale));
    --font-size-l:calc(1rem * var(--modular-scale));
    --font-size-m:1rem;
    --font-size-s:max(0.75rem, calc(1rem / var(--modular-scale)));
    --font-size-xs:max(0.6875rem, calc(var(--font-size-s) / var(--modular-scale)));
    --font-size-ui-xl:calc(var(--font-size-ui-l) * var(--modular-scale));
    --font-size-ui-l:calc(var(--font-size-ui) * var(--modular-scale));
    --font-size-ui-s:max(12px, calc(var(--font-size-ui) * 0.857));
    --line-height:1.6;
    --modular-scale:1.414;
    --background-color:var(--mono-50);
    --border-color:var(--mono-200);
    --border-radius:6px;
    --border-radius-s:3px;
    --border-radius-xs:1px;
    --btn-toggle-active-background:;
    --btn-toggle-active-color:var(--color-primary);
    --btn-toggle-background:;
    --btn-toggle-color:var(--mono-400);
    --btn-toggle-hover-background:var(--color-hover);
    --btn-toggle-hover-color:var(--color-hover-content);
    --drop-shadow:drop-shadow(0 3px 5px rgba(0, 0, 0, 0.15));
    --input-background:#fff;
    --input-border-color:var(--border-color);
    --input-focus-color:var(--color-primary);
    --input-color:var(--text-color);
    --input-placeholder-color:var(--mono-400);
    --kbd-background:var(--mono-600);
    --kbd-border-color:transparent;
    --kbd-color:#fff;
    --max-width:75ch;
    --md-brackets:var(--mono-400);
    --md-brackets-expanded:var(--color-secondary);
    --md-tags:var(--md-brackets);
    --md-tags-expanded:var(--md-brackets-expanded);
    --menu-background:#fff;
    --menu-border-width:0;
    --menu-color:inherit;
    --search-match-color:var(--text-color);
    --selection-color:;
    --sidebar-active-background:var(--color-hover);
    --sidebar-active-color:var(--color-hover-content);
    --sidebar-background:var(--mono-100);
    --sidebar-border-color:var(--mono-200);
    --sidebar-border-width:1px;
    --sidebar-color:var(--mono-700);
    --sidebar-hover-background:var(--color-hover);
    --sidebar-hover-color:var(--color-hover-content);
    --text-color:var(--mono-700);
    --blockquote-background:var(--mono-100);
    --blockquote-border-color:var(--color-primary);
    --blockquote-border-width:0 0 0 4px;
    --blockquote-color:inherit;
    --blockquote-padding:1rem 1.5rem 1rem 1.5rem;
    --code-inline-background:var(--mono-200);
    --code-inline-color:var(--strong-color);
    --code-padding-tb:1.5em;
    --code-padding-lr:1.5em;
    --checkbox-background:var(--mono-100);
    --checkbox-border-color:var(--mono-300);
    --checkbox-border-radius:var(--border-radius-s);
    --checkbox-check-color:var(--color-primary-content);
    --checkbox-size:1.2rem;
    --counter-color:inherit;
    --h1-font-size:var(--font-size-xxl);
    --h1-letter-spacing:-0.03em;
    --h2-font-size:var(--font-size-xl);
    --h2-letter-spacing:-0.02em;
    --h3-font-size:var(--font-size-l);
    --h3-letter-spacing:-0.01em;
    --h4-font-size:var(--font-size-m);
    --h5-font-size:var(--font-size-m);
    --h6-font-size:var(--font-size-s);
    --heading-color:var(--mono-800);
    --heading-font-weight:800;
    --hr-color:var(--mono-300);
    --hr-height:2px;
    --link-color:var(--color-primary);
    --marked-color:inherit;
    --marker-color:inherit;
    --strong-color:var(--mono-800);
    --strong-font-weight:600;
    --table-edit-active-background:var(--mono-500);
    --table-edit-active-color:var(--mono-50);
    --table-edit-background:var(--mono-200);
    --table-edit-color:var(--mono-600);
    --table-edit-hover-background:var(--mono-300);
    --table-edit-hover-color:var(--table-edit-color);
    --tbody-border-color:unset;
    --tbody-border-width:unset;
    --td-border-color:unset;
    --td-border-width:unset;
    --td-padding:0.5rem 0.75rem;
    --th-border-color:unset;
    --th-border-width:unset;
    --th-color:var(--strong-color);
    --th-font-weight:var(--strong-font-weight);
    --th-padding:0 0.75rem 0.5rem 0.75rem;
    --thead-border-color:var(--mono-300);
    --thead-border-width:0 0 2px 0;
    --tr-alt-background:var(--mono-100);
    --tr-border-color:var(--mono-200);
    --tr-border-width:0 0 1px 0;
    --code-activeline-background:var(--mono-200);
    --code-atom-color:var(--amber-600);
    --code-attribute-color:var(--sky-600);
    --code-background:var(--mono-100);
    --code-bracket-color:var(--mono-400);
    --code-builtin-color:var(--emerald-600);
    --code-comment-color:var(--mono-400);
    --code-cursor-border:2px solid var(--color-primary);
    --code-def-color:var(--violet-600);
    --code-error-color:var(--red-600);
    --code-gutter-border-color:var(--mono-200);
    --code-keyword-color:var(--sky-600);
    --code-language-background:var(--code-activeline-background);
    --code-language-color:var(--code-text-color);
    --code-linenumber-color:var(--mono-400);
    --code-link-color:;
    --code-meta-color:var(--rose-600);
    --code-number-color:;
    --code-operator-color:var(--rose-600);
    --code-property-color:var(--sky-600);
    --code-qualifier-color:var(--emerald-600);
    --code-selected-background:var(--selection-background);
    --code-string-color:;
    --code-string-2-color:;
    --code-tag-color:var(--violet-600);
    --code-text-color:var(--mono-700);
    --code-type-color:var(--rose-600);
    --code-variable-color:var(--cyan-600);
    --code-variable-2-color:var(--cyan-600);
    --code-variable-3-color:var(--emerald-600);
    --mermaid-theme:neutral;
    --mermaid-font-family:;
    --mermaid-flowchart-curve:basis;
    --mermaid-sequence-numbers:off;
    --mermaid--gantt-left-padding:75;
    --sequence-theme:simple;
}
@media print{
    :root{
        --background-color:#fff;
    }
}
:root{
    --active-file-bg-color:var(--sidebar-active-background);
    --active-file-text-color:var(--sidebar-active-color);
    --bg-color:var(--background-color);
    --control-text-color:var(--sidebar-color);
    --control-text-hover-color:var(--sidebar-hover-color);
    --item-hover-bg-color:var(--color-hover);
    --item-hover-text-color:var(--color-hover-content);
    --md-char-color:var(--md-brackets-expanded);
    --meta-content-color:inherit;
    --monospace:var(--font-family-mono);
    --search-select-bg-color:var(--search-match-background);
    --search-select-text-color:var(--search-match-color);
    --select-text-bg-color:var(--selection-background);
    --window-border:1px solid var(--border-color);
}
*,
::before,
::after{
    box-sizing:border-box;
    border:0;
    border-style:solid;
    border-color:currentColor;
}
html,
body{
    margin:0;
    line-height:var(--line-height);
}
html{
    accent-color:var(--color-primary);
    font-family:var(--font-family-ui);
    font-size:var(--font-size);
    font-weight:var(--font-weight);
}
a,
a code{
    color:var(--link-color);
}
a{
    text-decoration:underline;
}
b,
strong{
    color:var(--strong-color);
    font-weight:var(--strong-font-weight);
}
blockquote{
    margin:1.5rem 0;
    padding:var(--blockquote-padding);
    border-width:var(--blockquote-border-width);
    border-color:var(--blockquote-border-color);
    background:var(--blockquote-background);
    color:var(--blockquote-color);
}
code,
kbd,
samp,
pre{
    font-family:var(--font-family-mono);
    font-size:var(--font-size-mono);
}
kbd{
    padding:.2em .75em .3em .75em;
    border-color:var(--kbd-border-color);
    border-radius:var(--border-radius);
    background:var(--kbd-background);
    color:var(--kbd-color);
    box-shadow:none;
}
code,
pre{
    font-size:var(--font-size-mono);
    font-weight:var(--font-weight-mono);
}
hr{
    border-color:var(--hr-color);
    border-top-width:var(--hr-height);
}
input::placeholder,
textarea::placeholder{
    color:var(--input-placeholder-color) !important;
}
mark{
    border-radius:var(--border-radius-xs);
    box-shadow:0 0 0 1px var(--marked-background);
    background:var(--marked-background);
    color:var(--marked-color);
}
p{
    margin-top:1em;
    margin-bottom:1em;
}
small{
    font-size:var(--font-size-s);
}
sub,
sup{
    font-size:var(--font-size-s);
}
body:not([class*="seamless"]) :is(#typora-sidebar, content){
    border-top:1px solid var(--border-color);
}
.blink-area{
  -webkit-animation:none;
          animation:none;
}
.btn-primary,
.btn-primary:hover{
    background:var(--color-primary);
    color:var(--color-primary-content);
}
.btn-primary:hover{
    filter:contrast(1.2);
}
.context-menu,
.dropdown-menu,
:is(.context-menu, .dropdown-menu) > li > a{
    color:var(--menu-color);
}
.context-menu,
.dropdown-menu{
    border:var(--menu-border-width) solid var(--border-color);
    background:var(--menu-background);
    font-size:var(--font-size-ui);
}
:is(.context-menu, .dropdown-menu) .ty-menu-shortcut{
    font-family:var(--font-family-ui);
}
.context-menu .divider{
    border-top:1px solid var(--border-color);
    opacity:1;
}
.form-control:focus{
    -webkit-box-shadow:none;
            box-shadow:none;
}
.code-tooltip-content *{
    color:unset;
}
#ty-auto-suggest{
    border-radius:var(--border-radius);
    font-size:var(--font-size-s);
    box-shadow:none;
    filter:var(--drop-shadow);
}
.md-search-hit,
.md-search-hit.md-search-select,
.md-search-select,
body :is(#write, #typora-source) .cm-search-hit,
.ty-file-search-match-text,
.ty-outline-hit[class]{
    background-color:unset !important;
    background:var(--search-match-background) !important;
    color:var(--search-match-color) !important;
}
.md-search-hit,
.md-search-hit.md-search-select,
.md-search-select,
body :is(#write, #typora-source) .cm-search-hit{
    border-radius:var(--border-radius-xs);
    box-shadow:0 0 0 2px var(--search-match-border-color);
}
.ty-file-search-match-text,
.ty-outline-hit[class]{
    padding-right:1px;
    padding-left:1px;
    border:2px solid var(--search-match-border-color);
    border-radius:var(--border-radius-s);
    font-weight:var(--font-weight);
}
#write{
    max-width:var(--max-width);
    color:var(--text-color);
    font-family:var(--font-family);
}
#write > :first-child{
    margin-top:0;
}
#write > :last-child{
    margin-bottom:0;
}
footer.ty-footer{
    border-color:var(--mono-200);
}
.typora-sourceview-on #toggle-sourceview-btn{
    background:none;
    opacity:1;
}
.footer-item:hover,
.typora-sourceview-on #toggle-sourceview-btn:hover{
    background:var(--sidebar-hover-background);
    color:var(--sidebar-hover-color);
}
#typora-quick-open{
    top:calc(var(--title-bar-height) + 5px);
    padding:0;
    border:var(--sidebar-border-width) solid var(--sidebar-border-color);
    border-radius:var(--border-radius);
    background:var(--sidebar-background);
    color:var(--sidebar-color);
    box-shadow:none;
    filter:var(--drop-shadow);
}
#typora-quick-open-input,
.typora-quick-open-list{
    padding:0.5em;
}
#typora-quick-open-input input{
    max-height:unset;
    overflow:unset;
    border-color:var(--input-border-color);
    border-radius:var(--border-radius-s);
    background:var(--input-background);
    color:var(--input-color);
    font-size:var(--font-size-ui);
    line-height:2;
}
#typora-quick-open-input input:focus{
    border-color:var(--input-focus-color);
}
.ty-quick-open-category-title,
.typora-quick-open-item-path{
    opacity:0.7;
}
.ty-quick-open-category-title{
    margin-top:0.5rem;
    margin-bottom:0.15rem;
    font-size:0.9em;
    height:auto;
    line-height:var(--line-height);
    text-transform:uppercase;
    letter-spacing:0.5px;
    font-weight:600;
}
.ty-quick-open-category.ty-has-prev .ty-quick-open-category-title{
    margin-top:0.5rem;
    padding-top:0.5rem;
}
.typora-quick-open-item,
.typora-quick-open-item-path{
    max-height:auto;
    line-height:var(--line-height);
}
.typora-quick-open-item{
    height:auto;
    padding-top:0.25em;
    padding-bottom:0.25em;
    font-size:var(--font-size-ui);
    cursor:pointer;
}
.typora-quick-open-item.active{
    border-radius:var(--border-radius-s);
}
.typora-quick-open-item-path{
    font-size:var(--font-size-ui-s);
}
.typora-quick-open-item-title{
    margin-bottom:0.25em;
    line-height:var(--line-height);
}
.typora-quick-open-item-title b{
    border-radius:var(--border-radius-xs);
    box-shadow:0 0 0 1px var(--marked-background);
    background:var(--marked-background);
    color:var(--marked-color);
}
.mac-seamless-mode #md-searchpanel{
    max-height:63px;
}
#md-searchpanel{
    border-bottom:1px solid var(--sidebar-border-color);
    background:var(--sidebar-background);
    color:var(--sidebar-color);
    box-shadow:none;
    filter:var(--drop-shadow);
}
#md-searchpanel input,
#md-searchpanel .btn,
#searchpanel-msg{
    border-radius:var(--border-radius-s);
    font-size:var(--font-size-ui-s);
}
#md-searchpanel input{
    background:var(--input-background);
    border-color:var(--input-border-color);
    color:var(--input-color);
}
#md-searchpanel input:focus,
#md-searchpanel input:not(:placeholder-shown){
    border-color:var(--input-focus-color);
}
#md-searchpanel .btn:not(.close-btn):hover{
    box-shadow:none;
}
.searchpanel-search-option-btn,
.searchpanel-search-option-btn:hover,
.searchpanel-search-option-btn.active{
    opacity:1;
}
.searchpanel-search-option-btn{
    top:4px;
    padding:3px 2px;
    border:0;
    background:var(--btn-toggle-background);
    color:var(--btn-toggle-color);
}
.searchpanel-search-option-btn:hover{
    background:var(--btn-toggle-hover-background);
    color:var(--btn-toggle-hover-color);
}
.searchpanel-search-option-btn.active{
    background:var(--btn-toggle-active-background);
    color:var(--btn-toggle-active-color);
}
#search-panel-status .error-message{
    padding:0.25em 0.5em;
    border-radius:var(--border-radius-s);
    background:var(--color-status);
    color:var(--color-status-content);
}
#typora-sidebar{
    border-top:none !important;
    border-right:var(--sidebar-border-width) solid var(--sidebar-border-color);
    background:var(--sidebar-background);
    color:var(--sidebar-color);
}
#typora-sidebar,
#sidebar-files-menu.dropdown-menu > li,
.sidebar-content-content,
.ty-search-item-line{
    font-size:var(--font-size-ui);
}
#typora-sidebar input{
    border-radius:var(--border-radius-s);
    background:var(--input-background);
    color:var(--input-color);
}
.file-list-item-time,
.file-list-item-parent-loc,
.file-list-item-summary,
.ty-search-item-line{
    font-family:var(--font-family-ui);
}
.ty-search-item-line:hover{
    background-color:var(--sidebar-hover-background);
    color:var(--sidebar-hover-color);
}
.outline-item-active::after,
.active .file-list-item-file-name::after,
.active .file-node-content::after{
    content:"";
    position:absolute;
    top:calc(50% - 4px);
    right:0;
    width:8px;
    height:8px;
    border-radius:50%;
    background:var(--color-primary);
}
.info-panel-tab-border{
    border-radius:100vw;
}
.active-tab-files #info-panel-tab-file,
.active-tab-files #info-panel-tab-file:hover,
.active-tab-outline #info-panel-tab-outline,
.active-tab-outline #info-panel-tab-outline:hover,
.ty-show-search #info-panel-tab-search{
    font-weight:var(--strong-font-weight);
    color:var(--strong-color);
}
.active-tab-files #info-panel-tab-file .info-panel-tab-border,
.active-tab-outline #info-panel-tab-outline .info-panel-tab-border,
.ty-show-search #info-panel-tab-search .info-panel-tab-border{
    height:3px;
    background-color:var(--color-primary);
}
.sidebar-tabs{
    border-bottom:var(--sidebar-border-width) solid var(--sidebar-border-color);
}
.sidebar-tab{
    font-weight:var(--strong-font-weight);
    text-transform:none;
}
#outline-content{
    line-height:var(--line-height);
}
.outline-content{
    padding-top:0;
}
.pin-outline #outline-content .outline-active strong,
.pin-outline .outline-active{
    font-weight:var(--strong-font-weight);
}
.pin-outline .outline-active{
    font-weight:var(--font-weight);
}
.outline-item,
.no-collapse-outline .outline-item{
    margin:1px 0;
}
.outline-item{
    display:flex;
    align-items:center;
    position:relative;
    padding-top:0.4em;
    padding-bottom:0.4em;
}
.outline-item::before{
    content:"";
    position:absolute;
    top:0;
    bottom:0;
    right:-100px;
    left:-100px;
}
.outline-item:hover{
    margin-right:0;
    margin-left:0;
    border-right:0;
    border-left:0;
    background:none;
    color:var(--sidebar-hover-color);
}
.outline-item:hover::before{
    background:var(--sidebar-hover-background);
}
.outline-item > *{
    position:relative;
}
.outline-expander,
.outline-expander::before{
    --icon-width:10px;

    width:calc(var(--icon-width) * 2);
    padding:0;
    font-size:var(--icon-width);
    line-height:var(--icon-width);
}
.outline-expander{
    display:unset;
    height:auto;
    text-align:center;
}
.outline-label{
    width:100%;
    display:inline-block;
    overflow:hidden;
    white-space:nowrap;
    text-overflow:ellipsis;
}
.outline-label:hover{
    text-decoration:none;
}
.outline-item-active{
    position:relative;
    padding-right:8px;
    color:var(--sidebar-active-color);
}
.outline-item-active::before{
    background:var(--sidebar-active-background);
}
.outline-item-active .outline-label{
    padding-right:10px;
}
.file-node-icon.fa-folder::before{
    content:"\f114";
}
.file-node-open-state{
    margin-top:-2px;
    margin-right:3px;
    margin-left:-2px;
}
.file-node-collapsed .fa-caret-right::before{
    content:"\f125";
    font-family:Ionicons;
    font-size:10px;
}
.file-node-expanded .fa-caret-down::before{
    content:"\f123";
    font-family:Ionicons;
    font-size:10px;
}
.file-list-item-file-ext-part,
.file-list-item-parent-loc,
.file-list-item-summary,
.file-list-item-time{
    opacity:0.8;
}
.file-list-item-parent-loc,
.file-list-item-time{
    margin-bottom:3px;
    font-size:var(--font-size-ui-s);
}
.file-list-item{
    border-bottom:var(--sidebar-border-width) solid var(--sidebar-border-color);
}
.file-list-item:hover{
    background-color:var(--sidebar-hover-background);
    color:var(--sidebar-hover-color);
}
.file-list-item:not(.active){
    opacity:1;
}
.file-list-item.active{
    background:var(--sidebar-active-background);
    color:var(--sidebar-active-color);
}
.file-list-item-file-name{
    position:relative;
    margin-bottom:4px;
}
.active .file-list-item-file-name{
    padding-right:20px;
}
.file-list-item-file-name-part{
    font-weight:var(--strong-font-weight);
    color:var(--strong-color);
}
.active .file-list-item-file-name::after{
    right:8px;
}
.file-list-item-summary{
    height:auto;
    max-height:calc(3 * 0.95em * var(--line-height));
    line-height:inherit;
    font-size:var(--font-size-ui-s);
}
.file-list-item-time{
    font-size:var(--font-size-ui-s);
}
.file-library-file-node:not(.active):hover{
    color:var(--sidebar-hover-color);
}
.file-library-file-node:not(.active):hover > .file-node-background{
    background:var(--sidebar-hover-background);
}
.file-library-node:not(.file-node-root):focus > .file-node-content{
    outline:unset;
}
.file-node-content{
    padding-right:0;
}
.file-node-content:hover{
    cursor:pointer;
}
.active .file-node-content::after{
    right:14px;
}
.file-node-icon{
    margin-right:5px;
}
.file-node-title{
    width:calc(var(--sidebar-width) - 40px);
    overflow:hidden;
    text-overflow:ellipsis;
}
.file-node-children .file-node-title{
    width:calc(var(--sidebar-width) - 80px);
}
.file-node-children .file-node-children .file-node-title{
    width:calc(var(--sidebar-width) - 88px);
}
.file-node-children .file-node-children .file-node-children .file-node-title{
    width:calc(var(--sidebar-width) - 96px);
}
.allow-file-tree-scroll .file-node-title{
    overflow-x:hidden;
}
.file-tree-node{
    position:relative;
}
.file-tree-node.active > .file-node-background{
    border:0;
}
.file-tree-node.active > .file-node-background{
    background-color:var(--sidebar-active-background);
}
.file-tree-node.active > .file-node-content{
    color:var(--sidebar-active-color);
}
.file-node-background{
    top:0;
    bottom:0;
    right:-4px;
    left:-100px;
    height:auto;
    width:auto;
}
#sidebar-search-btn,
#ty-sidebar-search-back-btn{
    display:flex;
    justify-content:center;
    align-items:center;
    margin:0;
}
#ty-sidebar-search-tabs .searchpanel-search-option-btn{
    top:1em;
    padding:3px 1px;
    background:var(--btn-toggle-background);
    color:var(--btn-toggle-color);
    opacity:1;
}
#ty-sidebar-search-tabs .searchpanel-search-option-btn:hover{
    background:var(--btn-toggle-hover-background);
    color:var(--btn-toggle-hover-color);
}
#ty-sidebar-search-tabs .searchpanel-search-option-btn.select{
    background:var(--btn-toggle-active-background);
    color:var(--btn-toggle-active-color);
}
#filesearch-case-option-btn{
    transform:translateX(-8px);
}
#filesearch-word-option-btn{
    transform:translateX(-4px);
}
.ty-show-outline-filter #file-library-search,
.ty-show-search #file-library-search{
    height:calc(2em + 32px);
}
#file-library-search-input{
    height:auto;
    padding:0.5em 0.75em;
    border:1px solid currentColor;
    border-color:var(--sidebar-border-color);
    border-radius:var(--border-radius-s);
    background:transparent;
    color:inherit;
}
#file-library-search-input:not(:placeholder-shown),
#file-library-search-input:focus{
    border-color:var(--input-focus-color);
    background:var(--input-background);
    color:var(--input-color);
}
.ty-search-item{
    border-bottom:var(--sidebar-border-width) solid var(--sidebar-border-color);
}
.file-list-item-count{
    --size:1.65em;

    height:var(--size);
    min-width:var(--size);
    border-radius:50%;
    background-color:var(--color-status);
    color:var(--color-status-content);
    font-size:var(--font-size-ui-s);
    font-weight:var(--strong-font-weight);
    line-height:var(--size);
    text-align:center;
}
#sidebar-files-menu{
    border-color:var(--border-color);
    background:var(--menu-background);
}
#ty-sidebar-footer{
    border-color:var(--sidebar-border-color);
}
#sidebar-files-menu > .show + .menuitem-group-label.show{
    border-color:var(--border-color);
}
.sidebar-footer-item:hover{
    background:var(--sidebar-hover-background);
    color:var(--sidebar-hover-color);
}
#sidebar-files-menu .folder-menu-item i{
    margin-right:6px;
}
.menuitem-group-label.not-empty-menu-group{
    display:flex !important;
    align-items:center;
    justify-content:space-between;
}
.menuitem-group-label.not-empty-menu-group > .clearfix{
    display:none;
}
#sidebar-files-menu .selected-folder-menu-item a::after{
    content:"";
    position:absolute;
    top:calc(50% - 4px);
    right:8px;
    width:8px;
    height:8px;
    border-radius:50%;
    background:var(--color-primary);
}
#sidebar-files-menu .ty-side-sort-btn{
    --size:24px;

    width:var(--size);
    height:var(--size);
    margin-top:6px;
    margin-bottom:6px;
    border-radius:var(--border-radius-s);
    background:var(--btn-toggle-background);
    color:var(--btn-toggle-color);
    font-size:13px;
    line-height:var(--size);
    opacity:1;
}
#sidebar-files-menu .ty-side-sort-btn:hover{
    background:var(--btn-toggle-hover-background);
    color:var(--btn-toggle-hover-color);
}
#sidebar-files-menu .ty-side-sort-btn.active{
    background:var(--btn-toggle-active-background);
    color:var(--btn-toggle-active-color);
}
#toc-dropmenu{
    right:0;
    border-width:var(--sidebar-border-width) 0 var(--sidebar-border-width) var(--sidebar-border-width);
    border-color:var(--sidebar-border-color);
    border-radius:var(--border-radius) 0 0 var(--border-radius);
    background:var(--sidebar-background);
    color:var(--sidebar-color);
    box-shadow:none;
    filter:var(--drop-shadow);
}
#toc-dropmenu.open{
    animation:toc-in-from-right .3s ease-in;
}
#toc-dropmenu .btn{
    color:inherit;
}
#toc-dropmenu .divider{
    margin:5px 0;
    border-top:var(--sidebar-border-width) solid var(--sidebar-border-color);
    opacity:1;
}
#toc-dropmenu .outline-title-wrapper{
    display:flex;
    justify-content:space-between;
    align-items:center;
}
@keyframes toc-in-from-right{
    0%{
        opacity:0;
        transform:translateX(20%)
    }

    100%{
        opacity:1;
        transform:translateX(0)
    }
}
button.btn .ty-icon{
    font-size:13px;
}
.footnotes{
    opacity:1;
    font-size:var(--font-size-s);
}
.md-p{
    z-index:0;
}
.md-footnote{
    z-index:-1;
}
sup.md-footnote{
    padding:0.1em 0.25em 0.2em 0.25em;
    border-radius:var(--border-radius-s);
    background:var(--code-inline-background);
    color:var(--code-inline-color);
    line-height:1;
}
.md-def-name::before, .md-def-name::after, .md-def-title::before, .md-def-title::after, .md-link .md-meta.md-before, .md-link .md-meta.md-after{
    color:var(--md-brackets);
}
.md-footnote .md-meta.md-before,
.md-link .md-meta.md-before{
    margin-right:0.15em;
}
.md-footnote .md-meta.md-after,
.md-link .md-meta.md-before ~ .md-meta.md-before,
.md-link .md-meta.md-after{
    margin-left:0.15em;
}
.md-def-name{
    font-weight:var(--strong-font-weight);
    color:var(--strong-color);
}
.md-br,
.md-br-content,
.md-comment{
    opacity:1;
    color:var(--md-tags);
}
.md-hr{
    margin:3rem 0;
}
.md-image > .md-meta{
    color:inherit;
    font-family:var(--font-family-ui);
}
.md-image > .md-meta::before, .md-raw-inline:not(.md-br-content){
    opacity:1 !important;
    color:var(--md-tags-expanded);
}
.md-url,
.md-def-url{
    color:var(--link-color);
}
:is(h1, h2, h3, h4, h5, h6){
    margin-top:1.5rem;
    margin-bottom:1rem;
    color:var(--heading-color);
    font-weight:var(--heading-font-weight);
}
:is(h1, h2, h3, h4, h5, h6).md-heading::before{
    all:unset;
    position:absolute;
    top:50%;
    right:calc(100% + 0.5em);
    transform:translate(0, -50%);
    font-size:0.75rem;
    color:var(--md-brackets);
    opacity:0;
    transition:all 0.2s 0s;
}
:is(h1, h2, h3, h4, h5, h6).md-focus::before{
    transform:translate(-0.5em, -50%);
    opacity:1;
}
h1{
    margin-top:3rem;
    font-size:var(--h1-font-size);
    line-height:1.1;
    letter-spacing:var(--h1-letter-spacing);
}
h1.md-heading::before{
    content:'H1';
}
h2{
    margin-top:2rem;
    font-size:var(--h2-font-size);
    line-height:1.2;
    letter-spacing:var(--h2-letter-spacing);
}
h2.md-heading::before{
    content:'H2';
}
h3{
    font-size:var(--h3-font-size);
    line-height:1.3;
    letter-spacing:var(--h3-letter-spacing);
}
h3.md-heading::before{
    content:'H3';
}
h4{
    font-size:var(--h4-font-size);
}
h4.md-heading::before{
    content:'H4';
}
h5{
    font-size:var(--h5-font-size);
}
h5.md-heading::before{
    content:'H5';
}
h6{
    font-size:var(--h6-font-size);
}
h6.md-heading::before{
    content:'H6';
}
h6 ~ :not(h1, h2, h3, h4, h5, h6){
    font-size:var(--h6-font-size);
}
h6 ~ :is(h1, h2, h3, h4, h5, h6) ~ *:not(h1, h2, h3, h4, h5, h6){
    font-size:inherit;
}
ol,
ul{
    padding-left:1.5rem;
}
ol{
    margin-left:0.25rem;
    list-style-type:decimal;
}
ul{
    list-style-type:disc;
}
:is(ol, ul) :is(ol, ul){
    margin-top:0.75rem;
    margin-bottom:0.75rem;
}
ol > li::marker{
    color:var(--counter-color);
}
ul > li::marker{
    color:var(--marker-color);
}
#write li.task-list-item{
    padding-left:0.75em;
}
input[checked] ~ *{
    opacity:0.6;
    text-decoration:line-through;
}
#write input[type=checkbox],
li.task-list-item > input[type=checkbox]{
    appearance:none;
    width:var(--checkbox-size);
    height:var(--checkbox-size);
    padding:0;
    border:1px solid var(--checkbox-border-color);
    border-radius:var(--checkbox-border-radius);
    background:var(--checkbox-background);
}
#write input[type=checkbox][checked]{
    border-color:var(--color-primary);
    background:var(--color-primary);
}
#write input[type=checkbox][checked]::after{
    content:'';
    position:absolute;
    left:50%;
    top:calc(50% - 0.05em);
    height:calc(var(--checkbox-size) * 0.52);
    width:calc(var(--checkbox-size) * 0.3125);
    border-width:0 2px 2px 0;
    border-color:var(--checkbox-check-color);
    transform:translate(-50%, -50%) rotate(40deg);
}
li.task-list-item > input[type=checkbox]{
    top:calc(((1em * var(--line-height)) / 2) - (var(--checkbox-size) / 2));
    left:calc(0px - var(--checkbox-size));
    margin:0;
}
#write pre.md-meta-block:first-child{
    position:relative;
    overflow:visible;
    margin-bottom:2.5rem;
    padding:var(--code-padding-tb) var(--code-padding-lr);
    border-radius:var(--border-radius);
    background:var(--code-background);
    color:var(--code-text-color);
    font-size:var(--font-size-mono);
    font-weight:var(--font-weight-mono);
}
#write pre.md-meta-block:first-child::after{
    content:'YAML Front Matter';
    position:absolute;
    z-index:1;
    inset:auto var(--code-padding-lr) 100% auto;
    padding:0 1em;
    border-radius:var(--border-radius-s);
    background:var(--code-language-background);
    color:var(--code-language-color);
    font-size:var(--font-size-s);
    line-height:calc(var(--font-size-mono) * var(--line-height));
    transform:translateY(50%);
}
#write pre.md-meta-block:first-child:empty{
    line-height:1.15;
}
#write pre.md-meta-block:first-child:empty::before{
    content:'Insert YAML front matter here...';
    color:var(--code-comment-color);
}
[md-inline="code"]{
    padding:0.1em 0.35em;
    border-radius:var(--border-radius-s);
    background:var(--code-inline-background);
    color:var(--code-inline-color);
}
.md-fences{
    margin:2rem 0;
    background:none;
}
#typora-source .CodeMirror-lines{
    max-width:var(--max-width);
}
#typora-source .CodeMirror-line,
#write .CodeMirror{
    font-family:var(--font-family-mono);
    font-size:var(--font-size-mono);
    font-weight:var(--font-weight-mono);
    color:var(--code-text-color) !important;
}
#write .cm-s-inner,
#write .CodeMirror-scroll,
.md-rawblock-container{
    border-radius:var(--border-radius);
}
#write .cm-s-inner{
    overflow:hidden;
    background:var(--code-background);
}
#write .CodeMirror-lines{
    padding:var(--code-padding-tb) var(--code-padding-lr);
}
#write .CodeMirror-gutters{
    border-color:var(--code-gutter-border-color);
    background:var(--code-background);
}
.CodeMirror-linenumber{
    margin-left:calc(0px - var(--code-padding-lr));
    min-width:2.25em;
}
#write .CodeMirror-scroll{
    cursor:auto;
}
:is(#write, #typora-source) .CodeMirror-cursor{
    border-left:var(--code-cursor-border);
}
:is(#write, #typora-source) .CodeMirror-focused .CodeMirror-activeline:not(:only-child) .CodeMirror-activeline-background{
    border-radius:var(--border-radius-s);
    background:var(--code-activeline-background);
}
:is(#write, #typora-source) .CodeMirror-linenumber{
    color:var(--code-linenumber-color);
}
:is(#write, #typora-source) .CodeMirror-selected:not(.cm-search-hit),
:is(#write, #typora-source) .CodeMirror-selectedtext:not(.cm-search-hit){
    background:var(--code-selected-background) !important;
}
#typora-source .cm-atom{
    color:inherit !important;
}
#write .cm-atom{
    color:var(--code-atom-color) !important;
}
:is(#write, #typora-source) .cm-attribute{
    color:var(--code-attribute-color) !important;
}
:is(#write, #typora-source) .cm-builtin{
    color:var(--code-builtin-color) !important;
}
:is(#write, #typora-source) .cm-comment{
    color:var(--code-comment-color) !important;
    opacity:1 !important;
}
:is(#write, #typora-source) .cm-def{
    color:var(--code-def-color) !important;
}
:is(#write, #typora-source) .cm-error{
    color:var(--code-error-color) !important;
}
#typora-source .cm-header{
    color:var(--heading-color) !important;
}
:is(#write, #typora-source) .cm-keyword{
    color:var(--code-keyword-color) !important;
}
#write .cm-link{
    color:var(--code-link-color) !important;
}
#typora-source .cm-link{
    color:var(--link-color) !important;
}
#write .cm-meta{
    color:var(--code-meta-color) !important;
}
:is(#write, #typora-source) .cm-number{
    color:var(--code-number-color) !important;
}
:is(#write, #typora-source) .cm-operator{
    color:var(--code-operator-color) !important;
}
:is(#write, #typora-source) .cm-property{
    color:var(--code-property-color) !important;
}
:is(#write, #typora-source) .cm-qualifier{
    color:var(--code-qualifier-color) !important;
}
:is(#write, #typora-source) .cm-string{
    color:var(--code-string-color) !important;
}
:is(#write, #typora-source) .cm-string-2{
    color:var(--code-string-2-color) !important;
}
:is(#write, #typora-source) .cm-tag{
    color:var(--code-tag-color) !important;
}
:is(#write, #typora-source) .cm-type{
    color:var(--code-type-color) !important;
}
:is(#write, #typora-source) .cm-s-inner .cm-variable{
    color:var(--code-variable-color) !important;
}
:is(#write, #typora-source) .cm-s-inner .cm-variable-2{
    color:var(--code-variable-2-color) !important;
}
:is(#write, #typora-source) .cm-s-inner .cm-variable-3{
    color:var(--code-variable-3-color) !important;
}
:is(#write, #typora-source) .cm-bracket{
    color:var(--code-bracket-color) !important;
}
#write .md-fences > .code-tooltip,
#write .md-fences > .code-tooltip .ty-cm-lang-input{
    border-radius:var(--border-radius-s);
    font-family:var(--font-family-ui);
    font-size:var(--font-size-s);
    line-height:var(--line-height);
}
#write .md-fences > .code-tooltip{
    bottom:100%;
    right:var(--code-padding-lr);
    z-index:3;
    padding:0;
    border:0;
    color:var(--code-language-color);
    box-shadow:none;
    opacity:1;
    transform:translateY(50%);
}
.md-fences > .code-tooltip .ty-cm-lang-input{
    min-width:17ch;
    margin:0;
    padding:0.15em;
    border:1px solid transparent;
    background:var(--code-language-background);
    line-height:calc(var(--font-size-mono) * var(--line-height));
}
.md-fences > .code-tooltip .ty-cm-lang-input:focus{
    border-color:var(--color-primary);
    background:var(--input-background);
    color:var(--text-color);
}
.md-diagram-panel,
.md-diagram-panel svg,
.md-diagram-panel-preview{
    margin:0;
    padding:0;
}
#write .md-diagram.md-focus .cm-s-inner{
    border-bottom-left-radius:0;
    border-bottom-right-radius:0;
}
#write .md-diagram.md-focus .md-diagram-panel{
    border-bottom-left-radius:var(--border-radius);
    border-bottom-right-radius:var(--border-radius);
    border-width:2px 0 0 0;
    border-color:var(--code-activeline-background);
    background:var(--code-background);
}
.md-diagram-panel-preview svg,
mjx-container svg{
    inset:auto;
    margin:0 auto;
}
.md-fences-adv-panel,
.md-diagram-panel-preview svg text,
.md-diagram-panel-preview svg .label,
.md-diagram-panel-preview svg .nodeLabel{
    font-family:var(--font-family-diagram) !important;
}
.md-diagram-panel-error:not(:empty){
    position:relative;
    margin-top:10px;
    padding:var(--code-padding-tb) var(--code-padding-lr);
    border-radius:var(--border-radius);
    background:var(--code-error-color);
    color:#fff;
    font-size:var(--font-size-s);
    font-weight:calc(var(--font-weight) + 100);
}
.md-diagram-panel-error:not(:empty)::before{
    content:'';
    position:absolute;
    inset:auto auto 100% 50%;
    border-width:11px;
    border-color:transparent;
    border-top-width:0;
    border-bottom-color:var(--code-error-color);
    transform:translateX(-50%);
}
.md-diagram.md-focus .md-diagram-panel-error{
    border-top-left-radius:0;
    border-top-right-radius:0;
}
pre.md-diagram[lang="flow"] .md-diagram-panel-preview{
    padding-bottom:20px;
}
pre.md-diagram[mermaid-type] svg{
    padding-top:5px;
    padding-bottom:12px;
}
pre.md-diagram[mermaid-type="gantt"] svg{
    padding:8px 0 0;
}
pre.md-diagram[mermaid-type="pie"] svg{
    aspect-ratio:16/9;
    padding-top:15px;
}
pre.md-diagram[mermaid-type="sequenceDiagram"] svg{
    padding:13px;
}
pre.md-fences[lang="sequence"] .md-diagram-panel{
    padding:0;
}
.md-math-block.md-focus{
    background:var(--code-background);
}
.md-math-block .code-tooltip{
    box-shadow:none;
}
.md-math-block .md-rawblock-before,
.md-math-block .md-rawblock-after{
    padding:var(--code-padding-tb) var(--code-padding-lr);
}
.md-math-block .md-rawblock-before{
    padding-bottom:0;
}
.md-math-block .md-rawblock-after{
    padding-top:0;
}
.md-math-block .md-math-tag-input{
    position:relative;
    z-index:1;
}
.md-math-block .md-mathjax-preview{
    border-top-width:2px;
    border-color:var(--panel-border-color);
    padding:20px var(--code-padding-lr);
}
.md-rawblock:hover .md-rawblock-container,
.md-rawblock:hover .md-rawblock-tooltip{
    animation:none;
    transition:none;
}
.md-rawblock .md-rawblock-tooltip,
.md-rawblock:hover .md-rawblock-tooltip{
    background:var(--code-language-background);
}
.md-rawblock-tooltip,
.md-rawblock-tooltip-btn,
.md-rawblock-tooltip-name{
    margin:0;
    padding:0;
    color:var(--code-language-color);
    font-family:var(--font-family-ui);
    font-size:var(--font-size-s);
    line-height:calc(var(--font-size-mono) * var(--line-height));
    opacity:1;
}
.md-rawblock:hover .md-rawblock-container{
    background:var(--code-background);
    color:var(--code-text-color);
}
.md-rawblock .md-rawblock-control:not(.md-rawblock-tooltip){
    background:none;
}
.md-rawblock .md-rawblock-input{
    padding:0;
}
.md-rawblock .md-rawblock-tooltip{
    inset:auto 1rem auto auto;
    z-index:4;
    height:auto;
    padding:0 1rem;
    border-radius:var(--border-radius-s);
    transform:translateY(-50%);
}
.md-rawblock-tooltip-name ~ .md-rawblock-tooltip-btn{
    width:auto;
    margin-left:0.25em;
}
figure.md-table-fig{
    margin:2rem 0 2rem 0;
}
thead{
    border-width:var(--thead-border-width, 0);
    border-color:var(--thead-border-color);
}
tbody{
    border-width:var(--tbody-border-width, 0);
    border-color:var(--tbody-border-color);
}
tbody tr{
    border-width:var(--tr-border-width, 0);
    border-color:var(--tr-border-color);
}
tbody tr:nth-child(even){
    background:var(--tr-alt-background);
}
th{
    padding:var(--th-padding);
    border-width:var(--th-border-width, 0);
    border-color:var(--th-border-color);
    font-weight:var(--th-font-weight);
    color:var(--th-color);
}
td{
    padding:var(--td-padding);
    border-width:var(--td-border-width, 0);
    border-color:var(--td-border-color);
}
.md-table-edit{
    z-index:1;
    transform:translate(0, -0.30rem);
    padding:0 5px;
    border-radius:var(--border-radius);
    background:var(--table-edit-background);
}
.md-table-edit{
    display:flex !important;
    align-items:center;
    justify-content:space-between;
}
.md-table-edit .right-th-button{
    float:none;
}
.md-table-edit > span.right-th-button{
    margin-left:auto;
}
.md-table-edit > span.right-th-button ~ .right-th-button{
    margin-left:0;
}
.md-table-edit > span[class] button[class].btn{
    margin:0;
    padding:3px 8px 3px 8px;
    border:0;
    border-radius:0;
    background:var(--table-edit-background);
    color:var(--table-edit-color);
    font-size:inherit;
    line-height:1.4;
}
.md-table-edit > span[class] button[class]:hover{
    background:var(--table-edit-hover-background);
    color:var(--table-edit-hover-color);
}
.md-table-edit > span[class] button[class].active,
.md-table-edit button.active .ty-icon{
    background:var(--table-edit-active-background);
    color:var(--table-edit-active-color);
    box-shadow:none;
}
.md-table-edit .md-table-more{
    display:inline-block;
}
.md-table-edit .md-table-more .ty-icon{
    margin:0 3px !important;
}
.md-table-edit .md-table-more-label{
    display:none !important;
}
.md-table-resize-popover[class]{
    width:auto;
    transform:translate(10px, 2px);
    padding:0;
    border:0;
    background:var(--background-color);
    box-shadow:none;
    filter:var(--drop-shadow);
}
.md-table-resize-popover[class] .arrow,
.md-table-resize-popover[class] .arrow::after{
    border-bottom-color:var(--background-color);
}
.md-grid-board-wrap{
    padding:1rem;
    border-radius:var(--border-radius);
    background:var(--background-color);
}
table.md-grid-board{
    margin:auto;
    border-spacing:3px;
}
table.md-grid-board td{
    overflow:hidden;
    border-radius:2px;
}
table.md-grid-board a{
    border-color:var(--border-color);
    background:var(--input-background);
}
table.md-grid-board .md-grid-ext,
table.md-grid-board .md-grid-ext a{
    border-color:var(--table-edit-active-background);
    background:var(--table-edit-active-background);
}
table.md-grid-board:hover .md-grid-ext,
table.md-grid-board:hover .md-grid-ext a{
    border-color:var(--table-edit-hover-background);
    background:var(--table-edit-hover-background);
}
table.md-grid-board:hover a:hover,
table.md-grid-board:hover a.md-active{
    background:var(--color-primary);
    border-color:var(--color-primary);
}
.md-grid-board-wrap #md-grid-width,
.md-grid-board-wrap #md-grid-height{
    margin:0 0.2rem;
    border-color:var(--border-color);
    border-radius:2px;
    background:var(--input-background);
    line-height:1.6;
    text-align:center;
}
.md-grid-board-wrap .popover-title{
    margin:0.5rem 0 0 0;
    padding:0;
    border:0;
}
.md-grid-board-wrap .popover-title button{
    display:none !important;
}
#table-menu{
    width:30ch;
}
.md-toc{
    margin:2rem 0;
    font-size:var(--font-size-m);
    line-height:var(--line-height);
}
.md-toc-content{
    padding:0;
    margin:0;
}
.md-toc:focus .md-toc-content{
    border:unset;
    margin:0;
}
.md-toc-h1 .md-toc-inner{
    margin-left:0;
    font-weight:var(--strong-font-weight);
}
.md-toc-h2 .md-toc-inner{
    margin-left:1em;
}
.md-toc-h3 .md-toc-inner{
    margin-left:2em;
}
.md-toc-h4 .md-toc-inner{
    margin-left:3em;
}
.md-toc-h5 .md-toc-inner{
    margin-left:4em;
}
.md-toc-h6 .md-toc-inner{
    margin-left:5em;
}
#write div.md-toc-tooltip{
    inset:auto auto 100% -10px;
    width:calc(100% + 20px);
    padding:0 8px;
    border:0;
    border-radius:var(--border-radius);
    background:var(--table-edit-background);
    font-size:var(--font-size-s);
    line-height:calc(var(--font-size-m) * var(--line-height));
}
.md-toc.md-focus .md-toc-tooltip,
.md-toc:focus .md-toc-tooltip{
    display:flex !important;
    align-items:center;
    justify-content:space-between;
}
.megamenu-opened #w-traffic-lights{
    background:var(--mono-50);
    border-bottom-left-radius:var(--border-radius);
    overflow:hidden;
}
.paint-border .megamenu-content{
    border-color:var(--sidebar-border-color);
}
.megamenu-menu,
.megamenu-opened .megamenu-menu{
    transition:.2s;
}
.megamenu-menu{
    border-right:var(--sidebar-border-width) solid var(--sidebar-border-color);
    box-shadow:none;
    background:var(--sidebar-background);
    color:var(--sidebar-color);
}
.megamenu-menu-header{
    border-bottom:var(--sidebar-border-width) solid var(--sidebar-border-color);
}
#megamenu-menu-header-title{
    font-size:var(--font-size-ui-l);
    color:inherit !important;
}
#megamenu-back-btn{
    border-color:transparent;
    color:var(--mono-300);
    font-size:min(16px, calc(var(--font-size-ui-l) * 0.85));
}
.megamenu-menu-header:is(:focus, :hover){
    color:inherit;
}
.megamenu-menu-header:is(:focus,:hover) #megamenu-back-btn{
    color:var(--color-primary);
}
.megamenu-menu-list{
    background-color:transparent;
    border:0;
    border-radius:none;
}
.megamenu-menu-list.dropdown-menu .divider{
    background-color:var(--sidebar-border-color);
    opacity:1;
}
.megamenu-menu-list #m-saved .fa{
    font-size:1em;
}
.megamenu-menu-list #m-saved .fa::before{
    content:"\f00c";
    color:var(--color-primary);
}
.megamenu-menu-list:not(.saved) li a:hover{
    background-color:transparent;
}
.megamenu-menu-list li{
    font-size:var(--font-size-ui);
}
.megamenu-menu-list li a.active,
.megamenu-menu-list:not(.saved) li a:hover{
    background-color:var(--item-hover-bg-color);
    color:var(--item-hover-text-color)
}
.megamenu-opened header{
    background:none !important;
}
.megamenu-content{
    background:transparent;
}
.megamenu-opened > content{
    opacity:0.2;
    filter:blur(10px);
}
#m-import-local:hover .preference-item-hint{
}
.megamenu-menu-panel h1,
.megamenu-menu-panel h2{
    line-height:1;
    font-weight:var(--strong-font-weight);
}
.megamenu-menu-panel h1{
    font-size:var(--font-size-ui-xl);
}
.megamenu-menu-panel h2{
    font-size:var(--font-size-ui-l);
}
.long-btn,
.megamenu-menu-panel .btn,
#recent-file-panel-action-btn{
    background:var(--mono-100);
    border:1px solid var(--mono-300);
}
.long-btn:hover,
.megamenu-menu-panel .btn:hover,
#recent-file-panel-action-btn:hover{
    background-color:var(--item-hover-bg-color);
    color:var(--item-hover-text-color) !important;
}
.long-btn{
    padding:0.75em 1em;
    border-radius:var(--border-radius);
    font-size:inherit;
}
.megamenu-menu-panel table,
.megamenu-menu-panel table :is(thead, tbody, tr, th, td){
    border-style:solid;
}
.megamenu-menu-panel table{
    font-size:inherit !important;
    font-weight:inherit;
    letter-spacing:inherit;
    line-height:inherit;
}
.megamenu-menu-panel table thead{
    border-width:var(--thead-border-width, 0);
    border-color:var(--thead-border-color);
}
.megamenu-menu-panel table tbody{
    border-width:var(--tbody-border-width, 0);
    border-color:var(--tbody-border-color);
}
.megamenu-menu-panel table tbody tr{
    border-width:var(--tr-border-width, 0);
    border-color:var(--tr-border-color);
    background:transparent !important;
}
.megamenu-menu-panel table tbody tr:nth-child(even){
    background:var(--tr-alt-background) !important;
}
.megamenu-menu-panel table tr th{
    padding:var(--th-padding);
    border-width:var(--th-border-width, 0);
    border-color:var(--th-border-color);
    font-weight:var(--th-font-weight);
    color:var(--th-color)
}
.megamenu-menu-panel table tr td{
    padding:var(--td-padding);
    border-width:var(--td-border-width, 0);
    border-color:var(--td-border-color);
}
#recent-file-panel{
    font-size:inherit;
}
#recent-document-table{
    margin-top:1.5em !important;
}
@media (max-width: 530px){
    .megamenu-menu-header #megamenu-menu-header-title{
        display:none;
    }

    .megamenu-menu-list li a{
        font-size:24px;
    }

    .megamenu-menu-list li a.active{
        background-color:var(--item-hover-bg-color);
        color:inherit;
    }
}
.error-dialog .modal-header{
}
.modal-open .modal.fade.in{
}
.megamenu-opened.modal-open .modal.fade.in{
}
#about-content-license-button{
    border-radius:var(--border-radius);
    font-size:inherit;
}
.about-content-slogon{
    font-family:var(--font-family);
    letter-spacing:normal;
    color:var(--color-secondary);
}
.about-content-hint{
    font-size:inherit;
}
.about-content-meta{
    font-size:inherit;
    font-family:var(--font-family-mono);
}
.theme-preview-content{
    border-radius:var(--border-radius);
    border:none
}
.theme-preview-div{
    --border-width:4px;

    border:var(--border-width) solid var(--mono-200);
    color:var(--side-bar-menu-active-tint);
    border-radius:calc(var(--border-radius) + var(--border-width));
}
.theme-preview-div:hover{
    border-color:var(--color-primary);
}
.theme-preview-div.active,
.theme-preview-div.active:hover{
    border-color:var(--color-primary);
}
.theme-preview-div .fa{
    bottom:8px;
    left:auto;
    right:8px;
    padding:0.25em;
    border-radius:50%;
    background:var(--color-primary);
    color:#fff;
    font-size:125%;
}
.theme-preview-div .fa::before{
    content:"\f00c";
}

/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["<no source>","../src/core/vars-palette.css","../src/core/vars-theme.css","../src/core/vars-typora.css","../src/core/base.css","../src/core/app.css","../src/core/quick-open.css","../src/core/searchbar.css","../src/core/sidebar.css","../src/core/outline-popover.css","../src/core/markdown.css","../src/core/headings.css","../src/core/lists.css","../src/core/code.css","../src/core/tables.css","../src/core/toc.css","../src/core/megamenu.css"],"names":[],"mappings":"AAAA;;;;;;GAAA;ACIA;IACI,gBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;;IAElB,mBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;;IAErB,kBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;;IAEpB,mBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;;IAErB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;;IAEnB,kBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;;IAEpB,oBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;;IAEtB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;;IAEnB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;;IAEnB,gBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;IAClB,iBAAkB;;IAElB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;;IAEnB,mBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;;IAErB,mBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;;IAErB,mBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;IACrB,oBAAqB;;IAErB,oBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;;IAEtB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;;IAEnB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IAInB,kBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;;IAEpB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;;IAEnB,iBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;IACnB,kBAAmB;;IAEnB,oBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;IACtB,qBAAsB;;IAEtB,kBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;IACpB,mBAAoB;AACxB;ACrPA;IAMI,8BAA2C;IAC3C,mCAA8C;IAC9C,qCAA8C;IAC9C,yCAA4C;IAC5C,2CAA4C;IAC5C,qCAA2C;IAK3C,2BAA6B;IAC7B,6BAA8B;IAC9B,6BAA8B;IAC9B,6BAA8B;IAC9B,6BAA8B;IAC9B,6BAA8B;IAC9B,6BAA8B;IAC9B,6BAA8B;IAC9B,6BAA8B;IAC9B,6BAA8B;IAG9B,iLAAuL;IACvL,qHAAsH;IACtH,gBAAwB;IACxB,qBAAwB;IACxB,mBAAwB;IACxB,iBAAuB;IACvB,sBAAuB;AAC3B;AAKA;IAEI,6BAAwC;IACxC,6BAAgC;IAChC,4BAA6B;IAC7B,8BAAwC;IACxC,2BAA6B;IAG7B,wCAAyC;IACzC,mCAAyC;IACzC,gEAAuE;IACvE,8DAAsE;IACtE,+CAAwD;IACxD,kBAA2B;IAC3B,6DAAsE;IACtE,8EAAsF;IACtF,oEAAyE;IACzE,iEAAuE;IACvE,6DAAmE;IACnE,iBAA0B;IAC1B,qBAA4B;IAG5B,iCAA8C;IAC9C,8BAA+C;IAC/C,mBAAmC;IACnC,qBAAmC;IACnC,sBAAmC;IACnC,+BAAgC;IAChC,8CAAoD;IACpD,wBAAgC;IAChC,kCAA+C;IAC/C,gDAAkD;IAClD,mDAA0D;IAC1D,wDAA0E;IAC1E,uBAAoC;IACpC,wCAAmD;IACnD,wCAAoD;IACpD,+BAAiD;IACjD,yCAA+C;IAC/C,gCAA+C;IAC/C,8BAA2C;IAC3C,gBAAoC;IACpC,gBAAoC;IACpC,6BAA+C;IAC/C,6CAAsD;IACtD,4BAAkD;IAClD,8CAA2D;IAC3D,sBAAoC;IACpC,qBAAiC;IACjC,oBAAuC;IACvC,sCAAiD;IACjD,kBAAgC;IAChC,8CAAkD;IAClD,iDAA0D;IAC1D,oCAA+C;IAC/C,sCAA+C;IAC/C,0BAAmC;IACnC,+BAA+C;IAC/C,6CAAkD;IAClD,gDAA0D;IAC1D,4BAA+C;IAG/C,uCAA+C;IAC/C,8CAAoD;IACpD,mCAAyC;IACzC,0BAAuC;IACvC,4CAAuD;IACvD,wCAA+C;IAC/C,uCAAmD;IACnD,uBAAqC;IACrC,uBAAqC;IACrC,qCAA+C;IAC/C,uCAA+C;IAC/C,+CAAsD;IACtD,mDAA4D;IAC5D,sBAAsC;IACtC,uBAAuC;IACvC,mCAAoD;IACpD,2BAAuC;IACvC,kCAAmD;IACnD,2BAAuC;IACvC,iCAAkD;IAClD,2BAAuC;IACvC,iCAAkD;IAClD,iCAAkD;IAClD,iCAAkD;IAClD,+BAA+C;IAC/C,yBAAmC;IACnC,0BAA+C;IAC/C,eAAmC;IACnC,iCAAoD;IACpD,sBAAuC;IACvC,sBAAuC;IACvC,8BAA+C;IAC/C,wBAAmC;IACnC,8CAA+C;IAC/C,wCAA8C;IAC9C,uCAA+C;IAC/C,kCAA+C;IAC/C,6CAA+C;IAC/C,gDAAuD;IACvD,0BAAqC;IACrC,0BAAqC;IACrC,uBAAqC;IACrC,uBAAqC;IACrC,2BAA8C;IAC9C,uBAAqC;IACrC,uBAAqC;IACrC,8BAAmD;IACnD,0CAAyD;IACzD,qCAAwD;IACxD,oCAA+C;IAC/C,8BAAyC;IACzC,mCAA+C;IAC/C,iCAA+C;IAC/C,2BAAyC;IAKzC,4CAA6C;IAC7C,kCAA8C;IAC9C,qCAA4C;IAC5C,iCAA6C;IAC7C,oCAA6C;IAC7C,uCAAgD;IAChD,oCAA6C;IAC7C,mDAA4D;IAC5D,kCAA+C;IAC/C,iCAA4C;IAC5C,0CAA6C;IAC7C,mCAA4C;IAC5C,4DAA+D;IAC/D,4CAAoD;IACpD,uCAA6C;IAC7C,kBAA8B;IAC9B,iCAA6C;IAC7C,oBAA8B;IAC9B,qCAA6C;IAC7C,oCAA4C;IAC5C,yCAAgD;IAChD,sDAAyD;IACzD,oBAA8B;IAC9B,sBAA8B;IAC9B,kCAA+C;IAC/C,iCAA6C;IAC7C,iCAA6C;IAC7C,qCAA6C;IAC7C,uCAA6C;IAC7C,0CAAgD;IAGhD,uBAAsC;IACtC,sBAA+B;IAC/B,+BAAoC;IACpC,8BAAkC;IAClC,gCAAiC;IAGjC,uBAAwB;AAC5B;AAKA;IACI;QACI,uBAAwB;IAC5B;AACJ;ACpNA;IACI,uDAA4D;IAC5D,oDAAuD;IACvD,kCAAmD;IACnD,yCAAgD;IAChD,qDAAsD;IACtD,wCAA8C;IAC9C,kDAAsD;IACtD,2CAAuD;IACvD,4BAAmC;IACnC,mCAAmD;IACnD,uDAA0D;IAC1D,oDAAqD;IACrD,kDAAuD;IACvD,6CAAyD;AAC7D;ACfA;;;IAGI,qBAAsB;IACtB,QAAS;IACT,kBAAmB;IACnB,yBAA0B;AAC9B;AAEA;;IAEI,QAAS;IACT,8BAA+B;AACnC;AAEA;IACI,iCAAkC;IAClC,iCAAkC;IAClC,0BAA2B;IAC3B,8BAA+B;AACnC;AAEA;;IAEI,uBAAwB;AAC5B;AAEA;IACI,yBAA0B;AAC9B;AAEA;;IAEI,yBAA0B;IAC1B,qCAAsC;AAC1C;AAEA;IACI,eAAgB;IAChB,iCAAkC;IAClC,2CAA4C;IAC5C,2CAA4C;IAC5C,uCAAwC;IACxC,6BAA8B;AAClC;AAEA;;;;IAII,mCAAoC;IACpC,+BAAgC;AACpC;AAEA;IACI,6BAA8B;IAC9B,oCAAqC;IACrC,kCAAmC;IACnC,gCAAiC;IACjC,sBAAuB;IACvB,eAAgB;AACpB;AAEA;;IAEI,+BAAgC;IAChC,mCAAoC;AACxC;AAEA;IACI,4BAA6B;IAC7B,iCAAkC;AACtC;AAEA;;IAEI,+CAAgD;AACpD;AAEA;IACI,qCAAsC;IACtC,6CAA8C;IAC9C,mCAAoC;IACpC,yBAA0B;AAC9B;AAEA;IACI,cAAe;IACf,iBAAkB;AACtB;AAEA;IACI,4BAA6B;AACjC;AAEA;;IAEI,4BAA6B;AACjC;ACjGA;IACI,uBAAwB;IACxB,mBAAoB;IACpB,iBAAkB;IAClB,6BAA8B;IAC9B,iEAAkE;AACtE;AAOA;IACI,wCAAyC;AAC7C;AAGA;EACE,sBAAuB;UACf,cAAe;AACzB;AAGA;;IAEI,+BAAgC;IAChC,kCAAmC;AACvC;AAEA;IACI,oBAAqB;AACzB;AAGA;;;IAGI,uBAAwB;AAC5B;AAEA;;IAEI,yDAA0D;IAC1D,iCAAkC;IAClC,6BAA8B;AAClC;AAEA;IACI,iCAAkC;AACtC;AAEA;IACI,wCAAyC;IACzC,SAAU;AACd;AAGA;IACI,uBAAwB;YAChB,eAAgB;AAC5B;AAGA;IACI,WAAY;AAChB;AAGA;IACI,kCAAmC;IACnC,4BAA6B;IAC7B,eAAgB;IAChB,yBAA0B;AAC9B;AAGA;;;;;;IAMI,iCAAkC;IAClC,oDAAqD;IACrD,0CAA2C;AAC/C;AAEA;;;;IAII,qCAAsC;IACtC,qDAAsD;AAC1D;AAEA;;IAEI,iBAAkB;IAClB,gBAAiB;IACjB,iDAAkD;IAClD,oCAAqC;IACrC,8BAA+B;AACnC;AAMA;IACI,0BAA2B;IAC3B,uBAAwB;IACxB,8BAA+B;AACnC;AAEA;IACI,YAAa;AACjB;AAEA;IACI,eAAgB;AACpB;AAKA;IACI,4BAA6B;AACjC;AAEA;IACI,eAAgB;IAChB,SAAU;AACd;AAEA;;IAEI,0CAA2C;IAC3C,gCAAiC;AACrC;AC5IA;IACI,uCAAwC;IACxC,SAAU;IACV,oEAAqE;IACrE,kCAAmC;IACnC,oCAAqC;IACrC,0BAA2B;IAC3B,eAAgB;IAChB,yBAA0B;AAC9B;AAEA;;IAEI,aAAc;AAClB;AAEA;IACI,gBAAiB;IACjB,cAAe;IACf,sCAAuC;IACvC,oCAAqC;IACrC,kCAAmC;IACnC,wBAAyB;IACzB,6BAA8B;IAC9B,aAAc;AAClB;AAEA;IACI,qCAAsC;AAC1C;AAEA;;IAEI,WAAY;AAChB;AAEA;IACI,iBAAkB;IAClB,qBAAsB;IACtB,eAAgB;IAChB,WAAY;IACZ,8BAA+B;IAC/B,wBAAyB;IACzB,oBAAqB;IACrB,eAAgB;AACpB;AAEA;IACI,iBAAkB;IAClB,kBAAmB;AACvB;AAEA;;IAEI,eAAgB;IAChB,8BAA+B;AACnC;AAEA;IACI,WAAY;IACZ,kBAAmB;IACnB,qBAAsB;IACtB,6BAA8B;IAC9B,cAAe;AACnB;AAEA;IACI,oCAAqC;AACzC;AAEA;IACI,+BAAgC;AACpC;AAEA;IACI,oBAAqB;IACrB,8BAA+B;AACnC;AAEA;IACI,qCAAsC;IACtC,6CAA8C;IAC9C,mCAAoC;IACpC,yBAA0B;AAC9B;ACpFA;IACI,eAAgB;AACpB;AAEA;IACI,mDAAoD;IACpD,oCAAqC;IACrC,0BAA2B;IAC3B,eAAgB;IAChB,yBAA0B;AAC9B;AAEA;;;IAGI,oCAAqC;IACrC,+BAAgC;AACpC;AAEA;IACI,kCAAmC;IACnC,sCAAuC;IACvC,wBAAyB;AAC7B;AAEA;;IAEI,qCAAsC;AAC1C;AAEA;IACI,eAAgB;AACpB;AAEA;;;IAGI,SAAU;AACd;AAEA;IACI,OAAQ;IACR,eAAgB;IAChB,QAAS;IACT,uCAAwC;IACxC,6BAA8B;AAClC;AAEA;IACI,6CAA8C;IAC9C,mCAAoC;AACxC;AAEA;IACI,8CAA+C;IAC/C,oCAAqC;AACzC;AAEA;IACI,oBAAqB;IACrB,oCAAqC;IACrC,8BAA+B;IAC/B,iCAAkC;AACtC;AC/DA;IACI,0BAA2B;IAC3B,0EAA2E;IAC3E,oCAAqC;IACrC,0BAA2B;AAC/B;AAEA;;;;IAII,6BAA8B;AAClC;AAEA;IACI,oCAAqC;IACrC,kCAAmC;IACnC,wBAAyB;AAC7B;AAEA;;;;IAII,iCAAkC;AACtC;AAEA;IACI,gDAAiD;IACjD,gCAAiC;AACrC;AAGA;;;IAGI,UAAW;IACX,iBAAkB;IAClB,mBAAoB;IACpB,OAAQ;IACR,SAAU;IACV,UAAW;IACX,iBAAkB;IAClB,+BAAgC;AACpC;AAKA;IACI,mBAAoB;AACxB;AAEA;;;;;IAKI,qCAAsC;IACtC,yBAA0B;AAC9B;AAEA;;;IAGI,UAAW;IACX,qCAAsC;AAC1C;AAGA;IACI,2EAA4E;AAChF;AAEA;IACI,qCAAsC;IACtC,mBAAoB;AACxB;AAIA;IACI,8BAA+B;AACnC;AAEA;IACI,aAAc;AAClB;AAEA;;IAEI,qCAAsC;AAC1C;AAEA;IACI,8BAA+B;AACnC;AAEA;;IAEI,YAAa;AACjB;AAEA;IACI,YAAa;IACb,kBAAmB;IACnB,iBAAkB;IAClB,iBAAkB;IAClB,oBAAqB;AACzB;AAEA;IACI,UAAW;IACX,iBAAkB;IAClB,KAAM;IACN,QAAS;IACT,YAAa;IACb,WAAY;AAChB;AAEA;IACI,cAAe;IACf,aAAc;IACd,cAAe;IACf,aAAc;IACd,eAAgB;IAChB,gCAAiC;AACrC;AAEA;IACI,0CAA2C;AAC/C;AAEA;IACI,iBAAkB;AACtB;AAEA;;IAEI,iBAAkB;;IAElB,iCAAkC;IAClC,SAAU;IACV,2BAA4B;IAC5B,6BAA8B;AAClC;AAEA;IACI,aAAc;IACd,WAAY;IACZ,iBAAkB;AACtB;AAEA;IACI,UAAW;IACX,oBAAqB;IACrB,eAAgB;IAChB,kBAAmB;IACnB,sBAAuB;AAC3B;AAEA;IACI,oBAAqB;AACzB;AAEA;IACI,iBAAkB;IAClB,iBAAkB;IAClB,iCAAkC;AACtC;AAEA;IACI,2CAA4C;AAChD;AAEA;IACI,kBAAmB;AACvB;AAIA;IACI,eAAgB;AACpB;AAEA;IACI,eAAgB;IAChB,gBAAiB;IACjB,gBAAiB;AACrB;AAEA;IACI,eAAgB;IAChB,oBAAqB;IACrB,cAAe;AACnB;AAEA;IACI,eAAgB;IAChB,oBAAqB;IACrB,cAAe;AACnB;AAIA;;;;IAII,WAAY;AAChB;AAEA;;IAEI,iBAAkB;IAClB,+BAAgC;AACpC;AAEA;IACI,2EAA4E;AAChF;AAEA;IACI,gDAAiD;IACjD,gCAAiC;AACrC;AAEA;IACI,SAAU;AACd;AAEA;IACI,2CAA4C;IAC5C,iCAAkC;AACtC;AAEA;IACI,iBAAkB;IAClB,iBAAkB;AACtB;AAEA;IACI,kBAAmB;AACvB;AAEA;IACI,qCAAsC;IACtC,yBAA0B;AAC9B;AAGA;IACI,SAAU;AACd;AAEA;IACI,WAAY;IACZ,gDAAiD;IACjD,mBAAoB;IACpB,+BAAgC;AACpC;AAEA;IACI,+BAAgC;AACpC;AAIA;IACI,gCAAiC;AACrC;AAEA;IACI,0CAA2C;AAC/C;AAIA;IACI,aAAc;AAClB;AAEA;IACI,eAAgB;AACpB;AAEA;IACI,cAAe;AACnB;AAGA;IACI,UAAW;AACf;AAEA;IACI,gBAAiB;AACrB;AAEA;IACI,uCAAwC;IACxC,eAAgB;IAChB,sBAAuB;AAE3B;AAEA;IACI,uCAAwC;AAE5C;AAEA;IACI,uCAAwC;AAE5C;AAEA;IACI,uCAAwC;AAE5C;AAEA;IACI,iBAAkB;AACtB;AAEA;IACI,iBAAkB;AACtB;AAEA;IACI,QAAS;AACb;AAEA;IACI,iDAAkD;AACtD;AAEA;IACI,iCAAkC;AACtC;AAEA;IACI,KAAM;IACN,QAAS;IACT,UAAW;IACX,WAAY;IACZ,WAAY;IACZ,UAAW;AACf;AAIA;;IAEI,YAAa;IACb,sBAAuB;IACvB,kBAAmB;IACnB,QAAS;AACb;AAEA;IACI,OAAQ;IACR,eAAgB;IAChB,uCAAwC;IACxC,6BAA8B;IAC9B,SAAU;AACd;AAEA;IACI,6CAA8C;IAC9C,mCAAoC;AACxC;AAEA;IACI,8CAA+C;IAC/C,oCAAqC;AACzC;AAEA;IACI,0BAA2B;AAC/B;AAEA;IACI,0BAA2B;AAC/B;AAEA;;IAEI,uBAAwB;AAC5B;AAEA;IACI,WAAY;IACZ,oBAAqB;IACrB,6BAA8B;IAC9B,wCAAyC;IACzC,oCAAqC;IACrC,sBAAuB;IACvB,aAAc;AAClB;AAEA;;IAEI,qCAAsC;IACtC,kCAAmC;IACnC,wBAAyB;AAC7B;AAEA;IACI,2EAA4E;AAChF;AAEA;IACI,aAAc;;IAEd,kBAAmB;IACnB,qBAAsB;IACtB,iBAAkB;IAClB,oCAAqC;IACrC,iCAAkC;IAClC,+BAAgC;IAChC,qCAAsC;IACtC,uBAAwB;IACxB,iBAAkB;AACtB;AAIA;IACI,gCAAiC;IACjC,iCAAkC;AACtC;AAEA;IACI,wCAAyC;AAC7C;AAEA;IACI,gCAAiC;AACrC;AAEA;IACI,0CAA2C;IAC3C,gCAAiC;AACrC;AAEA;IACI,gBAAiB;AACrB;AAEA;IACI,uBAAwB;IACxB,kBAAmB;IACnB,6BAA8B;AAClC;AAEA;IACI,YAAa;AACjB;AAEA;IACI,UAAW;IACX,iBAAkB;IAClB,mBAAoB;IACpB,SAAU;IACV,SAAU;IACV,UAAW;IACX,iBAAkB;IAClB,+BAAgC;AACpC;AAEA;IACI,WAAY;;IAEZ,iBAAkB;IAClB,kBAAmB;IACnB,cAAe;IACf,iBAAkB;IAClB,oCAAqC;IACrC,uCAAwC;IACxC,6BAA8B;IAC9B,cAAe;IACf,uBAAwB;IACxB,SAAU;AACd;AAEA;IACI,6CAA8C;IAC9C,mCAAoC;AACxC;AAEA;IACI,8CAA+C;IAC/C,oCAAqC;AACzC;AC9eA;IACI,OAAQ;IACR,kGAAmG;IACnG,wCAAyC;IACzC,2DAA4D;IAC5D,oCAAqC;IACrC,0BAA2B;IAC3B,eAAgB;IAChB,yBAA0B;AAC9B;AAEA;IACI,uCAAwC;AAC5C;AAEA;IACI,aAAc;AAClB;AAEA;IACI,YAAa;IACb,wEAAyE;IACzE,SAAU;AACd;AAEA;IACI,YAAa;IACb,6BAA8B;IAC9B,kBAAmB;AACvB;AAEA;IACI;QACI,SAAU;QACV;IACJ;;IAEA;QACI,SAAU;QACV;IACJ;AACJ;ACxCA;IACI,cAAe;AACnB;AAGA;IACI,SAAU;IACV,4BAA6B;AACjC;AAEA;IAEI,SAAU;AACd;AAEA;IAEI,UAAW;AACf;AAEA;IACI,iCAAkC;IAClC,oCAAqC;IACrC,wCAAyC;IACzC,8BAA+B;IAC/B,aAAc;AAClB;AAGA;IAOI,wBAAyB;AAC7B;AAGA;;IAEI,mBAAoB;AACxB;AAGA;;;IAGI,kBAAmB;AACvB;AAGA;IACI,qCAAsC;IACtC,yBAA0B;AAC9B;AAGA;;;IAGI,SAAU;IACV,oBAAqB;AACzB;AAGA;IACI,aAAc;AAClB;AAGA;IACI,aAAc;IACd,iCAAkC;AACtC;AAGA;IAGI,oBAAqB;IACrB,6BAA8B;AAClC;AAGA;;IAEI,uBAAwB;AAC5B;AC1FA;IACI,iBAAkB;IAClB,kBAAmB;IACnB,0BAA2B;IAC3B,sCAAuC;AAC3C;AAEA;IACI,SAAU;IACV,iBAAkB;IAClB,OAAQ;IACR,wBAAyB;IACzB,4BAA6B;IAC7B,iBAAkB;IAClB,wBAAyB;IACzB,SAAU;IACV,sBAAuB;AAC3B;AAEA;IACI,iCAAkC;IAClC,SAAU;AACd;AAEA;IACI,eAAgB;IAChB,6BAA8B;IAC9B,eAAgB;IAChB,uCAAwC;AAC5C;AAEA;IACI,YAAa;AACjB;AAEA;IACI,eAAgB;IAChB,6BAA8B;IAC9B,eAAgB;IAChB,uCAAwC;AAC5C;AAEA;IACI,YAAa;AACjB;AAEA;IACI,6BAA8B;IAC9B,eAAgB;IAChB,uCAAwC;AAC5C;AAEA;IACI,YAAa;AACjB;AAEA;IACI,6BAA8B;AAClC;AAEA;IACI,YAAa;AACjB;AAEA;IACI,6BAA8B;AAClC;AAEA;IACI,YAAa;AACjB;AAEA;IACI,6BAA8B;AAClC;AAEA;IACI,YAAa;AACjB;AAEA;IACI,6BAA8B;AAClC;AAEA;IACI,iBAAkB;AACtB;ACtFA;;IAEI,mBAAoB;AACxB;AAEA;IACI,mBAAoB;IACpB,uBAAwB;AAC5B;AAEA;IACI,oBAAqB;AACzB;AAEA;IACI,kBAAmB;IACnB,qBAAsB;AAC1B;AAEA;IACI,0BAA2B;AAC/B;AAEA;IACI,yBAA0B;AAC9B;AAIA;IACI,mBAAoB;AACxB;AAEA;IACI,WAAY;IACZ,4BAA6B;AACjC;AAEA;;IAEI,eAAgB;IAChB,0BAA2B;IAC3B,2BAA4B;IAC5B,SAAU;IACV,6CAA8C;IAC9C,2CAA4C;IAC5C,qCAAsC;AAC1C;AAEA;IACI,iCAAkC;IAClC,+BAAgC;AACpC;AAEA;IACI,UAAW;IACX,iBAAkB;IAClB,QAAS;IACT,sBAAuB;IACvB,wCAAyC;IACzC,yCAA0C;IAC1C,wBAAyB;IACzB,wCAAyC;IACzC,6CAA8C;AAClD;AAEA;IACI,uEAAwE;IACxE,qCAAsC;IACtC,QAAS;AACb;ACpEA;IACI,iBAAkB;IAClB,gBAAiB;IACjB,oBAAqB;IACrB,qDAAsD;IACtD,kCAAmC;IACnC,iCAAkC;IAClC,4BAA6B;IAC7B,+BAAgC;IAChC,mCAAoC;AACxC;AAEA;IACI,2BAA4B;IAC5B,iBAAkB;IAClB,SAAU;IACV,2CAA4C;IAC5C,aAAc;IACd,oCAAqC;IACrC,0CAA2C;IAC3C,gCAAiC;IACjC,4BAA6B;IAC7B,4DAA6D;IAC7D,yBAA0B;AAC9B;AAEA;IACI,gBAAiB;AACrB;AAEA;IACI,0CAA2C;IAC3C,+BAAgC;AACpC;AAIA;IACI,oBAAqB;IACrB,oCAAqC;IACrC,wCAAyC;IACzC,8BAA+B;AACnC;AAIA;IACI,aAAc;IACd,eAAgB;AACpB;AAIA;IACI,0BAA2B;AAC/B;AAEA;;IAEI,mCAAoC;IACpC,+BAAgC;IAChC,mCAAoC;IACpC,uCAAwC;AAC5C;AAEA;;;IAGI,kCAAmC;AACvC;AAEA;IACI,eAAgB;IAChB,iCAAkC;AACtC;AAEA;IACI,qDAAsD;AAC1D;AAEA;IACI,4CAA6C;IAC7C,iCAAkC;AACtC;AAEA;IACI,8CAA+C;IAC/C,gBAAiB;AACrB;AAEA;IACI,WAAY;AAChB;AAEA;IACI,qCAAsC;AAC1C;AAEA;IACI,oCAAqC;IACrC,4CAA6C;AACjD;AAEA;IACI,kCAAmC;AACvC;AAEA;;IAEI,qDAAsD;AAC1D;AAIA;IACI,wBAAyB;AAC7B;AAEA;IACI,uCAAwC;AAC5C;AAEA;IACI,4CAA6C;AACjD;AAEA;IACI,0CAA2C;AAC/C;AAEA;IACI,0CAA2C;IAC3C,oBAAqB;AACzB;AAEA;IACI,sCAAuC;AAC3C;AAEA;IACI,wCAAyC;AAC7C;AAEA;IACI,qCAAsC;AAC1C;AAEA;IACI,0CAA2C;AAC/C;AAEA;IACI,uCAAwC;AAC5C;AAEA;IACI,kCAAmC;AACvC;AAEA;IACI,uCAAwC;AAC5C;AAEA;IACI,yCAA0C;AAC9C;AAEA;IACI,2CAA4C;AAChD;AAEA;IACI,2CAA4C;AAChD;AAEA;IACI,4CAA6C;AACjD;AAEA;IACI,yCAA0C;AAC9C;AAEA;IACI,2CAA4C;AAChD;AAEA;IACI,sCAAuC;AAC3C;AAEA;IACI,uCAAwC;AAC5C;AAEA;IACI,2CAA4C;AAChD;AAEA;IACI,6CAA8C;AAClD;AAEA;IACI,6CAA8C;AAClD;AAGA;IACI,0CAA2C;AAC/C;AAIA;;IAEI,oCAAqC;IACrC,iCAAkC;IAClC,4BAA6B;IAC7B,8BAA+B;AACnC;AAEA;IACI,WAAY;IACZ,4BAA6B;IAC7B,SAAU;IACV,SAAU;IACV,QAAS;IACT,gCAAiC;IACjC,eAAgB;IAChB,SAAU;IACV,yBAA0B;AAC9B;AAEA;IACI,cAAe;IACf,QAAS;IACT,cAAe;IACf,4BAA6B;IAC7B,0CAA2C;IAC3C,4DAA6D;AACjE;AAEA;IACI,iCAAkC;IAClC,kCAAmC;IACnC,uBAAwB;AAC5B;AAIA;;;IAGI,QAAS;IACT,SAAU;AACd;AAEA;IACI,2BAA4B;IAC5B,4BAA6B;AACjC;AAEA;IACI,8CAA+C;IAC/C,+CAAgD;IAChD,sBAAuB;IACvB,8CAA+C;IAC/C,iCAAkC;AACtC;AAEA;;IAEI,UAAW;IACX,aAAc;AAClB;AAEA;;;;IAII,iDAAkD;AACtD;AAGA;IACI,iBAAkB;IAClB,eAAgB;IAChB,qDAAsD;IACtD,kCAAmC;IACnC,kCAAmC;IACnC,UAAW;IACX,4BAA6B;IAC7B,0CAA2C;AAC/C;AAEA;IACI,UAAW;IACX,iBAAkB;IAClB,wBAAyB;IACzB,iBAAkB;IAClB,wBAAyB;IACzB,kBAAmB;IACnB,2CAA4C;IAC5C,0BAA2B;AAC/B;AAEA;IACI,wBAAyB;IACzB,yBAA0B;AAC9B;AAGA;IACI,mBAAoB;AACxB;AAGA;IACI,eAAgB;IAChB,mBAAoB;AACxB;AAGA;IACI,eAAgB;AACpB;AAGA;IACI,iBAAkB;IAClB,gBAAiB;AACrB;AAGA;IACI,YAAa;AACjB;AAGA;IACI,SAAU;AACd;AAGA;IACI,iCAAkC;AACtC;AAEA;IACI,eAAgB;AACpB;AAEA;;IAEI,qDAAsD;AAC1D;AAEA;IACI,gBAAiB;AACrB;AAEA;IACI,aAAc;AAClB;AAEA;IACI,iBAAkB;IAClB,SAAU;AACd;AAEA;IACI,oBAAqB;IACrB,sCAAuC;IACvC,mCAAoC;AACxC;AAIA;;IAEI,cAAe;IACf,eAAgB;AACpB;AAEA;;IAEI,0CAA2C;AAC/C;AAEA;;;IAGI,QAAS;IACT,SAAU;IACV,gCAAiC;IACjC,iCAAkC;IAClC,4BAA6B;IAC7B,4DAA6D;IAC7D,SAAU;AACd;AAEA;IACI,iCAAkC;IAClC,4BAA6B;AACjC;AAEA;IACI,eAAgB;AACpB;AAEA;IACI,SAAU;AACd;AAEA;IACI,yBAA0B;IAC1B,SAAU;IACV,WAAY;IACZ,cAAe;IACf,oCAAqC;IACrC,0BAA2B;AAC/B;AAEA;IACI,UAAW;IACX,kBAAmB;AACvB;AC7aA;IACI,oBAAqB;AACzB;AAEA;IACI,yCAA0C;IAC1C,sCAAuC;AAC3C;AAEA;IACI,yCAA0C;IAC1C,sCAAuC;AAC3C;AAEA;IACI,sCAAuC;IACvC,mCAAoC;AACxC;AAEA;IACI,mCAAoC;AACxC;AAEA;IACI,yBAA0B;IAC1B,sCAAuC;IACvC,mCAAoC;IACpC,iCAAkC;IAClC,qBAAsB;AAC1B;AAEA;IACI,yBAA0B;IAC1B,sCAAuC;IACvC,mCAAoC;AACxC;AAIA;IACI,SAAU;IACV,gCAAiC;IACjC,aAAc;IACd,kCAAmC;IACnC,uCAAwC;AAC5C;AAEA;IACI,uBAAwB;IACxB,kBAAmB;IACnB,6BAA8B;AAClC;AAEA;IACI,UAAW;AACf;AAEA;IACI,gBAAiB;AACrB;AAEA;IACI,aAAc;AAClB;AAEA;IACI,QAAS;IACT,uBAAwB;IACxB,QAAS;IACT,eAAgB;IAChB,uCAAwC;IACxC,6BAA8B;IAC9B,iBAAkB;IAClB,eAAgB;AACpB;AAEA;IACI,6CAA8C;IAC9C,mCAAoC;AACxC;AAEA;;IAEI,8CAA+C;IAC/C,oCAAqC;IACrC,eAAgB;AACpB;AAEA;IACI,oBAAqB;AACzB;AAEA;IACI,uBAAwB;AAC5B;AAEA;IACI,uBAAwB;AAC5B;AAIA;IACI,UAAW;IACX,8BAA+B;IAC/B,SAAU;IACV,QAAS;IACT,kCAAmC;IACnC,eAAgB;IAChB,yBAA0B;AAC9B;AAEA;;IAEI,2CAA4C;AAChD;AAEA;IACI,YAAa;IACb,kCAAmC;IACnC,kCAAmC;AACvC;AAEA;IACI,WAAY;IACZ,kBAAmB;AACvB;AAEA;IACI,eAAgB;IAChB,iBAAkB;AACtB;AAEA;IACI,gCAAiC;IACjC,kCAAmC;AACvC;AAEA;;IAEI,gDAAiD;IACjD,8CAA+C;AACnD;AAEA;;IAEI,+CAAgD;IAChD,6CAA8C;AAClD;AAEA;;IAEI,+BAAgC;IAChC,iCAAkC;AACtC;AAEA;;IAEI,eAAgB;IAChB,gCAAiC;IACjC,iBAAkB;IAClB,kCAAmC;IACnC,eAAgB;IAChB,iBAAkB;AACtB;AAEA;IACI,mBAAoB;IACpB,SAAU;IACV,QAAS;AACb;AAEA;IACI,uBAAwB;AAC5B;AAIA;IACI,UAAW;AACf;ACpLA;IACI,aAAc;IACd,4BAA6B;IAC7B,8BAA+B;AACnC;AAEA;IACI,SAAU;IACV,QAAS;AACb;AAEA;IACI,YAAa;IACb,QAAS;AACb;AAEA;IACI,aAAc;IACd,qCAAsC;AAC1C;AAEA;IACI,eAAgB;AACpB;AAEA;IACI,eAAgB;AACpB;AAEA;IACI,eAAgB;AACpB;AAEA;IACI,eAAgB;AACpB;AAEA;IACI,eAAgB;AACpB;AAIA;IACI,0BAA2B;IAC3B,uBAAwB;IACxB,aAAc;IACd,QAAS;IACT,kCAAmC;IACnC,uCAAwC;IACxC,4BAA6B;IAC7B,yDAA0D;AAC9D;AAEA;;IAEI,uBAAwB;IACxB,kBAAmB;IACnB,6BAA8B;AAClC;AC3DA;IACI,yBAA0B;IAC1B,8CAA+C;IAC/C,eAAgB;AACpB;AAEA;IACI,wCAAyC;AAC7C;AAEA;;IAEI,cAAe;AACnB;AAEA;IACI,0EAA2E;IAC3E,eAAgB;IAChB,oCAAqC;IACrC,0BAA2B;AAC/B;AAIA;IACI,2EAA4E;AAChF;AAEA;IACI,+BAAgC;IAChC,wBAAyB;AAC7B;AAEA;IACI,wBAAyB;IACzB,qBAAsB;IACtB,uDAAwD;AAC5D;AAEA;IACI,aAAc;AAClB;AAEA;IACI,0BAA2B;AAC/B;AAEA;IACI,4BAA6B;IAC7B,QAAS;IACT,kBAAmB;AACvB;AAEA;IACI,4CAA6C;IAC7C,SAAU;AACd;AAEA;IACI,aAAc;AAClB;AAEA;IACI,eAAgB;IAChB,0BAA2B;AAC/B;AAEA;IACI,4BAA6B;AACjC;AAEA;IACI,6BAA8B;AAClC;AAEA;;IAEI,2CAA4C;IAC5C;AACJ;AAEA;IACI,0BAA2B;AAC/B;AAIA;IACI,sBAAuB;AAC3B;AAEA;IACI,WAAY;IACZ,iBAAkB;AACtB;AAEA;AAEA;AAEA;;IAEI,aAAc;IACd,qCAAsC;AAC1C;AAEA;IACI,gCAAiC;AACrC;AAEA;IACI,+BAAgC;AACpC;AAEA;;;IAGI,0BAA2B;IAC3B,gCAAiC;AACrC;AAEA;;;IAGI,2CAA4C;IAC5C,6CAA8C;AAClD;AAEA;IACI,kBAAmB;IACnB,kCAAmC;IACnC,iBAAkB;AACtB;AAEA;;IAEI,kBAAmB;AACvB;AAEA;IACI,4BAA6B;IAC7B,mBAAoB;IACpB,sBAAuB;IACvB,mBAAoB;AACxB;AAEA;IACI,yCAA0C;IAC1C,sCAAuC;AAC3C;AAEA;IACI,yCAA0C;IAC1C,sCAAuC;AAC3C;AAEA;IACI,sCAAuC;IACvC,mCAAoC;IACpC,iCAAkC;AACtC;AAEA;IACI,8CAA+C;AACnD;AAEA;IACI,yBAA0B;IAC1B,sCAAuC;IACvC,mCAAoC;IACpC,iCAAkC;IAClC;AACJ;AAEA;IACI,yBAA0B;IAC1B,sCAAuC;IACvC,mCAAoC;AACxC;AAEA;IACI,iBAAkB;AACtB;AAEA;IACI,2BAA4B;AAChC;AAEA;IACI;QACI,YAAa;IACjB;;IAEA;QACI,cAAe;IACnB;;IAEA;QACI,2CAA4C;QAC5C,aAAc;IAClB;AACJ;AAIA;AAEA;AAEA;AAEA;AAEA;AAEA;AAIA;IACI,kCAAmC;IACnC,iBAAkB;AACtB;AAEA;IACI,8BAA+B;IAC/B,qBAAsB;IACtB,4BAA6B;AACjC;AAEA;IACI,iBAAkB;AAEtB;AAEA;IAEI,iBAAkB;IAClB,mCAAoC;AACxC;AAIA;IACI,kCAAmC;IACnC;AACJ;AAEA;IACI,kBAAmB;;IAEnB,gDAAiD;IACjD,sCAAuC;IACvC,8DAA+D;AACnE;AAEA;IACI,iCAAkC;AACtC;AAEA;;IAEI,iCAAkC;AACtC;AAEA;IACI,UAAW;IACX,SAAU;IACV,SAAU;IACV,cAAe;IACf,iBAAkB;IAClB,+BAAgC;IAChC,UAAW;IACX,cAAe;AACnB;AAEA;IACI,eAAgB;AACpB","file":"themeable-light.css","sourcesContent":[null,"/* ================================================================ */\n/* Themeable - Color Palette\n/* Credit: https://tailwindcss.com/docs/customizing-colors\n/* ================================================================ */\n:root {\n    --red-50 : #fef2f2;\n    --red-100: #fee2e2;\n    --red-200: #fecaca;\n    --red-300: #fca5a5;\n    --red-400: #f87171;\n    --red-500: #ef4444;\n    --red-600: #dc2626;\n    --red-700: #b91c1c;\n    --red-800: #991b1b;\n    --red-900: #7f1d1d;\n\n    --orange-50 : #fff7ed;\n    --orange-100: #ffedd5;\n    --orange-200: #fed7aa;\n    --orange-300: #fdba74;\n    --orange-400: #fb923c;\n    --orange-500: #f97316;\n    --orange-600: #ea580c;\n    --orange-700: #c2410c;\n    --orange-800: #9a3412;\n    --orange-900: #7c2d12;\n\n    --amber-50 : #fffbeb;\n    --amber-100: #fef3c7;\n    --amber-200: #fde68a;\n    --amber-300: #fcd34d;\n    --amber-400: #fbbf24;\n    --amber-500: #f59e0b;\n    --amber-600: #d97706;\n    --amber-700: #b45309;\n    --amber-800: #92400e;\n    --amber-900: #78350f;\n\n    --yellow-50 : #fefce8;\n    --yellow-100: #fef9c3;\n    --yellow-200: #fef08a;\n    --yellow-300: #fde047;\n    --yellow-400: #facc15;\n    --yellow-500: #eab308;\n    --yellow-600: #ca8a04;\n    --yellow-700: #a16207;\n    --yellow-800: #854d0e;\n    --yellow-900: #713f12;\n\n    --lime-50 : #f7fee7;\n    --lime-100: #ecfccb;\n    --lime-200: #d9f99d;\n    --lime-300: #bef264;\n    --lime-400: #a3e635;\n    --lime-500: #84cc16;\n    --lime-600: #65a30d;\n    --lime-700: #4d7c0f;\n    --lime-800: #3f6212;\n    --lime-900: #365314;\n\n    --green-50 : #f0fdf4;\n    --green-100: #dcfce7;\n    --green-200: #bbf7d0;\n    --green-300: #86efac;\n    --green-400: #4ade80;\n    --green-500: #22c55e;\n    --green-600: #16a34a;\n    --green-700: #15803d;\n    --green-800: #166534;\n    --green-900: #14532d;\n\n    --emerald-50 : #ecfdf5;\n    --emerald-100: #d1fae5;\n    --emerald-200: #a7f3d0;\n    --emerald-300: #6ee7b7;\n    --emerald-400: #34d399;\n    --emerald-500: #10b981;\n    --emerald-600: #059669;\n    --emerald-700: #047857;\n    --emerald-800: #065f46;\n    --emerald-900: #064e3b;\n\n    --teal-50 : #f0fdfa;\n    --teal-100: #ccfbf1;\n    --teal-200: #99f6e4;\n    --teal-300: #5eead4;\n    --teal-400: #2dd4bf;\n    --teal-500: #14b8a6;\n    --teal-600: #0d9488;\n    --teal-700: #0f766e;\n    --teal-800: #115e59;\n    --teal-900: #134e4a;\n\n    --cyan-50 : #ecfeff;\n    --cyan-100: #cffafe;\n    --cyan-200: #a5f3fc;\n    --cyan-300: #67e8f9;\n    --cyan-400: #22d3ee;\n    --cyan-500: #06b6d4;\n    --cyan-600: #0891b2;\n    --cyan-700: #0e7490;\n    --cyan-800: #155e75;\n    --cyan-900: #164e63;\n\n    --sky-50 : #f0f9ff;\n    --sky-100: #e0f2fe;\n    --sky-200: #bae6fd;\n    --sky-300: #7dd3fc;\n    --sky-400: #38bdf8;\n    --sky-500: #0ea5e9;\n    --sky-600: #0284c7;\n    --sky-700: #0369a1;\n    --sky-800: #075985;\n    --sky-900: #0c4a6e;\n\n    --blue-50 : #eff6ff;\n    --blue-100: #dbeafe;\n    --blue-200: #bfdbfe;\n    --blue-300: #93c5fd;\n    --blue-400: #60a5fa;\n    --blue-500: #3b82f6;\n    --blue-600: #2563eb;\n    --blue-700: #1d4ed8;\n    --blue-800: #1e40af;\n    --blue-900: #1e3a8a;\n\n    --indigo-50 : #eef2ff;\n    --indigo-100: #e0e7ff;\n    --indigo-200: #c7d2fe;\n    --indigo-300: #a5b4fc;\n    --indigo-400: #818cf8;\n    --indigo-500: #6366f1;\n    --indigo-600: #4f46e5;\n    --indigo-700: #4338ca;\n    --indigo-800: #3730a3;\n    --indigo-900: #312e81;\n\n    --violet-50 : #f5f3ff;\n    --violet-100: #ede9fe;\n    --violet-200: #ddd6fe;\n    --violet-300: #c4b5fd;\n    --violet-400: #a78bfa;\n    --violet-500: #8b5cf6;\n    --violet-600: #7c3aed;\n    --violet-700: #6d28d9;\n    --violet-800: #5b21b6;\n    --violet-900: #4c1d95;\n\n    --purple-50 : #faf5ff;\n    --purple-100: #f3e8ff;\n    --purple-200: #e9d5ff;\n    --purple-300: #d8b4fe;\n    --purple-400: #c084fc;\n    --purple-500: #a855f7;\n    --purple-600: #9333ea;\n    --purple-700: #7e22ce;\n    --purple-800: #6b21a8;\n    --purple-900: #581c87;\n\n    --fuchsia-50 : #fdf4ff;\n    --fuchsia-100: #fae8ff;\n    --fuchsia-200: #f5d0fe;\n    --fuchsia-300: #f0abfc;\n    --fuchsia-400: #e879f9;\n    --fuchsia-500: #d946ef;\n    --fuchsia-600: #c026d3;\n    --fuchsia-700: #a21caf;\n    --fuchsia-800: #86198f;\n    --fuchsia-900: #701a75;\n\n    --pink-50 : #fdf2f8;\n    --pink-100: #fce7f3;\n    --pink-200: #fbcfe8;\n    --pink-300: #f9a8d4;\n    --pink-400: #f472b6;\n    --pink-500: #ec4899;\n    --pink-600: #db2777;\n    --pink-700: #be185d;\n    --pink-800: #9d174d;\n    --pink-900: #831843;\n\n    --rose-50 : #fff1f2;\n    --rose-100: #ffe4e6;\n    --rose-200: #fecdd3;\n    --rose-300: #fda4af;\n    --rose-400: #fb7185;\n    --rose-500: #f43f5e;\n    --rose-600: #e11d48;\n    --rose-700: #be123c;\n    --rose-800: #9f1239;\n    --rose-900: #881337;\n\n    /* Monochrome (cool => warm) */\n    /* ------------------------------------------------------------ */\n    --slate-50 : #f8fafc;\n    --slate-100: #f1f5f9;\n    --slate-200: #e2e8f0;\n    --slate-300: #cbd5e1;\n    --slate-400: #94a3b8;\n    --slate-500: #64748b;\n    --slate-600: #475569;\n    --slate-700: #334155;\n    --slate-800: #1e293b;\n    --slate-900: #0f172a;\n\n    --gray-50 : #f9fafb;\n    --gray-100: #f3f4f6;\n    --gray-200: #e5e7eb;\n    --gray-300: #d1d5db;\n    --gray-400: #9ca3af;\n    --gray-500: #6b7280;\n    --gray-600: #4b5563;\n    --gray-700: #374151;\n    --gray-800: #1f2937;\n    --gray-900: #111827;\n\n    --zinc-50 : #fafafa;\n    --zinc-100: #f4f4f5;\n    --zinc-200: #e4e4e7;\n    --zinc-300: #d4d4d8;\n    --zinc-400: #a1a1aa;\n    --zinc-500: #71717a;\n    --zinc-600: #52525b;\n    --zinc-700: #3f3f46;\n    --zinc-800: #27272a;\n    --zinc-900: #18181b;\n\n    --neutral-50 : #fafafa;\n    --neutral-100: #f5f5f5;\n    --neutral-200: #e5e5e5;\n    --neutral-300: #d4d4d4;\n    --neutral-400: #a3a3a3;\n    --neutral-500: #737373;\n    --neutral-600: #525252;\n    --neutral-700: #404040;\n    --neutral-800: #262626;\n    --neutral-900: #171717;\n\n    --stone-50 : #fafaf9;\n    --stone-100: #f5f5f4;\n    --stone-200: #e7e5e4;\n    --stone-300: #d6d3d1;\n    --stone-400: #a8a29e;\n    --stone-500: #78716c;\n    --stone-600: #57534e;\n    --stone-700: #44403c;\n    --stone-800: #292524;\n    --stone-900: #1c1917;\n}\n","/* ================================================================ */\n/* Themeable - Common\n/* ================================================================ */\n:root {\n    /* Colors */\n    /* Names: red, orange, amber, yellow, lime, green, emerald, */\n    /*        teal, cyan, sky,blue, indigo, violet, purple, */\n    /*        fuchsia, pink, rose */\n    /* Range: 50 (light), 100, 200 ... 900 (dark) */\n    --color-primary            : var(--sky-600);\n    --color-secondary          : var(--violet-500);\n    --marked-background        : var(--yellow-300);\n    --search-match-background  : var(--pink-100);\n    --search-match-border-color: var(--pink-500);\n    --selection-background     : var(--sky-100);\n\n    /* Monochrome */\n    /* Names: slate, gray, zinc, neutral, stone */\n    /* Range: 50 (light), 100, 200 ... 900 (dark) */\n    --mono-50 : var(--neutral-50);\n    --mono-100: var(--neutral-100);\n    --mono-200: var(--neutral-200);\n    --mono-300: var(--neutral-300);\n    --mono-400: var(--neutral-400);\n    --mono-500: var(--neutral-500);\n    --mono-600: var(--neutral-600);\n    --mono-700: var(--neutral-700);\n    --mono-800: var(--neutral-800);\n    --mono-900: var(--neutral-900);\n\n    /* Typography */\n    --font-family     : \"Inter var\", \"Inter\", system, -apple-system, \".SFNSText-Regular\", \"San Francisco\", \"Segoe UI\", Roboto, Oxygen-Sans, Ubuntu, Cantarell, \"Helvetica Neue\", sans-serif;\n    --font-family-mono: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, \"Liberation Mono\", \"Courier New\", monospace;\n    --font-size       : 16px;\n    --font-size-mono  : 15px;\n    --font-size-ui    : 14px;\n    --font-weight     : 400;\n    --font-weight-mono: 500;\n}\n\n/* ================================================================ */\n/* Themeable - Advanced\n/* ================================================================ */\n:root {\n    /* Colors */\n    --color-hover          : var(--mono-200);\n    --color-hover-content  : inherit;\n    --color-primary-content: #fff;\n    --color-status         : var(--mono-500);\n    --color-status-content : #fff;\n\n    /* Typography */\n    --font-family-diagram: var(--font-family);\n    --font-family-ui     : var(--font-family);\n    --font-size-xxl      : calc(var(--font-size-xl) * var(--modular-scale)); /* 47px (33 * 1.414) */\n    --font-size-xl       : calc(var(--font-size-l) * var(--modular-scale)); /* 33px (23 * 1.414) */\n    --font-size-l        : calc(1rem * var(--modular-scale)); /* 23px (16 * 1.414) */\n    --font-size-m        : 1rem; /* 16px */\n    --font-size-s        : max(0.75rem, calc(1rem / var(--modular-scale))); /* 12px ((16 * 0.75 = 12) > (16 / 1.414 = 11) */\n    --font-size-xs       : max(0.6875rem, calc(var(--font-size-s) / var(--modular-scale))); /* 11px ((16 * 0.6875 = 11) > (12 / 1.414 = 8) */\n    --font-size-ui-xl    : calc(var(--font-size-ui-l) * var(--modular-scale)); /* 28px */\n    --font-size-ui-l     : calc(var(--font-size-ui) * var(--modular-scale)); /* 20px */\n    --font-size-ui-s     : max(12px, calc(var(--font-size-ui) * 0.857)); /* 12px */\n    --line-height        : 1.6;\n    --modular-scale      : 1.414; /* 1.067, 1.125, 1.200, 1.250, 1.333, 1.414, 1.500, 1.618 */\n\n    /* App */\n    --background-color            : var(--mono-50);\n    --border-color                : var(--mono-200);\n    --border-radius               : 6px;\n    --border-radius-s             : 3px;\n    --border-radius-xs            : 1px;\n    --btn-toggle-active-background: ;\n    --btn-toggle-active-color     : var(--color-primary);\n    --btn-toggle-background       : ;\n    --btn-toggle-color            : var(--mono-400);\n    --btn-toggle-hover-background : var(--color-hover);\n    --btn-toggle-hover-color      : var(--color-hover-content);\n    --drop-shadow                 : drop-shadow(0 3px 5px rgba(0, 0, 0, 0.15));\n    --input-background            : #fff;\n    --input-border-color          : var(--border-color);\n    --input-focus-color           : var(--color-primary);\n    --input-color                 : var(--text-color);\n    --input-placeholder-color     : var(--mono-400);\n    --kbd-background              : var(--mono-600);\n    --kbd-border-color            : transparent;\n    --kbd-color                   : #fff;\n    --max-width                   : 75ch;\n    --md-brackets                 : var(--mono-400);\n    --md-brackets-expanded        : var(--color-secondary);\n    --md-tags                     : var(--md-brackets);\n    --md-tags-expanded            : var(--md-brackets-expanded);\n    --menu-background             : #fff;\n    --menu-border-width           : 0;\n    --menu-color                  : inherit;\n    --search-match-color          : var(--text-color);\n    --selection-color             : ;\n    --sidebar-active-background   : var(--color-hover);\n    --sidebar-active-color        : var(--color-hover-content);\n    --sidebar-background          : var(--mono-100);\n    --sidebar-border-color        : var(--mono-200);\n    --sidebar-border-width        : 1px;\n    --sidebar-color               : var(--mono-700);\n    --sidebar-hover-background    : var(--color-hover);\n    --sidebar-hover-color         : var(--color-hover-content);\n    --text-color                  : var(--mono-700);\n\n    /* Elements */\n    --blockquote-background       : var(--mono-100);\n    --blockquote-border-color     : var(--color-primary);\n    --blockquote-border-width     : 0 0 0 4px;\n    --blockquote-color            : inherit;\n    --blockquote-padding          : 1rem 1.5rem 1rem 1.5rem;\n    --code-inline-background      : var(--mono-200);\n    --code-inline-color           : var(--strong-color);\n    --code-padding-tb             : 1.5em;\n    --code-padding-lr             : 1.5em;\n    --checkbox-background         : var(--mono-100);\n    --checkbox-border-color       : var(--mono-300);\n    --checkbox-border-radius      : var(--border-radius-s);\n    --checkbox-check-color        : var(--color-primary-content);\n    --checkbox-size               : 1.2rem;\n    --counter-color               : inherit;\n    --h1-font-size                : var(--font-size-xxl);\n    --h1-letter-spacing           : -0.03em;\n    --h2-font-size                : var(--font-size-xl);\n    --h2-letter-spacing           : -0.02em;\n    --h3-font-size                : var(--font-size-l);\n    --h3-letter-spacing           : -0.01em;\n    --h4-font-size                : var(--font-size-m);\n    --h5-font-size                : var(--font-size-m);\n    --h6-font-size                : var(--font-size-s);\n    --heading-color               : var(--mono-800);\n    --heading-font-weight         : 800;\n    --hr-color                    : var(--mono-300);\n    --hr-height                   : 2px;\n    --link-color                  : var(--color-primary);\n    --marked-color                : inherit;\n    --marker-color                : inherit;\n    --strong-color                : var(--mono-800);\n    --strong-font-weight          : 600;\n    --table-edit-active-background: var(--mono-500);\n    --table-edit-active-color     : var(--mono-50);\n    --table-edit-background       : var(--mono-200);\n    --table-edit-color            : var(--mono-600);\n    --table-edit-hover-background : var(--mono-300);\n    --table-edit-hover-color      : var(--table-edit-color);\n    --tbody-border-color          : unset;\n    --tbody-border-width          : unset;\n    --td-border-color             : unset;\n    --td-border-width             : unset;\n    --td-padding                  : 0.5rem 0.75rem;\n    --th-border-color             : unset;\n    --th-border-width             : unset;\n    --th-color                    : var(--strong-color);\n    --th-font-weight              : var(--strong-font-weight);\n    --th-padding                  : 0 0.75rem 0.5rem 0.75rem;\n    --thead-border-color          : var(--mono-300);\n    --thead-border-width          : 0 0 2px 0;\n    --tr-alt-background           : var(--mono-100);\n    --tr-border-color             : var(--mono-200);\n    --tr-border-width             : 0 0 1px 0;\n\n    /* Syntax Highlighting */\n    /* NOTE: Typora uses CodeMirror for syntax highlight */\n    /* See https://codemirror.net for details and themes */\n    --code-activeline-background: var(--mono-200);\n    --code-atom-color           : var(--amber-600);\n    --code-attribute-color      : var(--sky-600);\n    --code-background           : var(--mono-100);\n    --code-bracket-color        : var(--mono-400);\n    --code-builtin-color        : var(--emerald-600);\n    --code-comment-color        : var(--mono-400);\n    --code-cursor-border        : 2px solid var(--color-primary);\n    --code-def-color            : var(--violet-600);\n    --code-error-color          : var(--red-600);\n    --code-gutter-border-color  : var(--mono-200);\n    --code-keyword-color        : var(--sky-600);\n    --code-language-background  : var(--code-activeline-background);\n    --code-language-color       : var(--code-text-color);\n    --code-linenumber-color     : var(--mono-400);\n    --code-link-color           : ;\n    --code-meta-color           : var(--rose-600);\n    --code-number-color         : ;\n    --code-operator-color       : var(--rose-600);\n    --code-property-color       : var(--sky-600);\n    --code-qualifier-color      : var(--emerald-600);\n    --code-selected-background  : var(--selection-background);\n    --code-string-color         : ;\n    --code-string-2-color       : ;\n    --code-tag-color            : var(--violet-600);\n    --code-text-color           : var(--mono-700);\n    --code-type-color           : var(--rose-600);\n    --code-variable-color       : var(--cyan-600);\n    --code-variable-2-color     : var(--cyan-600);\n    --code-variable-3-color     : var(--emerald-600);\n\n    /* Mermaid*/\n    --mermaid-theme              : neutral; /* base, dark, forest, neutral, night */\n    --mermaid-font-family        : ;\n    --mermaid-flowchart-curve    : basis; /* basis, linear, natural, step */\n    --mermaid-sequence-numbers   : off; /* off, on */\n    --mermaid--gantt-left-padding: 75;\n\n    /* Sequence */\n    --sequence-theme: simple; /* hand, simple */\n}\n\n/* ================================================================ */\n/* Print */\n/* ================================================================ */\n@media print {\n    :root {\n        --background-color: #fff;\n    }\n}\n","/* ================================================================ */\n/* Typora (Overrides)\n/* ================================================================ */\n:root {\n    --active-file-bg-color    : var(--sidebar-active-background);\n    --active-file-text-color  : var(--sidebar-active-color);\n    --bg-color                : var(--background-color);\n    --control-text-color      : var(--sidebar-color);\n    --control-text-hover-color: var(--sidebar-hover-color);\n    --item-hover-bg-color     : var(--color-hover);\n    --item-hover-text-color   : var(--color-hover-content);\n    --md-char-color           : var(--md-brackets-expanded);\n    --meta-content-color      : inherit;\n    --monospace               : var(--font-family-mono);\n    --search-select-bg-color  : var(--search-match-background);\n    --search-select-text-color: var(--search-match-color);\n    --select-text-bg-color    : var(--selection-background);\n    --window-border           : 1px solid var(--border-color);\n}\n","/* ========================================================================== */\n/* Base\n/* ========================================================================== */\n*,\n::before,\n::after  {\n    box-sizing: border-box;\n    border: 0;\n    border-style: solid;\n    border-color: currentColor;\n}\n\nhtml,\nbody {\n    margin: 0;\n    line-height: var(--line-height);\n}\n\nhtml {\n    accent-color: var(--color-primary);\n    font-family: var(--font-family-ui);\n    font-size: var(--font-size);\n    font-weight: var(--font-weight);\n}\n\na,\na code {\n    color: var(--link-color);\n}\n\na {\n    text-decoration: underline;\n}\n\nb,\nstrong {\n    color: var(--strong-color);\n    font-weight: var(--strong-font-weight);\n}\n\nblockquote {\n    margin: 1.5rem 0;\n    padding: var(--blockquote-padding);\n    border-width: var(--blockquote-border-width);\n    border-color: var(--blockquote-border-color);\n    background: var(--blockquote-background);\n    color: var(--blockquote-color);\n}\n\ncode,\nkbd,\nsamp,\npre {\n    font-family: var(--font-family-mono);\n    font-size: var(--font-size-mono);\n}\n\nkbd {\n    padding: .2em .75em .3em .75em;\n    border-color: var(--kbd-border-color);\n    border-radius: var(--border-radius);\n    background: var(--kbd-background);\n    color: var(--kbd-color);\n    box-shadow: none;\n}\n\ncode,\npre {\n    font-size: var(--font-size-mono);\n    font-weight: var(--font-weight-mono);\n}\n\nhr {\n    border-color: var(--hr-color);\n    border-top-width: var(--hr-height);\n}\n\ninput::placeholder,\ntextarea::placeholder {\n    color: var(--input-placeholder-color) !important;\n}\n\nmark {\n    border-radius: var(--border-radius-xs);\n    box-shadow: 0 0 0 1px var(--marked-background);\n    background: var(--marked-background);\n    color: var(--marked-color);\n}\n\np {\n    margin-top: 1em;\n    margin-bottom: 1em;\n}\n\nsmall {\n    font-size: var(--font-size-s);\n}\n\nsub,\nsup {\n    font-size: var(--font-size-s);\n}\n","/* ========================================================================== */\n/* Fonts\n/* ========================================================================== */\n/* Inter: https://rsms.me/inter/ */\n@font-face {\n    font-family: 'Inter var';\n    font-weight: 100 900;\n    font-display: swap;\n    font-style: oblique 0deg 10deg;\n    src: url(\"themeable/fonts/Inter.var.woff2?v=3.19\") format(\"woff2\");\n}\n\n\n/* ========================================================================== */\n/* App\n/* ========================================================================== */\n/* Tabs */\nbody:not([class*=\"seamless\"]) :is(#typora-sidebar, content) {\n    border-top: 1px solid var(--border-color);\n}\n\n/* Blink Effect (ex: rename file) */\n.blink-area {\n  -webkit-animation: none;\n          animation: none;\n}\n\n/* Buttons */\n.btn-primary,\n.btn-primary:hover {\n    background: var(--color-primary);\n    color: var(--color-primary-content);\n}\n\n.btn-primary:hover {\n    filter: contrast(1.2);\n}\n\n/* Context Menus */\n.context-menu,\n.dropdown-menu,\n:is(.context-menu, .dropdown-menu) > li > a {\n    color: var(--menu-color);\n}\n\n.context-menu,\n.dropdown-menu {\n    border: var(--menu-border-width) solid var(--border-color);\n    background: var(--menu-background);\n    font-size: var(--font-size-ui);\n}\n\n:is(.context-menu, .dropdown-menu) .ty-menu-shortcut {\n    font-family: var(--font-family-ui);\n}\n\n.context-menu .divider {\n    border-top: 1px solid var(--border-color);\n    opacity: 1;\n}\n\n/* Form Controls */\n.form-control:focus {\n    -webkit-box-shadow: none;\n            box-shadow: none;\n}\n\n/* Tooltips */\n.code-tooltip-content * {\n    color: unset;\n}\n\n/* Auto-suggest (ex: code fence language selection) */\n#ty-auto-suggest {\n    border-radius: var(--border-radius);\n    font-size: var(--font-size-s);\n    box-shadow: none;\n    filter: var(--drop-shadow);\n}\n\n/* Search Hits */\n.md-search-hit,\n.md-search-hit.md-search-select,\n.md-search-select,\nbody :is(#write, #typora-source) .cm-search-hit,\n.ty-file-search-match-text,\n.ty-outline-hit[class] {\n    background-color: unset !important;\n    background: var(--search-match-background) !important;\n    color: var(--search-match-color) !important;\n}\n\n.md-search-hit,\n.md-search-hit.md-search-select,\n.md-search-select,\nbody :is(#write, #typora-source) .cm-search-hit {\n    border-radius: var(--border-radius-xs);\n    box-shadow: 0 0 0 2px var(--search-match-border-color);\n}\n\n.ty-file-search-match-text,\n.ty-outline-hit[class] {\n    padding-right: 1px;\n    padding-left: 1px;\n    border: 2px solid var(--search-match-border-color);\n    border-radius: var(--border-radius-s);\n    font-weight: var(--font-weight);\n}\n\n\n/* ========================================================================== */\n/* Content Area\n/* ========================================================================== */\n#write {\n    max-width: var(--max-width);\n    color: var(--text-color);\n    font-family: var(--font-family);\n}\n\n#write > :first-child {\n    margin-top: 0;\n}\n\n#write > :last-child {\n    margin-bottom: 0;\n}\n\n/* ========================================================================== */\n/* Footer\n/* ========================================================================== */\nfooter.ty-footer {\n    border-color: var(--mono-200);\n}\n\n.typora-sourceview-on #toggle-sourceview-btn {\n    background: none;\n    opacity: 1;\n}\n\n.footer-item:hover,\n.typora-sourceview-on #toggle-sourceview-btn:hover {\n    background: var(--sidebar-hover-background);\n    color: var(--sidebar-hover-color);\n}\n","/* ========================================================================== */\n/* Quick Open\n/* ========================================================================== */\n#typora-quick-open {\n    top: calc(var(--title-bar-height) + 5px);\n    padding: 0;\n    border: var(--sidebar-border-width) solid var(--sidebar-border-color);\n    border-radius: var(--border-radius);\n    background: var(--sidebar-background);\n    color: var(--sidebar-color);\n    box-shadow: none;\n    filter: var(--drop-shadow);\n}\n\n#typora-quick-open-input,\n.typora-quick-open-list {\n    padding: 0.5em;\n}\n\n#typora-quick-open-input input {\n    max-height: unset;\n    overflow: unset;\n    border-color: var(--input-border-color);\n    border-radius: var(--border-radius-s);\n    background: var(--input-background);\n    color: var(--input-color);\n    font-size: var(--font-size-ui);\n    line-height: 2;\n}\n\n#typora-quick-open-input input:focus {\n    border-color: var(--input-focus-color);\n}\n\n.ty-quick-open-category-title,\n.typora-quick-open-item-path {\n    opacity: 0.7;\n}\n\n.ty-quick-open-category-title {\n    margin-top: 0.5rem;\n    margin-bottom: 0.15rem;\n    font-size: 0.9em;\n    height: auto;\n    line-height: var(--line-height);\n    text-transform: uppercase;\n    letter-spacing: 0.5px;\n    font-weight: 600;\n}\n\n.ty-quick-open-category.ty-has-prev .ty-quick-open-category-title {\n    margin-top: 0.5rem;\n    padding-top: 0.5rem;\n}\n\n.typora-quick-open-item,\n.typora-quick-open-item-path {\n    max-height: auto;\n    line-height: var(--line-height);\n}\n\n.typora-quick-open-item {\n    height: auto;\n    padding-top: 0.25em;\n    padding-bottom: 0.25em;\n    font-size: var(--font-size-ui);\n    cursor: pointer;\n}\n\n.typora-quick-open-item.active {\n    border-radius: var(--border-radius-s);\n}\n\n.typora-quick-open-item-path {\n    font-size: var(--font-size-ui-s);\n}\n\n.typora-quick-open-item-title {\n    margin-bottom: 0.25em;\n    line-height: var(--line-height);\n}\n\n.typora-quick-open-item-title b {\n    border-radius: var(--border-radius-xs);\n    box-shadow: 0 0 0 1px var(--marked-background);\n    background: var(--marked-background);\n    color: var(--marked-color);\n}\n","/* ========================================================================== */\n/* Search Bar (CMD/CTRL+F)\n/* ========================================================================== */\n.mac-seamless-mode #md-searchpanel {\n    max-height: 63px;\n}\n\n#md-searchpanel {\n    border-bottom: 1px solid var(--sidebar-border-color);\n    background: var(--sidebar-background);\n    color: var(--sidebar-color);\n    box-shadow: none;\n    filter: var(--drop-shadow);\n}\n\n#md-searchpanel input,\n#md-searchpanel .btn,\n#searchpanel-msg {\n    border-radius: var(--border-radius-s);\n    font-size: var(--font-size-ui-s);\n}\n\n#md-searchpanel input {\n    background: var(--input-background);\n    border-color: var(--input-border-color);\n    color: var(--input-color);\n}\n\n#md-searchpanel input:focus,\n#md-searchpanel input:not(:placeholder-shown) {\n    border-color: var(--input-focus-color);\n}\n\n#md-searchpanel .btn:not(.close-btn):hover {\n    box-shadow: none;\n}\n\n.searchpanel-search-option-btn,\n.searchpanel-search-option-btn:hover,\n.searchpanel-search-option-btn.active {\n    opacity: 1;\n}\n\n.searchpanel-search-option-btn {\n    top: 4px;\n    padding: 3px 2px;\n    border: 0;\n    background: var(--btn-toggle-background);\n    color: var(--btn-toggle-color);\n}\n\n.searchpanel-search-option-btn:hover {\n    background: var(--btn-toggle-hover-background);\n    color: var(--btn-toggle-hover-color);\n}\n\n.searchpanel-search-option-btn.active {\n    background: var(--btn-toggle-active-background);\n    color: var(--btn-toggle-active-color);\n}\n\n#search-panel-status .error-message {\n    padding: 0.25em 0.5em;\n    border-radius: var(--border-radius-s);\n    background: var(--color-status);\n    color: var(--color-status-content);\n}\n","/* ========================================================================== */\n/* Sidebar\n/* ========================================================================== */\n#typora-sidebar {\n    border-top: none !important;\n    border-right: var(--sidebar-border-width) solid var(--sidebar-border-color);\n    background: var(--sidebar-background);\n    color: var(--sidebar-color);\n}\n\n#typora-sidebar,\n#sidebar-files-menu.dropdown-menu > li,\n.sidebar-content-content,\n.ty-search-item-line {\n    font-size: var(--font-size-ui);\n}\n\n#typora-sidebar input {\n    border-radius: var(--border-radius-s);\n    background: var(--input-background);\n    color: var(--input-color);\n}\n\n.file-list-item-time,\n.file-list-item-parent-loc,\n.file-list-item-summary,\n.ty-search-item-line {\n    font-family: var(--font-family-ui);\n}\n\n.ty-search-item-line:hover {\n    background-color: var(--sidebar-hover-background);\n    color: var(--sidebar-hover-color);\n}\n\n/* Selection Dot */\n.outline-item-active::after,\n.active .file-list-item-file-name::after,\n.active .file-node-content::after {\n    content: \"\";\n    position: absolute;\n    top: calc(50% - 4px);\n    right: 0;\n    width: 8px;\n    height: 8px;\n    border-radius: 50%;\n    background: var(--color-primary);\n}\n\n/* Headers */\n/* -------------------------------------------------------------------------- */\n/* Linux/Windows */\n.info-panel-tab-border {\n    border-radius: 100vw;\n}\n\n.active-tab-files #info-panel-tab-file,\n.active-tab-files #info-panel-tab-file:hover,\n.active-tab-outline #info-panel-tab-outline,\n.active-tab-outline #info-panel-tab-outline:hover,\n.ty-show-search #info-panel-tab-search {\n    font-weight: var(--strong-font-weight);\n    color: var(--strong-color);\n}\n\n.active-tab-files #info-panel-tab-file .info-panel-tab-border,\n.active-tab-outline #info-panel-tab-outline .info-panel-tab-border,\n.ty-show-search #info-panel-tab-search .info-panel-tab-border {\n    height: 3px;\n    background-color: var(--color-primary);\n}\n\n/* macOS */\n.sidebar-tabs {\n    border-bottom: var(--sidebar-border-width) solid var(--sidebar-border-color);\n}\n\n.sidebar-tab {\n    font-weight: var(--strong-font-weight);\n    text-transform: none;\n}\n\n/* Outline */\n/* -------------------------------------------------------------------------- */\n#outline-content {\n    line-height: var(--line-height);\n}\n\n.outline-content {\n    padding-top: 0;\n}\n\n.pin-outline #outline-content .outline-active strong,\n.pin-outline .outline-active {\n    font-weight: var(--strong-font-weight);\n}\n\n.pin-outline .outline-active {\n    font-weight: var(--font-weight);\n}\n\n.outline-item,\n.no-collapse-outline .outline-item {\n    margin: 1px 0;\n}\n\n.outline-item {\n    display: flex;\n    align-items: center;\n    position: relative;\n    padding-top: 0.4em;\n    padding-bottom: 0.4em;\n}\n\n.outline-item::before {\n    content: \"\";\n    position: absolute;\n    top: 0;\n    bottom: 0;\n    right: -100px;\n    left: -100px;\n}\n\n.outline-item:hover {\n    margin-right: 0;\n    margin-left: 0;\n    border-right: 0;\n    border-left: 0;\n    background: none;\n    color: var(--sidebar-hover-color);\n}\n\n.outline-item:hover::before {\n    background: var(--sidebar-hover-background);\n}\n\n.outline-item > * {\n    position: relative;\n}\n\n.outline-expander,\n.outline-expander::before {\n    --icon-width: 10px;\n\n    width: calc(var(--icon-width) * 2);\n    padding: 0;\n    font-size: var(--icon-width);\n    line-height: var(--icon-width);\n}\n\n.outline-expander {\n    display: unset;\n    height: auto;\n    text-align: center;\n}\n\n.outline-label {\n    width: 100%;\n    display: inline-block;\n    overflow: hidden;\n    white-space: nowrap;\n    text-overflow: ellipsis;\n}\n\n.outline-label:hover {\n    text-decoration: none;\n}\n\n.outline-item-active {\n    position: relative;\n    padding-right: 8px;\n    color: var(--sidebar-active-color);\n}\n\n.outline-item-active::before {\n    background: var(--sidebar-active-background);\n}\n\n.outline-item-active .outline-label {\n    padding-right: 10px;\n}\n\n/* Articles & Files (Shared) */\n/* -------------------------------------------------------------------------- */\n.file-node-icon.fa-folder::before {\n    content: \"\\f114\";\n}\n\n.file-node-open-state {\n    margin-top: -2px;\n    margin-right: 3px;\n    margin-left: -2px;\n}\n\n.file-node-collapsed .fa-caret-right::before {\n    content: \"\\f125\";\n    font-family: Ionicons;\n    font-size: 10px;\n}\n\n.file-node-expanded .fa-caret-down::before {\n    content: \"\\f123\";\n    font-family: Ionicons;\n    font-size: 10px;\n}\n\n/* Articles */\n/* -------------------------------------------------------------------------- */\n.file-list-item-file-ext-part,\n.file-list-item-parent-loc,\n.file-list-item-summary,\n.file-list-item-time {\n    opacity: 0.8;\n}\n\n.file-list-item-parent-loc,\n.file-list-item-time {\n    margin-bottom: 3px;\n    font-size: var(--font-size-ui-s);\n}\n\n.file-list-item {\n    border-bottom: var(--sidebar-border-width) solid var(--sidebar-border-color);\n}\n\n.file-list-item:hover {\n    background-color: var(--sidebar-hover-background);\n    color: var(--sidebar-hover-color);\n}\n\n.file-list-item:not(.active) {\n    opacity: 1;\n}\n\n.file-list-item.active {\n    background: var(--sidebar-active-background);\n    color: var(--sidebar-active-color);\n}\n\n.file-list-item-file-name {\n    position: relative;\n    margin-bottom: 4px;\n}\n\n.active .file-list-item-file-name {\n    padding-right: 20px;\n}\n\n.file-list-item-file-name-part {\n    font-weight: var(--strong-font-weight);\n    color: var(--strong-color);\n}\n\n/* Selection Dot */\n.active .file-list-item-file-name::after {\n    right: 8px;\n}\n\n.file-list-item-summary {\n    height: auto;\n    max-height: calc(3 * 0.95em * var(--line-height));\n    line-height: inherit;\n    font-size: var(--font-size-ui-s);\n}\n\n.file-list-item-time {\n    font-size: var(--font-size-ui-s);\n}\n\n/* Files List */\n/* -------------------------------------------------------------------------- */\n.file-library-file-node:not(.active):hover {\n    color: var(--sidebar-hover-color);\n}\n\n.file-library-file-node:not(.active):hover > .file-node-background {\n    background: var(--sidebar-hover-background);\n}\n\n/* Remove dashed outline on mouse-down. */\n/* NOTE: Bad for keyboard navigation, but this is broken in Typora already. */\n.file-library-node:not(.file-node-root):focus > .file-node-content {\n    outline: unset;\n}\n\n.file-node-content {\n    padding-right: 0;\n}\n\n.file-node-content:hover {\n    cursor: pointer;\n}\n\n/* Selection Dot */\n.active .file-node-content::after {\n    right: 14px;\n}\n\n.file-node-icon {\n    margin-right: 5px;\n}\n\n.file-node-title {\n    width: calc(var(--sidebar-width) - 40px);\n    overflow: hidden;\n    text-overflow: ellipsis;\n    /* outline: 1px solid red; */\n}\n\n.file-node-children .file-node-title {\n    width: calc(var(--sidebar-width) - 80px);\n    /* outline: 1px solid blue; */\n}\n\n.file-node-children .file-node-children .file-node-title {\n    width: calc(var(--sidebar-width) - 88px);\n    /* outline: 1px solid green; */\n}\n\n.file-node-children .file-node-children .file-node-children .file-node-title {\n    width: calc(var(--sidebar-width) - 96px);\n    /* outline: 1px solid orange; */\n}\n\n.allow-file-tree-scroll .file-node-title {\n    overflow-x: hidden;\n}\n\n.file-tree-node {\n    position: relative;\n}\n\n.file-tree-node.active > .file-node-background {\n    border: 0;\n}\n\n.file-tree-node.active > .file-node-background {\n    background-color: var(--sidebar-active-background);\n}\n\n.file-tree-node.active > .file-node-content {\n    color: var(--sidebar-active-color);\n}\n\n.file-node-background {\n    top: 0;\n    bottom: 0;\n    right: -4px;\n    left: -100px;\n    height: auto;\n    width: auto;\n}\n\n/* Search */\n/* -------------------------------------------------------------------------- */\n#sidebar-search-btn,\n#ty-sidebar-search-back-btn {\n    display: flex;\n    justify-content: center;\n    align-items: center;\n    margin: 0;\n}\n\n#ty-sidebar-search-tabs .searchpanel-search-option-btn {\n    top: 1em;\n    padding: 3px 1px;\n    background: var(--btn-toggle-background);\n    color: var(--btn-toggle-color);\n    opacity: 1;\n}\n\n#ty-sidebar-search-tabs .searchpanel-search-option-btn:hover {\n    background: var(--btn-toggle-hover-background);\n    color: var(--btn-toggle-hover-color);\n}\n\n#ty-sidebar-search-tabs .searchpanel-search-option-btn.select {\n    background: var(--btn-toggle-active-background);\n    color: var(--btn-toggle-active-color);\n}\n\n#filesearch-case-option-btn {\n    transform: translateX(-8px);\n}\n\n#filesearch-word-option-btn {\n    transform: translateX(-4px);\n}\n\n.ty-show-outline-filter #file-library-search,\n.ty-show-search #file-library-search {\n    height: calc(2em + 32px);\n}\n\n#file-library-search-input {\n    height: auto;\n    padding: 0.5em 0.75em;\n    border: 1px solid currentColor;\n    border-color: var(--sidebar-border-color);\n    border-radius: var(--border-radius-s);\n    background: transparent;\n    color: inherit;\n}\n\n#file-library-search-input:not(:placeholder-shown),\n#file-library-search-input:focus {\n    border-color: var(--input-focus-color);\n    background: var(--input-background);\n    color: var(--input-color);\n}\n\n.ty-search-item {\n    border-bottom: var(--sidebar-border-width) solid var(--sidebar-border-color);\n}\n\n.file-list-item-count {\n    --size: 1.65em;\n\n    height: var(--size);\n    min-width: var(--size);\n    border-radius: 50%;\n    background-color: var(--color-status);\n    color: var(--color-status-content);\n    font-size: var(--font-size-ui-s);\n    font-weight: var(--strong-font-weight);\n    line-height: var(--size);\n    text-align: center;\n}\n\n/* Footer Menu */\n/* -------------------------------------------------------------------------- */\n#sidebar-files-menu {\n    border-color: var(--border-color);\n    background: var(--menu-background);\n}\n\n#ty-sidebar-footer {\n    border-color: var(--sidebar-border-color);\n}\n\n#sidebar-files-menu > .show + .menuitem-group-label.show {\n    border-color: var(--border-color);\n}\n\n.sidebar-footer-item:hover {\n    background: var(--sidebar-hover-background);\n    color: var(--sidebar-hover-color);\n}\n\n#sidebar-files-menu .folder-menu-item i {\n    margin-right: 6px;\n}\n\n.menuitem-group-label.not-empty-menu-group {\n    display: flex !important;\n    align-items: center;\n    justify-content: space-between;\n}\n\n.menuitem-group-label.not-empty-menu-group > .clearfix {\n    display: none;\n}\n\n#sidebar-files-menu .selected-folder-menu-item a::after {\n    content: \"\";\n    position: absolute;\n    top: calc(50% - 4px);\n    right: 8px;\n    width: 8px;\n    height: 8px;\n    border-radius: 50%;\n    background: var(--color-primary);\n}\n\n#sidebar-files-menu .ty-side-sort-btn {\n    --size: 24px;\n\n    width: var(--size);\n    height: var(--size);\n    margin-top: 6px;\n    margin-bottom: 6px;\n    border-radius: var(--border-radius-s);\n    background: var(--btn-toggle-background);\n    color: var(--btn-toggle-color);\n    font-size: 13px;\n    line-height: var(--size);\n    opacity: 1;\n}\n\n#sidebar-files-menu .ty-side-sort-btn:hover {\n    background: var(--btn-toggle-hover-background);\n    color: var(--btn-toggle-hover-color);\n}\n\n#sidebar-files-menu .ty-side-sort-btn.active {\n    background: var(--btn-toggle-active-background);\n    color: var(--btn-toggle-active-color);\n}\n","/* ========================================================================== */\n/* Outline Popover\n/* ========================================================================== */\n#toc-dropmenu {\n    right: 0;\n    border-width: var(--sidebar-border-width) 0 var(--sidebar-border-width) var(--sidebar-border-width);\n    border-color: var(--sidebar-border-color);\n    border-radius: var(--border-radius) 0 0 var(--border-radius);\n    background: var(--sidebar-background);\n    color: var(--sidebar-color);\n    box-shadow: none;\n    filter: var(--drop-shadow);\n}\n\n#toc-dropmenu.open {\n    animation: toc-in-from-right .3s ease-in;\n}\n\n#toc-dropmenu .btn {\n    color: inherit;\n}\n\n#toc-dropmenu .divider {\n    margin: 5px 0;\n    border-top: var(--sidebar-border-width) solid var(--sidebar-border-color);\n    opacity: 1;\n}\n\n#toc-dropmenu .outline-title-wrapper {\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n}\n\n@keyframes toc-in-from-right {\n    0% {\n        opacity: 0;\n        transform: translateX(20%)\n    }\n\n    100% {\n        opacity: 1;\n        transform: translateX(0)\n    }\n}\n","/* ========================================================================== */\n/* Markdown\n/* ========================================================================== */\n/* Button Icons */\nbutton.btn .ty-icon {\n    font-size: 13px; /* Icons */\n}\n\n/* Footnotes */\n.footnotes {\n    opacity: 1;\n    font-size: var(--font-size-s);\n}\n\n.md-p {\n    /* Footnote cursor fix #1 */\n    z-index: 0;\n}\n\n.md-footnote {\n    /* Footnote cursor fix #2 */\n    z-index: -1;\n}\n\nsup.md-footnote {\n    padding: 0.1em 0.25em 0.2em 0.25em;\n    border-radius: var(--border-radius-s);\n    background: var(--code-inline-background);\n    color: var(--code-inline-color);\n    line-height: 1;\n}\n\n/* Footnote Brackets */\n.md-def-name::before,\n.md-def-name::after,\n.md-def-title::before,\n.md-def-title::after,\n/* Link Brackets */\n.md-link .md-meta.md-before,\n.md-link .md-meta.md-after {\n    color: var(--md-brackets);\n}\n\n/* Footnote & Link Bracket */\n.md-footnote .md-meta.md-before,\n.md-link .md-meta.md-before {\n    margin-right: 0.15em;\n}\n\n/* Footnote & Link Bracket */\n.md-footnote .md-meta.md-after,\n.md-link .md-meta.md-before ~ .md-meta.md-before,\n.md-link .md-meta.md-after {\n    margin-left: 0.15em;\n}\n\n/* Footnote & Link Name */\n.md-def-name {\n    font-weight: var(--strong-font-weight);\n    color: var(--strong-color);\n}\n\n/* HTML tags (always visible) */\n.md-br,\n.md-br-content,\n.md-comment {\n    opacity: 1;\n    color: var(--md-tags);\n}\n\n/* Horizontal Rules */\n.md-hr {\n    margin: 3rem 0;\n}\n\n/* Images */\n.md-image > .md-meta {\n    color: inherit;\n    font-family: var(--font-family-ui);\n}\n\n/* Image Icon */\n.md-image > .md-meta::before,\n/* HTML tags */\n.md-raw-inline:not(.md-br-content) {\n    opacity: 1 !important;\n    color: var(--md-tags-expanded);\n}\n\n/* URLs */\n.md-url,\n.md-def-url {\n    color: var(--link-color);\n}\n","/* ========================================================================== */\n/* Headings\n/* ========================================================================== */\n:is(h1, h2, h3, h4, h5, h6) {\n    margin-top: 1.5rem;\n    margin-bottom: 1rem;\n    color: var(--heading-color);\n    font-weight: var(--heading-font-weight);\n}\n\n:is(h1, h2, h3, h4, h5, h6).md-heading::before {\n    all: unset;\n    position: absolute;\n    top: 50%;\n    right: calc(100% + 0.5em);\n    transform: translate(0, -50%);\n    font-size: 0.75rem;\n    color: var(--md-brackets);\n    opacity: 0;\n    transition: all 0.2s 0s;\n}\n\n:is(h1, h2, h3, h4, h5, h6).md-focus::before {\n    transform: translate(-0.5em, -50%);\n    opacity: 1;\n}\n\nh1 {\n    margin-top: 3rem;\n    font-size: var(--h1-font-size);\n    line-height: 1.1;\n    letter-spacing: var(--h1-letter-spacing);\n}\n\nh1.md-heading::before {\n    content: 'H1';\n}\n\nh2 {\n    margin-top: 2rem;\n    font-size: var(--h2-font-size);\n    line-height: 1.2;\n    letter-spacing: var(--h2-letter-spacing);\n}\n\nh2.md-heading::before {\n    content: 'H2';\n}\n\nh3 {\n    font-size: var(--h3-font-size);\n    line-height: 1.3;\n    letter-spacing: var(--h3-letter-spacing);\n}\n\nh3.md-heading::before {\n    content: 'H3';\n}\n\nh4 {\n    font-size: var(--h4-font-size);\n}\n\nh4.md-heading::before {\n    content: 'H4';\n}\n\nh5 {\n    font-size: var(--h5-font-size);\n}\n\nh5.md-heading::before {\n    content: 'H5';\n}\n\nh6 {\n    font-size: var(--h6-font-size);\n}\n\nh6.md-heading::before {\n    content: 'H6';\n}\n\nh6 ~ :not(h1, h2, h3, h4, h5, h6) {\n    font-size: var(--h6-font-size);\n}\n\nh6 ~ :is(h1, h2, h3, h4, h5, h6) ~ *:not(h1, h2, h3, h4, h5, h6) {\n    font-size: inherit;\n}\n","/* ========================================================================== */\n/* Lists\n/* ========================================================================== */\nol,\nul {\n    padding-left: 1.5rem;\n}\n\nol {\n    margin-left: 0.25rem;\n    list-style-type: decimal;\n}\n\nul {\n    list-style-type: disc;\n}\n\n:is(ol, ul) :is(ol, ul) {\n    margin-top: 0.75rem;\n    margin-bottom: 0.75rem;\n}\n\nol > li::marker {\n    color: var(--counter-color);\n}\n\nul > li::marker {\n    color: var(--marker-color);\n}\n\n/* Task Lists */\n/* -------------------------------------------------------------------------- */\n#write li.task-list-item {\n    padding-left: 0.75em;\n}\n\ninput[checked] ~ * {\n    opacity: 0.6;\n    text-decoration: line-through;\n}\n\n#write input[type=checkbox],\nli.task-list-item > input[type=checkbox] {\n    appearance: none;\n    width: var(--checkbox-size);\n    height: var(--checkbox-size);\n    padding: 0;\n    border: 1px solid var(--checkbox-border-color);\n    border-radius: var(--checkbox-border-radius);\n    background: var(--checkbox-background);\n}\n\n#write input[type=checkbox][checked] {\n    border-color: var(--color-primary);\n    background: var(--color-primary);\n}\n\n#write input[type=checkbox][checked]::after {\n    content: '';\n    position: absolute;\n    left: 50%;\n    top: calc(50% - 0.05em);\n    height: calc(var(--checkbox-size) * 0.52);\n    width: calc(var(--checkbox-size) * 0.3125);\n    border-width: 0 2px 2px 0;\n    border-color: var(--checkbox-check-color);\n    transform: translate(-50%, -50%) rotate(40deg);\n}\n\nli.task-list-item > input[type=checkbox] {\n    top: calc(((1em * var(--line-height)) / 2) - (var(--checkbox-size) / 2));\n    left: calc(0px - var(--checkbox-size));\n    margin: 0;\n}\n","/* ========================================================================== */\n/* Code\n/* ========================================================================== */\n/* YAML Front Matter */\n/* -------------------------------------------------------------------------- */\n#write pre.md-meta-block:first-child {\n    position: relative;\n    overflow: visible;\n    margin-bottom: 2.5rem;\n    padding: var(--code-padding-tb) var(--code-padding-lr);\n    border-radius: var(--border-radius);\n    background: var(--code-background);\n    color: var(--code-text-color);\n    font-size: var(--font-size-mono);\n    font-weight: var(--font-weight-mono);\n}\n\n#write pre.md-meta-block:first-child::after {\n    content: 'YAML Front Matter';\n    position: absolute;\n    z-index: 1;\n    inset: auto var(--code-padding-lr) 100% auto;\n    padding: 0 1em;\n    border-radius: var(--border-radius-s);\n    background: var(--code-language-background);\n    color: var(--code-language-color);\n    font-size: var(--font-size-s);\n    line-height: calc(var(--font-size-mono) * var(--line-height));\n    transform: translateY(50%);\n}\n\n#write pre.md-meta-block:first-child:empty {\n    line-height: 1.15;\n}\n\n#write pre.md-meta-block:first-child:empty::before {\n    content: 'Insert YAML front matter here...';\n    color: var(--code-comment-color);\n}\n\n/* Inline */\n/* -------------------------------------------------------------------------- */\n[md-inline=\"code\"] {\n    padding: 0.1em 0.35em;\n    border-radius: var(--border-radius-s);\n    background: var(--code-inline-background);\n    color: var(--code-inline-color);\n}\n\n/* Fences */\n/* -------------------------------------------------------------------------- */\n.md-fences {\n    margin: 2rem 0;\n    background: none;\n}\n\n/* CodeMirror */\n/* -------------------------------------------------------------------------- */\n#typora-source .CodeMirror-lines {\n    max-width: var(--max-width);\n}\n\n#typora-source .CodeMirror-line,\n#write .CodeMirror {\n    font-family: var(--font-family-mono);\n    font-size: var(--font-size-mono);\n    font-weight: var(--font-weight-mono);\n    color: var(--code-text-color) !important;\n}\n\n#write .cm-s-inner,\n#write .CodeMirror-scroll,\n.md-rawblock-container {\n    border-radius: var(--border-radius);\n}\n\n#write .cm-s-inner {\n    overflow: hidden;\n    background: var(--code-background);\n}\n\n#write .CodeMirror-lines {\n    padding: var(--code-padding-tb) var(--code-padding-lr);\n}\n\n#write .CodeMirror-gutters {\n    border-color: var(--code-gutter-border-color);\n    background: var(--code-background);\n}\n\n.CodeMirror-linenumber {\n    margin-left: calc(0px - var(--code-padding-lr));\n    min-width: 2.25em;\n}\n\n#write .CodeMirror-scroll {\n    cursor: auto;\n}\n\n:is(#write, #typora-source) .CodeMirror-cursor {\n    border-left: var(--code-cursor-border);\n}\n\n:is(#write, #typora-source) .CodeMirror-focused .CodeMirror-activeline:not(:only-child) .CodeMirror-activeline-background {\n    border-radius: var(--border-radius-s);\n    background: var(--code-activeline-background);\n}\n\n:is(#write, #typora-source) .CodeMirror-linenumber {\n    color: var(--code-linenumber-color);\n}\n\n:is(#write, #typora-source) .CodeMirror-selected:not(.cm-search-hit),\n:is(#write, #typora-source) .CodeMirror-selectedtext:not(.cm-search-hit) {\n    background: var(--code-selected-background) !important;\n}\n\n/* Syntax Highlighting */\n/* -------------------------------------------------------------------------- */\n#typora-source .cm-atom {\n    color: inherit !important;\n}\n\n#write .cm-atom {\n    color: var(--code-atom-color) !important;\n}\n\n:is(#write, #typora-source) .cm-attribute {\n    color: var(--code-attribute-color) !important;\n}\n\n:is(#write, #typora-source) .cm-builtin {\n    color: var(--code-builtin-color) !important;\n}\n\n:is(#write, #typora-source) .cm-comment {\n    color: var(--code-comment-color) !important;\n    opacity: 1 !important;\n}\n\n:is(#write, #typora-source) .cm-def {\n    color: var(--code-def-color) !important;\n}\n\n:is(#write, #typora-source) .cm-error {\n    color: var(--code-error-color) !important;\n}\n\n#typora-source .cm-header {\n    color: var(--heading-color) !important;\n}\n\n:is(#write, #typora-source) .cm-keyword {\n    color: var(--code-keyword-color) !important;\n}\n\n#write .cm-link {\n    color: var(--code-link-color) !important;\n}\n\n#typora-source .cm-link {\n    color: var(--link-color) !important;\n}\n\n#write .cm-meta {\n    color: var(--code-meta-color) !important;\n}\n\n:is(#write, #typora-source) .cm-number {\n    color: var(--code-number-color) !important;\n}\n\n:is(#write, #typora-source) .cm-operator {\n    color: var(--code-operator-color) !important;\n}\n\n:is(#write, #typora-source) .cm-property {\n    color: var(--code-property-color) !important;\n}\n\n:is(#write, #typora-source) .cm-qualifier {\n    color: var(--code-qualifier-color) !important;\n}\n\n:is(#write, #typora-source) .cm-string {\n    color: var(--code-string-color) !important;\n}\n\n:is(#write, #typora-source) .cm-string-2 {\n    color: var(--code-string-2-color) !important;\n}\n\n:is(#write, #typora-source) .cm-tag {\n    color: var(--code-tag-color) !important;\n}\n\n:is(#write, #typora-source) .cm-type {\n    color: var(--code-type-color) !important;\n}\n\n:is(#write, #typora-source) .cm-s-inner .cm-variable {\n    color: var(--code-variable-color) !important;\n}\n\n:is(#write, #typora-source) .cm-s-inner .cm-variable-2 {\n    color: var(--code-variable-2-color) !important;\n}\n\n:is(#write, #typora-source) .cm-s-inner .cm-variable-3 {\n    color: var(--code-variable-3-color) !important;\n}\n\n/* Note: must come after other classes */\n:is(#write, #typora-source) .cm-bracket {\n    color: var(--code-bracket-color) !important;\n}\n\n/* Language Selector */\n/* -------------------------------------------------------------------------- */\n#write .md-fences > .code-tooltip,\n#write .md-fences > .code-tooltip .ty-cm-lang-input {\n    border-radius: var(--border-radius-s);\n    font-family: var(--font-family-ui);\n    font-size: var(--font-size-s);\n    line-height: var(--line-height);\n}\n\n#write .md-fences > .code-tooltip {\n    bottom: 100%;\n    right: var(--code-padding-lr);\n    z-index: 3;\n    padding: 0;\n    border: 0;\n    color: var(--code-language-color);\n    box-shadow: none;\n    opacity: 1;\n    transform: translateY(50%);\n}\n\n.md-fences > .code-tooltip .ty-cm-lang-input {\n    min-width: 17ch;\n    margin: 0;\n    padding: 0.15em;\n    border: 1px solid transparent;\n    background: var(--code-language-background);\n    line-height: calc(var(--font-size-mono) * var(--line-height));\n}\n\n.md-fences > .code-tooltip .ty-cm-lang-input:focus {\n    border-color: var(--color-primary);\n    background: var(--input-background);\n    color: var(--text-color);\n}\n\n/* Diagrams */\n/* -------------------------------------------------------------------------- */\n.md-diagram-panel,\n.md-diagram-panel svg,\n.md-diagram-panel-preview {\n    margin: 0;\n    padding: 0;\n}\n\n#write .md-diagram.md-focus .cm-s-inner {\n    border-bottom-left-radius: 0;\n    border-bottom-right-radius: 0;\n}\n\n#write .md-diagram.md-focus .md-diagram-panel {\n    border-bottom-left-radius: var(--border-radius);\n    border-bottom-right-radius: var(--border-radius);\n    border-width: 2px 0 0 0;\n    border-color: var(--code-activeline-background);\n    background: var(--code-background);\n}\n\n.md-diagram-panel-preview svg,\nmjx-container svg {\n    inset: auto;\n    margin: 0 auto;\n}\n\n.md-fences-adv-panel,\n.md-diagram-panel-preview svg text,\n.md-diagram-panel-preview svg .label,\n.md-diagram-panel-preview svg .nodeLabel {\n    font-family: var(--font-family-diagram) !important;\n}\n\n/* Errors */\n.md-diagram-panel-error:not(:empty) {\n    position: relative;\n    margin-top: 10px;\n    padding: var(--code-padding-tb) var(--code-padding-lr);\n    border-radius: var(--border-radius);\n    background: var(--code-error-color);\n    color: #fff;\n    font-size: var(--font-size-s);\n    font-weight: calc(var(--font-weight) + 100);\n}\n\n.md-diagram-panel-error:not(:empty)::before {\n    content: '';\n    position: absolute;\n    inset: auto auto 100% 50%;\n    border-width: 11px;\n    border-color: transparent;\n    border-top-width: 0;\n    border-bottom-color: var(--code-error-color);\n    transform: translateX(-50%);\n}\n\n.md-diagram.md-focus .md-diagram-panel-error {\n    border-top-left-radius: 0;\n    border-top-right-radius: 0;\n}\n\n/* Flowcharts */\npre.md-diagram[lang=\"flow\"] .md-diagram-panel-preview {\n    padding-bottom: 20px;\n}\n\n/* Mermaid */\npre.md-diagram[mermaid-type] svg {\n    padding-top: 5px;\n    padding-bottom: 12px;\n}\n\n/* Mermaid: GANTT */\npre.md-diagram[mermaid-type=\"gantt\"] svg {\n    padding: 8px 0 0;\n}\n\n/* Mermaid: Pie */\npre.md-diagram[mermaid-type=\"pie\"] svg {\n    aspect-ratio: 16/9;\n    padding-top: 15px;\n}\n\n/* Mermaid: Sequence */\npre.md-diagram[mermaid-type=\"sequenceDiagram\"] svg {\n    padding: 13px;\n}\n\n/* Sequence */\npre.md-fences[lang=\"sequence\"] .md-diagram-panel {\n    padding: 0;\n}\n\n/* Math (LaTeX / Tex) */\n.md-math-block.md-focus {\n    background: var(--code-background);\n}\n\n.md-math-block .code-tooltip {\n    box-shadow: none;\n}\n\n.md-math-block .md-rawblock-before,\n.md-math-block .md-rawblock-after {\n    padding: var(--code-padding-tb) var(--code-padding-lr);\n}\n\n.md-math-block .md-rawblock-before {\n    padding-bottom: 0;\n}\n\n.md-math-block .md-rawblock-after {\n    padding-top: 0;\n}\n\n.md-math-block .md-math-tag-input {\n    position: relative;\n    z-index: 1;\n}\n\n.md-math-block .md-mathjax-preview {\n    border-top-width: 2px;\n    border-color: var(--panel-border-color);\n    padding: 20px var(--code-padding-lr);\n}\n\n/* Raw Blocks */\n/* -------------------------------------------------------------------------- */\n.md-rawblock:hover .md-rawblock-container,\n.md-rawblock:hover .md-rawblock-tooltip {\n    animation: none;\n    transition: none;\n}\n\n.md-rawblock .md-rawblock-tooltip,\n.md-rawblock:hover .md-rawblock-tooltip {\n    background: var(--code-language-background);\n}\n\n.md-rawblock-tooltip,\n.md-rawblock-tooltip-btn,\n.md-rawblock-tooltip-name {\n    margin: 0;\n    padding: 0;\n    color: var(--code-language-color);\n    font-family: var(--font-family-ui);\n    font-size: var(--font-size-s);\n    line-height: calc(var(--font-size-mono) * var(--line-height));\n    opacity: 1;\n}\n\n.md-rawblock:hover .md-rawblock-container {\n    background: var(--code-background);\n    color: var(--code-text-color);\n}\n\n.md-rawblock .md-rawblock-control:not(.md-rawblock-tooltip) {\n    background: none;\n}\n\n.md-rawblock .md-rawblock-input {\n    padding: 0;\n}\n\n.md-rawblock .md-rawblock-tooltip {\n    inset: auto 1rem auto auto;\n    z-index: 4;\n    height: auto;\n    padding: 0 1rem;\n    border-radius: var(--border-radius-s);\n    transform: translateY(-50%);\n}\n\n.md-rawblock-tooltip-name ~ .md-rawblock-tooltip-btn {\n    width: auto;\n    margin-left: 0.25em;\n}\n","/* ========================================================================== */\n/* Tables\n/* ========================================================================== */\nfigure.md-table-fig {\n    margin: 2rem 0 2rem 0;\n}\n\nthead {\n    border-width: var(--thead-border-width, 0);\n    border-color: var(--thead-border-color);\n}\n\ntbody {\n    border-width: var(--tbody-border-width, 0);\n    border-color: var(--tbody-border-color);\n}\n\ntbody tr {\n    border-width: var(--tr-border-width, 0);\n    border-color: var(--tr-border-color);\n}\n\ntbody tr:nth-child(even) {\n    background: var(--tr-alt-background);\n}\n\nth {\n    padding: var(--th-padding);\n    border-width: var(--th-border-width, 0);\n    border-color: var(--th-border-color);\n    font-weight: var(--th-font-weight);\n    color: var(--th-color);\n}\n\ntd {\n    padding: var(--td-padding);\n    border-width: var(--td-border-width, 0);\n    border-color: var(--td-border-color);\n}\n\n/* Editing Bar */\n/* -------------------------------------------------------------------------- */\n.md-table-edit {\n    z-index: 1;\n    transform: translate(0, -0.30rem);\n    padding: 0 5px;\n    border-radius: var(--border-radius);\n    background: var(--table-edit-background);\n}\n\n.md-table-edit {\n    display: flex !important;\n    align-items: center;\n    justify-content: space-between;\n}\n\n.md-table-edit .right-th-button {\n    float: none;\n}\n\n.md-table-edit > span.right-th-button {\n    margin-left: auto;\n}\n\n.md-table-edit > span.right-th-button ~ .right-th-button  {\n    margin-left: 0;\n}\n\n.md-table-edit > span[class] button[class].btn {\n    margin: 0;\n    padding: 3px 8px 3px 8px;\n    border: 0;\n    border-radius: 0;\n    background: var(--table-edit-background);\n    color: var(--table-edit-color);\n    font-size: inherit;\n    line-height: 1.4;\n}\n\n.md-table-edit > span[class] button[class]:hover {\n    background: var(--table-edit-hover-background);\n    color: var(--table-edit-hover-color);\n}\n\n.md-table-edit > span[class] button[class].active,\n.md-table-edit button.active .ty-icon {\n    background: var(--table-edit-active-background);\n    color: var(--table-edit-active-color);\n    box-shadow: none;\n}\n\n.md-table-edit .md-table-more {\n    display: inline-block;\n}\n\n.md-table-edit .md-table-more .ty-icon {\n    margin: 0 3px !important;\n}\n\n.md-table-edit .md-table-more-label {\n    display: none !important;\n}\n\n/* Resize Popover */\n/* -------------------------------------------------------------------------- */\n.md-table-resize-popover[class] {\n    width: auto;\n    transform: translate(10px, 2px);\n    padding: 0;\n    border: 0;\n    background: var(--background-color);\n    box-shadow: none;\n    filter: var(--drop-shadow);\n}\n\n.md-table-resize-popover[class] .arrow,\n.md-table-resize-popover[class] .arrow::after {\n    border-bottom-color: var(--background-color);\n}\n\n.md-grid-board-wrap {\n    padding: 1rem;\n    border-radius: var(--border-radius);\n    background: var(--background-color);\n}\n\ntable.md-grid-board {\n    margin: auto;\n    border-spacing: 3px;\n}\n\ntable.md-grid-board td {\n    overflow: hidden;\n    border-radius: 2px;\n}\n\ntable.md-grid-board a {\n    border-color: var(--border-color);\n    background: var(--input-background);\n}\n\ntable.md-grid-board .md-grid-ext,\ntable.md-grid-board .md-grid-ext a {\n    border-color: var(--table-edit-active-background);\n    background: var(--table-edit-active-background);\n}\n\ntable.md-grid-board:hover .md-grid-ext,\ntable.md-grid-board:hover .md-grid-ext a {\n    border-color: var(--table-edit-hover-background);\n    background: var(--table-edit-hover-background);\n}\n\ntable.md-grid-board:hover a:hover,\ntable.md-grid-board:hover a.md-active {\n    background: var(--color-primary);\n    border-color: var(--color-primary);\n}\n\n.md-grid-board-wrap #md-grid-width,\n.md-grid-board-wrap #md-grid-height {\n    margin: 0 0.2rem;\n    border-color: var(--border-color);\n    border-radius: 2px;\n    background: var(--input-background);\n    line-height: 1.6;\n    text-align: center;\n}\n\n.md-grid-board-wrap .popover-title {\n    margin: 0.5rem 0 0 0;\n    padding: 0;\n    border: 0;\n}\n\n.md-grid-board-wrap .popover-title button {\n    display: none !important;\n}\n\n/* \"More\" context menu */\n/* -------------------------------------------------------------------------- */\n#table-menu {\n    width: 30ch;\n}\n","/* ========================================================================== */\n/* TOC\n/* ========================================================================== */\n.md-toc {\n    margin: 2rem 0;\n    font-size: var(--font-size-m);\n    line-height: var(--line-height);\n}\n\n.md-toc-content {\n    padding: 0;\n    margin: 0;\n}\n\n.md-toc:focus .md-toc-content {\n    border: unset;\n    margin: 0;\n}\n\n.md-toc-h1 .md-toc-inner {\n    margin-left: 0;\n    font-weight: var(--strong-font-weight);\n}\n\n.md-toc-h2 .md-toc-inner {\n    margin-left: 1em;\n}\n\n.md-toc-h3 .md-toc-inner {\n    margin-left: 2em;\n}\n\n.md-toc-h4 .md-toc-inner {\n    margin-left: 3em;\n}\n\n.md-toc-h5 .md-toc-inner {\n    margin-left: 4em;\n}\n\n.md-toc-h6 .md-toc-inner {\n    margin-left: 5em;\n}\n\n/* Edit bar (TOC, Tables) */\n/* -------------------------------------------------------------------------- */\n#write div.md-toc-tooltip {\n    inset: auto auto 100% -10px;\n    width: calc(100% + 20px);\n    padding: 0 8px;\n    border: 0;\n    border-radius: var(--border-radius);\n    background: var(--table-edit-background);\n    font-size: var(--font-size-s);\n    line-height: calc(var(--font-size-m) * var(--line-height));\n}\n\n.md-toc.md-focus .md-toc-tooltip,\n.md-toc:focus .md-toc-tooltip {\n    display: flex !important;\n    align-items: center;\n    justify-content: space-between;\n}\n","/* ========================================================================== */\n/* Mega Menu (Windows only)\n/* ========================================================================== */\n.megamenu-opened #w-traffic-lights {\n    background: var(--mono-50);\n    border-bottom-left-radius: var(--border-radius);\n    overflow: hidden;\n}\n\n.paint-border .megamenu-content {\n    border-color: var(--sidebar-border-color);\n}\n\n.megamenu-menu,\n.megamenu-opened .megamenu-menu {\n    transition: .2s;\n}\n\n.megamenu-menu {\n    border-right: var(--sidebar-border-width) solid var(--sidebar-border-color);\n    box-shadow: none;\n    background: var(--sidebar-background);\n    color: var(--sidebar-color);\n}\n\n/* Header */\n/* -------------------------------------------------------------------------- */\n.megamenu-menu-header {\n    border-bottom: var(--sidebar-border-width) solid var(--sidebar-border-color);\n}\n\n#megamenu-menu-header-title {\n    font-size: var(--font-size-ui-l);\n    color: inherit !important;\n}\n\n#megamenu-back-btn {\n    border-color: transparent;\n    color: var(--mono-300);\n    font-size: min(16px, calc(var(--font-size-ui-l) * 0.85));\n}\n\n.megamenu-menu-header:is(:focus, :hover) {\n    color: inherit;\n}\n\n.megamenu-menu-header:is(:focus,:hover) #megamenu-back-btn {\n    color: var(--color-primary);\n}\n\n.megamenu-menu-list {\n    background-color: transparent;\n    border: 0;\n    border-radius: none;\n}\n\n.megamenu-menu-list.dropdown-menu .divider {\n    background-color: var(--sidebar-border-color);\n    opacity: 1;\n}\n\n.megamenu-menu-list #m-saved .fa {\n    font-size: 1em;\n}\n\n.megamenu-menu-list #m-saved .fa::before {\n    content: \"\\f00c\";\n    color: var(--color-primary);\n}\n\n.megamenu-menu-list:not(.saved) li a:hover {\n    background-color: transparent;\n}\n\n.megamenu-menu-list li {\n    font-size: var(--font-size-ui);\n}\n\n.megamenu-menu-list li a.active,\n.megamenu-menu-list:not(.saved) li a:hover {\n    background-color: var(--item-hover-bg-color);\n    color: var(--item-hover-text-color)\n}\n\n.megamenu-opened header {\n    background: none !important;\n}\n\n/* Content */\n/* -------------------------------------------------------------------------- */\n.megamenu-content {\n    background: transparent;\n}\n\n.megamenu-opened > content {\n    opacity: 0.2;\n    filter: blur(10px);\n}\n\n#m-import-local:hover .preference-item-hint {\n    /* color: #999; */\n}\n\n.megamenu-menu-panel h1,\n.megamenu-menu-panel h2  {\n    line-height: 1;\n    font-weight: var(--strong-font-weight);\n}\n\n.megamenu-menu-panel h1 {\n    font-size: var(--font-size-ui-xl);\n}\n\n.megamenu-menu-panel h2 {\n    font-size: var(--font-size-ui-l);\n}\n\n.long-btn,\n.megamenu-menu-panel .btn,\n#recent-file-panel-action-btn {\n    background: var(--mono-100);\n    border: 1px solid var(--mono-300);\n}\n\n.long-btn:hover,\n.megamenu-menu-panel .btn:hover,\n#recent-file-panel-action-btn:hover {\n    background-color: var(--item-hover-bg-color);\n    color: var(--item-hover-text-color) !important;\n}\n\n.long-btn {\n    padding: 0.75em 1em;\n    border-radius: var(--border-radius);\n    font-size: inherit;\n}\n\n.megamenu-menu-panel table,\n.megamenu-menu-panel table :is(thead, tbody, tr, th, td) {\n    border-style: solid;\n}\n\n.megamenu-menu-panel table {\n    font-size: inherit !important;\n    font-weight: inherit;\n    letter-spacing: inherit;\n    line-height: inherit;\n}\n\n.megamenu-menu-panel table thead {\n    border-width: var(--thead-border-width, 0);\n    border-color: var(--thead-border-color);\n}\n\n.megamenu-menu-panel table tbody {\n    border-width: var(--tbody-border-width, 0);\n    border-color: var(--tbody-border-color);\n}\n\n.megamenu-menu-panel table tbody tr {\n    border-width: var(--tr-border-width, 0);\n    border-color: var(--tr-border-color);\n    background: transparent !important;\n}\n\n.megamenu-menu-panel table tbody tr:nth-child(even) {\n    background: var(--tr-alt-background) !important;\n}\n\n.megamenu-menu-panel table tr th {\n    padding: var(--th-padding);\n    border-width: var(--th-border-width, 0);\n    border-color: var(--th-border-color);\n    font-weight: var(--th-font-weight);\n    color: var(--th-color)\n}\n\n.megamenu-menu-panel table tr td {\n    padding: var(--td-padding);\n    border-width: var(--td-border-width, 0);\n    border-color: var(--td-border-color);\n}\n\n#recent-file-panel {\n    font-size: inherit;\n}\n\n#recent-document-table {\n    margin-top: 1.5em !important;\n}\n\n@media (max-width: 530px) {\n    .megamenu-menu-header #megamenu-menu-header-title {\n        display: none;\n    }\n\n    .megamenu-menu-list li a {\n        font-size: 24px;\n    }\n\n    .megamenu-menu-list li a.active {\n        background-color: var(--item-hover-bg-color);\n        color: inherit;\n    }\n}\n\n/* Modals */\n/* -------------------------------------------------------------------------- */\n.error-dialog .modal-header {\n    /* border-left: 8px #d9534f solid; */\n}\n\n.modal-open .modal.fade.in {\n    /* background-color: rgba(0, 0, 0, .1) */\n}\n\n.megamenu-opened.modal-open .modal.fade.in {\n    /* background-color: rgba(0, 0, 0, .35) */\n}\n\n/* About */\n/* -------------------------------------------------------------------------- */\n#about-content-license-button {\n    border-radius: var(--border-radius);\n    font-size: inherit;\n}\n\n.about-content-slogon {\n    font-family: var(--font-family);\n    letter-spacing: normal;\n    color: var(--color-secondary);\n}\n\n.about-content-hint {\n    font-size: inherit;\n    /* opacity: .6; */\n}\n\n.about-content-meta {\n    /* opacity: .8; */\n    font-size: inherit;\n    font-family: var(--font-family-mono);\n}\n\n/* Theme Thumbnails */\n/* -------------------------------------------------------------------------- */\n.theme-preview-content {\n    border-radius: var(--border-radius);\n    border: none\n}\n\n.theme-preview-div {\n    --border-width: 4px;\n\n    border: var(--border-width) solid var(--mono-200);\n    color: var(--side-bar-menu-active-tint);\n    border-radius: calc(var(--border-radius) + var(--border-width));\n}\n\n.theme-preview-div:hover {\n    border-color: var(--color-primary);\n}\n\n.theme-preview-div.active,\n.theme-preview-div.active:hover {\n    border-color: var(--color-primary);\n}\n\n.theme-preview-div .fa {\n    bottom: 8px;\n    left: auto;\n    right: 8px;\n    padding: 0.25em;\n    border-radius: 50%;\n    background: var(--color-primary);\n    color: #fff;\n    font-size: 125%;\n}\n\n.theme-preview-div .fa::before {\n    content: \"\\f00c\";\n}\n"]} */


mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
  min-height: 1px;
  min-width: 1px;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-assistive-mml {
  position: absolute !important;
  top: 0px;
  left: 0px;
  clip: rect(1px, 1px, 1px, 1px);
  padding: 1px 0px 0px 0px !important;
  border: 0px !important;
  display: block !important;
  width: auto !important;
  overflow: hidden !important;
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

mjx-assistive-mml[display="block"] {
  width: 100% !important;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][display="true"][width="full"] {
  display: flex;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line], svg[data-table] > g > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > g > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

mjx-container[jax="SVG2"] path[data-c], mjx-container[jax="SVG2"] use[data-c] {
  stroke-width: 3;
}

g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}

.MathJax g[data-mml-node="xypic"] path {
  stroke-width: inherit;
}
mjx-container[jax="SVG"] path[data-c], mjx-container[jax="SVG"] use[data-c] {
							stroke-width: 0;
						}
</style><title>SAA-C03 Preparation - Questions, answers and explanations 201-400 Nov. 2024</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><h2 id='saa-c03-preparation---questions-answers-and-explanations-201-400-nov-2024'><span>SAA-C03 Preparation - Questions, answers and explanations 201-400 Nov. 2024</span></h2><p>&nbsp;</p><h3 id='prompt'><strong><span>Prompt:</span></strong></h3><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang=""><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang=""><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 32.5px; left: 26.5px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Correct the spellings and grammar. Summarize the question in a few words.</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">Print out the q and a, and explanation format </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">----------------------------------------</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 165px;"></div><div class="CodeMirror-gutters" style="display: none; height: 165px;"></div></div></div></pre><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang=""><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang=""><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 32.5px; left: 26.5px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> Q 2 is as follows. Make sure your one-sentence summary is correct:</span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 69px;"></div><div class="CodeMirror-gutters" style="display: none; height: 69px;"></div></div></div></pre><hr /><p>&nbsp;</p><h2 id='questions-201-300'><span>Questions 201-300</span></h2><hr /><h3 id='question-201-develop-a-marketing-communications-service-that-sends-sms-messages-and-stores-responses-for-a-year'><span>Question #201 Develop a marketing communications service that sends SMS messages and stores responses for a year</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is developing a marketing communications service that targets mobile app users. The company needs to send confirmation messages with Short Message Service (SMS) to its users. The users must be able to reply to the SMS messages. The company must store the responses for a year for analysis. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Create an Amazon Connect contact flow to send the SMS messages. Use AWS Lambda to process the responses.</span></p><p><span>B. Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.</span></p><p><span>C. Use Amazon Simple Queue Service (Amazon SQS) to distribute the SMS messages. Use AWS Lambda to process the responses.</span></p><p><span>D. Create an Amazon Simple Notification Service (Amazon SNS) FIFO topic. Subscribe an Amazon Kinesis data stream to the SNS topic for analysis and archiving.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Pinpoint</span></strong><span>: Amazon Pinpoint is a flexible and scalable outbound and inbound marketing communications service. It can send SMS messages, track user responses, and integrate with other AWS services for further processing and analysis.</span></p></li><li><p><strong><span>Amazon Kinesis Data Stream</span></strong><span>: By configuring Amazon Pinpoint to send events to an Amazon Kinesis data stream, the company can capture and store the responses for a year. Kinesis provides a reliable and scalable way to collect, process, and analyze real-time data streams.</span></p></li></ol><p><span>Other solutions have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon Connect</span></strong><span>: While Amazon Connect can send SMS messages, it is primarily designed for contact center solutions and may not be the best fit for marketing communications.</span></p><p><span>C. </span><strong><span>Amazon SQS</span></strong><span>: SQS is a message queuing service that can distribute messages but does not inherently support the sending of SMS messages or the long-term storage required for analysis.</span></p><p><span>D. </span><strong><span>Amazon SNS FIFO Topic</span></strong><span>: SNS can send SMS messages, but it does not provide the built-in capabilities for tracking responses and storing them for analysis like Amazon Pinpoint does.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-202-data-encryption-and-key-rotation-for-amazon-s3'><span>Question #202 Data encryption and key rotation for Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is planning to move its data to an Amazon S3 bucket. The data must be encrypted when it is stored in the S3 bucket. Additionally, the encryption key must be automatically rotated every year. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Move the data to the S3 bucket. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use the built-in key rotation behavior of SSE-S3 encryption keys.</span></p><p><span>B. Create an AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket&#39;s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket.</span></p><p><span>C. Create an AWS Key Management Service (AWS KMS) customer managed key. Set the S3 bucket&#39;s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket. Manually rotate the KMS key every year.</span></p><p><span>D. Encrypt the data with customer key material before moving the data to the S3 bucket. Create an AWS Key Management Service (AWS KMS) key without key material. Import the customer key material into the KMS key. Enable automatic key rotation.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create an AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket&#39;s default encryption behavior to use the customer managed KMS key. Move the data to the S3 bucket.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS KMS Customer Managed Key</span></strong><span>: By using an AWS KMS customer managed key, you can have full control over the encryption keys. This includes enabling automatic key rotation, which ensures that the encryption keys are rotated every year without manual intervention.</span></p></li><li><p><strong><span>Automatic Key Rotation</span></strong><span>: Enabling automatic key rotation for the KMS key minimizes operational overhead as it removes the need for manual key rotation.</span></p></li><li><p><strong><span>Default Encryption Behavior</span></strong><span>: Setting the S3 bucket&#39;s default encryption behavior to use the customer managed KMS key ensures that all data stored in the S3 bucket is encrypted using the specified key.</span></p></li></ol><p><span>The other solutions have the following drawbacks:</span></p><p><span>A. </span><strong><span>SSE-S3 Managed Keys</span></strong><span>: While SSE-S3 provides built-in key management, it does not offer the same level of control and flexibility as AWS KMS customer managed keys. Additionally, SSE-S3 does not support automatic key rotation.</span></p><p><span>C. </span><strong><span>Manual Key Rotation</span></strong><span>: Manually rotating the KMS key every year increases operational overhead and the risk of human error.</span></p><p><span>D. </span><strong><span>Customer Key Material</span></strong><span>: Importing customer key material and enabling automatic key rotation adds unnecessary complexity compared to using AWS KMS managed keys with automatic rotation.</span></p><p>&nbsp;</p><hr /><h3 id='question-203-improve-the-performance-of-sending-meeting-invitations-for-a-finance-company'><span>Question #203 Improve the performance of sending meeting invitations for a finance company</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>The customers of a finance company request appointments with financial advisors by sending text messages. A web application that runs on Amazon EC2 instances accepts the appointment requests. The text messages are published to an Amazon Simple Queue Service (Amazon SQS) queue through the web application. Another application that runs on EC2 instances then sends meeting invitations and meeting confirmation email messages to the customers. After successful scheduling, this application stores the meeting information in an Amazon DynamoDB database. As the company expands, customers report that their meeting invitations are taking longer to arrive. What should a solutions architect recommend to resolve this issue?</span></p><p><span>A. Add a DynamoDB Accelerator (DAX) cluster in front of the DynamoDB database.</span></p><p><span>B. Add an Amazon API Gateway API in front of the web application that accepts the appointment requests.</span></p><p><span>C. Add an Amazon CloudFront distribution. Set the origin as the web application that accepts the appointment requests.</span></p><p><span>D. Add an Auto Scaling group for the application that sends meeting invitations. Configure the Auto Scaling group to scale based on the depth of the SQS queue.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Add an Auto Scaling group for the application that sends meeting invitations. Configure the Auto Scaling group to scale based on the depth of the SQS queue.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Auto Scaling Group</span></strong><span>: By adding an Auto Scaling group for the application that sends meeting invitations, the system can dynamically adjust the number of EC2 instances based on the depth of the SQS queue. This ensures that there are enough resources to handle the increased load as the company expands, thereby reducing the delay in sending meeting invitations.</span></p></li><li><p><strong><span>SQS Queue Depth</span></strong><span>: Scaling based on the depth of the SQS queue allows the system to respond to increased demand by automatically adding more instances when the queue grows and reducing instances when the queue shrinks. This helps in maintaining a consistent performance and timely processing of appointment requests.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>DynamoDB Accelerator (DAX)</span></strong><span>: DAX is used to accelerate read performance for DynamoDB but does not address the issue of delays in sending meeting invitations.</span></p><p><span>B. </span><strong><span>Amazon API Gateway</span></strong><span>: Adding an API Gateway in front of the web application does not directly address the issue of processing delays in sending meeting invitations.</span></p><p><span>C. </span><strong><span>Amazon CloudFront</span></strong><span>: CloudFront is used for content delivery and caching, which does not solve the problem of delayed processing of meeting invitations.</span></p><p>&nbsp;</p><hr /><h3 id='question-204-data-management-and-analytics-for-an-online-retail-company'><span>Question #204 Data management and analytics for an online retail company</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An online retail company has more than 50 million active customers and receives more than 25,000 orders each day. The company collects purchase data for customers and stores this data in Amazon S3. Additional customer data is stored in Amazon RDS. The company wants to make all the data available to various teams so that the teams can perform analytics. The solution must provide the ability to manage fine-grained permissions for the data and must minimize operational overhead. Which solution will meet these requirements?</span></p><p><span>A. Migrate the purchase data to write directly to Amazon RDS. Use RDS access controls to limit access.</span></p><p><span>B. Schedule an AWS Lambda function to periodically copy data from Amazon RDS to Amazon S3. Create an AWS Glue crawler. Use Amazon Athena to query the data. Use S3 policies to limit access.</span></p><p><span>C. Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.</span></p><p><span>D. Create an Amazon Redshift cluster. Schedule an AWS Lambda function to periodically copy data from Amazon S3 and Amazon RDS to Amazon Redshift. Use Amazon Redshift access controls to limit access.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Lake Formation</span></strong><span>: Lake Formation simplifies the process of setting up a secure data lake in days. It allows you to manage and secure your data, including fine-grained access controls, which are essential for providing data access to various teams while maintaining data security.</span></p></li><li><p><strong><span>AWS Glue JDBC Connection</span></strong><span>: By creating an AWS Glue JDBC connection to Amazon RDS, you can easily integrate RDS data into the data lake, making it accessible for analytics.</span></p></li><li><p><strong><span>Registering S3 Bucket in Lake Formation</span></strong><span>: Registering the S3 bucket in Lake Formation ensures that all purchase data stored in S3 is included in the data lake and can be managed and accessed through Lake Formation.</span></p></li><li><p><strong><span>Fine-Grained Access Controls</span></strong><span>: Lake Formation provides fine-grained access controls, allowing you to set permissions at the column, row, and table levels. This meets the requirement for managing fine-grained permissions for the data.</span></p></li></ol><p><span>The other solutions have the following drawbacks:</span></p><p><span>A. </span><strong><span>Migrating Data to RDS</span></strong><span>: This approach increases the complexity and operational overhead by consolidating all data into RDS, which is not optimized for large-scale analytics.</span></p><p><span>B. </span><strong><span>Periodic Copy and Athena</span></strong><span>: While this solution allows for querying data using Athena, it does not provide fine-grained access controls as effectively as Lake Formation.</span></p><p><span>D. </span><strong><span>Amazon Redshift</span></strong><span>: Although Redshift is suitable for large-scale data warehousing and analytics, it does not offer the same level of fine-grained access control as Lake Formation and involves more operational overhead in managing the data transfer and integration.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-205-host-a-marketing-website-on-aws-using-amazon-cloudfront'><span>Question #205 Host a marketing website on AWS using Amazon CloudFront</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a marketing website in an on-premises data center. The website consists of static documents and runs on a single server. An administrator updates the website content infrequently and uses an SFTP client to upload new documents. The company decides to host its website on AWS and to use Amazon CloudFront. The company&#39;s solutions architect creates a CloudFront distribution. The solutions architect must design the most cost-effective and resilient architecture for website hosting to serve as the CloudFront origin. Which solution will meet these requirements?</span></p><p><span>A. Create a virtual server by using Amazon Lightsail. Configure the web server in the Lightsail instance. Upload website content by using an SFTP client.</span></p><p><span>B. Create an AWS Auto Scaling group for Amazon EC2 instances. Use an Application Load Balancer. Upload website content by using an SFTP client.</span></p><p><span>C. Create a private Amazon S3 bucket. Use an S3 bucket policy to allow access from a CloudFront origin access identity (OAI). Upload website content by using the AWS CLI.</span></p><p><span>D. Create a public Amazon S3 bucket. Configure AWS Transfer for SFTP. Configure the S3 bucket for website hosting. Upload website content by using the SFTP client.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create a private Amazon S3 bucket. Use an S3 bucket policy to allow access from a CloudFront origin access identity (OAI). Upload website content by using the AWS CLI.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3</span></strong><span>: Using an Amazon S3 bucket to host the static website content is cost-effective and highly resilient. S3 provides high availability and durability for storing static documents.</span></p></li><li><p><strong><span>CloudFront Origin Access Identity (OAI)</span></strong><span>: By creating a private S3 bucket and using an S3 bucket policy to allow access from a CloudFront OAI, you ensure that the content is securely served through CloudFront without making the S3 bucket publicly accessible.</span></p></li><li><p><strong><span>AWS CLI for Uploads</span></strong><span>: Using the AWS CLI to upload website content to the S3 bucket is efficient and integrates well with the existing workflow of the administrator.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon Lightsail</span></strong><span>: While Lightsail can be used to host the website, it is not as cost-effective or resilient as using S3 for static content.</span></p><p><span>B. </span><strong><span>Auto Scaling Group and Load Balancer</span></strong><span>: This setup is more complex and costly than necessary for hosting static content.</span></p><p><span>D. </span><strong><span>Public S3 Bucket with AWS Transfer for SFTP</span></strong><span>: Making the S3 bucket public is not as secure as using a private bucket with OAI. Additionally, AWS Transfer for SFTP adds unnecessary complexity and cost compared to using the AWS CLI for uploads.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-206-managing-and-alerting-on-ami-creation'><span>Question #206 Managing and alerting on AMI creation</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to manage Amazon Machine Images (AMIs). The company currently copies AMIs to the same AWS Region where the AMIs were created. The company needs to design an application that captures AWS API calls and sends alerts whenever the Amazon EC2 CreateImage API operation is called within the company&#39;s account. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Create an AWS Lambda function to query AWS CloudTrail logs and to send an alert when a CreateImage API call is detected.</span></p><p><span>B. Configure AWS CloudTrail with an Amazon Simple Notification Service (Amazon SNS) notification that occurs when updated logs are sent to Amazon S3. Use Amazon Athena to create a new table and to query on CreateImage when an API call is detected.</span></p><p><span>C. Create an Amazon EventBridge (Amazon CloudWatch Events) rule for the CreateImage API call. Configure the target as an Amazon Simple Notification Service (Amazon SNS) topic to send an alert when a CreateImage API call is detected.</span></p><p><span>D. Configure an Amazon Simple Queue Service (Amazon SQS) FIFO queue as a target for AWS CloudTrail logs. Create an AWS Lambda function to send an alert to an Amazon Simple Notification Service (Amazon SNS) topic when a CreateImage API call is detected.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create an Amazon EventBridge (Amazon CloudWatch Events) rule for the CreateImage API call. Configure the target as an Amazon Simple Notification Service (Amazon SNS) topic to send an alert when a CreateImage API call is detected.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon EventBridge (Amazon CloudWatch Events)</span></strong><span>: EventBridge allows you to create rules that can trigger actions based on specific AWS API calls. By setting up a rule for the CreateImage API call, you can automatically detect when this API is called.</span></p></li><li><p><strong><span>Amazon SNS</span></strong><span>: Configuring the target as an SNS topic allows you to send alerts easily. SNS provides a simple way to send notifications to various endpoints such as email, SMS, or other AWS services.</span></p></li><li><p><strong><span>Least Operational Overhead</span></strong><span>: This solution is straightforward and requires minimal setup and maintenance. EventBridge directly integrates with AWS services and provides a seamless way to capture and respond to specific events.</span></p></li></ol><p><span>The other solutions have the following drawbacks:</span></p><p><span>A. </span><strong><span>Lambda Function with CloudTrail</span></strong><span>: This approach involves querying CloudTrail logs, which adds complexity and increases operational overhead compared to using EventBridge rules.</span></p><p><span>B. </span><strong><span>CloudTrail with Athena</span></strong><span>: While this method can achieve the desired outcome, it involves setting up and maintaining Athena queries, which is more complex and less efficient than using EventBridge.</span></p><p><span>D. </span><strong><span>SQS with Lambda</span></strong><span>: This solution introduces additional components (SQS and Lambda) that increase operational overhead and complexity compared to the direct integration provided by EventBridge and SNS.</span></p><p>&nbsp;</p><hr /><h3 id='question-207-improve-the-reliability-of-an-asynchronous-api-using-amazon-dynamodb'><span>Question #207 Improve the reliability of an asynchronous API using Amazon DynamoDB</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company owns an asynchronous API that is used to ingest user requests and, based on the request type, dispatch requests to the appropriate microservice for processing. The company is using Amazon API Gateway to deploy the API front end, and an AWS Lambda function that invokes Amazon DynamoDB to store user requests before dispatching them to the processing microservices. The company provisioned as much DynamoDB throughput as its budget allows, but the company is still experiencing availability issues and is losing user requests. What should a solutions architect do to address this issue without impacting existing users?</span></p><p><span>A. Add throttling on the API Gateway with server-side throttling limits.</span></p><p><span>B. Use DynamoDB Accelerator (DAX) and Lambda to buffer writes to DynamoDB.</span></p><p><span>C. Create a secondary index in DynamoDB for the table with the user requests.</span></p><p><span>D. Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use the Amazon Simple Queue Service (Amazon SQS) queue and Lambda to buffer writes to DynamoDB.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SQS for Buffering</span></strong><span>: By using Amazon SQS to buffer writes to DynamoDB, you can decouple the ingestion of user requests from the processing of those requests. This helps to handle spikes in traffic and ensures that user requests are not lost even if DynamoDB is temporarily unable to handle the load.</span></p></li><li><p><strong><span>Lambda for Processing</span></strong><span>: AWS Lambda can be used to poll the SQS queue and write the requests to DynamoDB at a controlled rate. This approach smooths out the write operations to DynamoDB, preventing it from being overwhelmed and reducing the likelihood of availability issues.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Throttling on API Gateway</span></strong><span>: Adding throttling limits on the API Gateway can prevent the API from being overwhelmed, but it does not address the root cause of the issue, which is DynamoDB&#39;s inability to handle the write throughput.</span></p><p><span>B. </span><strong><span>DynamoDB Accelerator (DAX)</span></strong><span>: DAX is used to accelerate read performance, not write performance. It would not help in buffering writes to DynamoDB.</span></p><p><span>C. </span><strong><span>Secondary Index in DynamoDB</span></strong><span>: Creating a secondary index can improve query performance but does not directly address the issue of write throughput and availability.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-208-secure-data-transfer-from-ec2-to-s3'><span>Question #208 Secure data transfer from EC2 to S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs to move data from an Amazon EC2 instance to an Amazon S3 bucket. The company must ensure that no API calls and no data are routed through public internet routes. Only the EC2 instance can have access to upload data to the S3 bucket. Which solution will meet these requirements?</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance&#39;s IAM role for access.</span></p><p><span>B. Create a gateway VPC endpoint for Amazon S3 in the Availability Zone where the EC2 instance is located. Attach appropriate security groups to the endpoint. Attach a resource policy to the S3 bucket to only allow the EC2 instance&#39;s IAM role for access.</span></p><p><span>C. Run the nslookup tool from inside the EC2 instance to obtain the private IP address of the S3 bucket&#39;s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance&#39;s IAM role for access.</span></p><p><span>D. Use the AWS provided, publicly available ip-ranges.json file to obtain the private IP address of the S3 bucket&#39;s service API endpoint. Create a route in the VPC route table to provide the EC2 instance with access to the S3 bucket. Attach a resource policy to the S3 bucket to only allow the EC2 instance&#39;s IAM role for access.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>A. Create an interface VPC endpoint for Amazon S3 in the subnet where the EC2 instance is located. Attach a resource policy to the S3 bucket to only allow the EC2 instance&#39;s IAM role for access.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Interface VPC Endpoint (Option A)</span></strong><span>: Creating an interface VPC endpoint for Amazon S3 ensures that all traffic between the EC2 instance and the S3 bucket remains within the AWS network, without traversing the public internet. This provides secure, private connectivity. Additionally, attaching a resource policy to the S3 bucket that only allows access from the EC2 instance&#39;s IAM role ensures that only the specified EC2 instance can upload data to the S3 bucket.</span></p></li><li><p><strong><span>Gateway VPC Endpoint (Option B)</span></strong><span>: While creating a gateway VPC endpoint for Amazon S3 is a valid solution, interface VPC endpoints are more specific to the subnet and can provide more granular control over the traffic.</span></p></li></ol><p><span>The other solutions have the following drawbacks:</span></p><p><span>C. </span><strong><span>Using nslookup Tool</span></strong><span>: This method is not feasible as it does not provide a secure or reliable way to ensure private connectivity to the S3 bucket.</span></p><p><span>D. </span><strong><span>Using ip-ranges.json File</span></strong><span>: This approach is not recommended as it involves manually managing IP addresses, which can change and lead to potential connectivity issues. It also does not ensure that the traffic remains within the private AWS network.</span></p><p>&nbsp;</p><hr /><h3 id='question-209-support-distributed-session-data-management-for-an-application-on-aws'><span>Question #209 Support distributed session data management for an application on AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect is designing the architecture of a new application being deployed to the AWS Cloud. The application will run on Amazon EC2 On-Demand Instances and will automatically scale across multiple Availability Zones. The EC2 instances will scale up and down frequently throughout the day. An Application Load Balancer (ALB) will handle the load distribution. The architecture needs to support distributed session data management. The company is willing to make changes to code if needed. What should the solutions architect do to ensure that the architecture supports distributed session data management?</span></p><p><span>A. Use Amazon ElastiCache to manage and store session data.</span></p><p><span>B. Use session affinity (sticky sessions) of the ALB to manage session data.</span></p><p><span>C. Use Session Manager from AWS Systems Manager to manage the session.</span></p><p><span>D. Use the GetSessionToken API operation in AWS Security Token Service (AWS STS) to manage the session.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use Amazon ElastiCache to manage and store session data.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon ElastiCache</span></strong><span>: ElastiCache is a managed in-memory caching service that can be used to store session data. By using ElastiCache (with Redis or Memcached), you can ensure that session data is stored in a centralized location, which supports distributed session management across multiple EC2 instances and Availability Zones. This approach is highly scalable and can handle frequent scaling of EC2 instances without losing session data.</span></p></li><li><p><strong><span>Distributed Session Management</span></strong><span>: Storing session data in ElastiCache allows any instance in the auto-scaling group to access the session data, ensuring that the application can scale horizontally without session data loss or inconsistency.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Session Affinity (Sticky Sessions)</span></strong><span>: While sticky sessions can help maintain session data on the same instance, they do not support distributed session management effectively in a highly dynamic scaling environment. Sticky sessions can lead to uneven load distribution and do not work well when instances are frequently added or removed.</span></p><p><span>C. </span><strong><span>Session Manager from AWS Systems Manager</span></strong><span>: Session Manager is used for managing and accessing EC2 instances and does not provide a solution for managing application session data.</span></p><p><span>D. </span><strong><span>GetSessionToken API in AWS STS</span></strong><span>: The GetSessionToken API is used for temporary security credentials and is not designed for managing application session data.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-210-scaling-order-processing-for-a-food-delivery-service'><span>Question #210 Scaling order processing for a food delivery service</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company offers a food delivery service that is growing rapidly. Because of the growth, the company&#39;s order processing system is experiencing scaling problems during peak traffic hours. The current architecture includes the following:</span></p><ul><li><p><span>A group of Amazon EC2 instances that run in an Amazon EC2 Auto Scaling group to collect orders from the application</span></p></li><li><p><span>Another group of EC2 instances that run in an Amazon EC2 Auto Scaling group to fulfill orders</span></p></li></ul><p><span>The order collection process occurs quickly, but the order fulfillment process can take longer. Data must not be lost because of a scaling event. A solutions architect must ensure that the order collection process and the order fulfillment process can both scale properly during peak traffic hours. The solution must optimize utilization of the company&#39;s AWS resources. Which solution meets these requirements?</span></p><p><span>A. Use Amazon CloudWatch metrics to monitor the CPU of each instance in the Auto Scaling groups. Configure each Auto Scaling group&#39;s minimum capacity according to peak workload values.</span></p><p><span>B. Use Amazon CloudWatch metrics to monitor the CPU of each instance in the Auto Scaling groups. Configure a CloudWatch alarm to invoke an Amazon Simple Notification Service (Amazon SNS) topic that creates additional Auto Scaling groups on demand.</span></p><p><span>C. Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Scale the Auto Scaling groups based on notifications that the queues send.</span></p><p><span>D. Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Create a metric based on a backlog per instance calculation. Scale the Auto Scaling groups based on this metric.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Provision two Amazon Simple Queue Service (Amazon SQS) queues: one for order collection and another for order fulfillment. Configure the EC2 instances to poll their respective queue. Create a metric based on a backlog per instance calculation. Scale the Auto Scaling groups based on this metric.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SQS Queues</span></strong><span>: Using SQS queues ensures that no data is lost during scaling events. One queue is used for order collection and another for order fulfillment, decoupling the two processes and allowing them to scale independently.</span></p></li><li><p><strong><span>Polling Queues</span></strong><span>: Configuring the EC2 instances to poll their respective queues ensures that they can handle the workload dynamically based on the number of messages in the queue.</span></p></li><li><p><strong><span>Backlog Per Instance Metric</span></strong><span>: Creating a metric based on the backlog per instance calculation allows the Auto Scaling groups to scale based on the actual workload. This helps in optimizing resource utilization by scaling out when there is a high number of messages in the queue and scaling in when the backlog is reduced.</span></p></li></ol><p><span>The other solutions have the following drawbacks:</span></p><p><span>A. </span><strong><span>Minimum Capacity Based on Peak Workload</span></strong><span>: This approach does not dynamically adjust to changing traffic patterns and can lead to over-provisioning during non-peak hours.</span></p><p><span>B. </span><strong><span>Creating Additional Auto Scaling Groups on Demand</span></strong><span>: This adds unnecessary complexity and does not efficiently address the need for dynamic scaling based on the workload.</span></p><p><span>C. </span><strong><span>Scaling Based on Notifications</span></strong><span>: While this approach uses SQS queues, it lacks the granularity and efficiency provided by scaling based on a backlog per instance calculation.</span></p><p>&nbsp;</p><hr /><h3 id='question-211-identify-all-tagged-components-across-multiple-aws-regions'><span>Question #211 Identify all tagged components across multiple AWS Regions</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts multiple production applications. One of the applications consists of resources from Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service (Amazon SNS), and Amazon Simple Queue Service (Amazon SQS) across multiple AWS Regions. All company resources are tagged with a tag name of &quot;application&quot; and a value that corresponds to each application. A solutions architect must provide the quickest solution for identifying all of the tagged components. Which solution meets these requirements?</span></p><p><span>A. Use AWS CloudTrail to generate a list of resources with the application tag.</span></p><p><span>B. Use the AWS CLI to query each service across all Regions to report the tagged components.</span></p><p><span>C. Run a query in Amazon CloudWatch Logs Insights to report on the components with the application tag.</span></p><p><span>D. Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Run a query with the AWS Resource Groups Tag Editor to report on the resources globally with the application tag.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Resource Groups Tag Editor</span></strong><span>: The AWS Resource Groups Tag Editor is designed to help you manage tags for your AWS resources across multiple services and Regions. It provides a centralized interface to search, edit, and manage tags for your resources. By running a query with the Tag Editor, you can quickly identify all resources tagged with a specific tag name and value, such as &quot;application&quot;.</span></p></li><li><p><strong><span>Global Search Capability</span></strong><span>: The Tag Editor allows you to perform a global search, making it the quickest and most efficient solution to identify all tagged components across multiple AWS Regions and services.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS CloudTrail</span></strong><span>: CloudTrail logs API calls and events within your AWS account but is not designed for querying and reporting on tagged resources.</span></p><p><span>B. </span><strong><span>AWS CLI</span></strong><span>: Using the AWS CLI to query each service across all Regions would be time-consuming and complex, as it requires manual scripting and handling of multiple API calls.</span></p><p><span>C. </span><strong><span>Amazon CloudWatch Logs Insights</span></strong><span>: CloudWatch Logs Insights is used for querying log data, but it is not intended for querying and reporting on tagged resources across multiple services and Regions.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-212-cost-effective-s3-storage-for-variable-access-pattern'><span>Question #212 Cost-effective S3 storage for variable access pattern</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs to export its database once a day to Amazon S3 for other teams to access. The exported object size varies between 2 GB and 5 GB. The S3 access pattern for the data is variable and changes rapidly. The data must be immediately available and must remain accessible for up to 3 months. The company needs the most cost-effective solution that will not increase retrieval time. Which S3 storage class should the company use to meet these requirements?</span></p><p><span>A. S3 Intelligent-Tiering</span></p><p><span>B. S3 Glacier Instant Retrieval</span></p><p><span>C. S3 Standard</span></p><p><span>D. S3 Standard-Infrequent Access (S3 Standard-IA)</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. S3 Intelligent-Tiering</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>S3 Intelligent-Tiering</span></strong><span>: This storage class is designed to optimize costs by automatically moving data between two access tiers (frequent and infrequent) when access patterns change. It is ideal for data with unpredictable access patterns, as it ensures that data is always immediately available while minimizing storage costs.</span></p></li><li><p><strong><span>Immediate Availability</span></strong><span>: S3 Intelligent-Tiering provides immediate access to data, which is crucial for the company&#39;s requirement to have the data available immediately.</span></p></li><li><p><strong><span>Cost Optimization</span></strong><span>: By automatically moving data between access tiers based on changing access patterns, S3 Intelligent-Tiering helps in reducing costs without increasing retrieval times.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>S3 Glacier Instant Retrieval</span></strong><span>: While this provides low-cost storage with instant retrieval, it is typically used for archival data that is rarely accessed. It may not be suitable for data with rapidly changing access patterns.</span></p><p><span>C. </span><strong><span>S3 Standard</span></strong><span>: Although it provides immediate access and high availability, it is more expensive compared to S3 Intelligent-Tiering for data with variable access patterns.</span></p><p><span>D. </span><strong><span>S3 Standard-Infrequent Access (S3 Standard-IA)</span></strong><span>: This is cost-effective for data that is accessed less frequently, but it incurs retrieval charges and may not be suitable for data with rapidly changing access patterns. Additionally, it requires a minimum storage duration of 30 days.</span></p><p>&nbsp;</p><hr /><h3 id='question-213-implement-traffic-filtering-to-protect-an-application-load-balancer-alb-against-common-attacks'><span>Question #213 Implement traffic filtering to protect an Application Load Balancer (ALB) against common attacks</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is developing a new mobile app. The company must implement proper traffic filtering to protect its Application Load Balancer (ALB) against common application-level attacks, such as cross-site scripting or SQL injection. The company has minimal infrastructure and operational staff. The company needs to reduce its share of the responsibility in managing, updating, and securing servers for its AWS environment. What should a solutions architect recommend to meet these requirements?</span></p><p><span>A. Configure AWS WAF rules and associate them with the ALB.</span></p><p><span>B. Deploy the application using Amazon S3 with public hosting enabled.</span></p><p><span>C. Deploy AWS Shield Advanced and add the ALB as a protected resource.</span></p><p><span>D. Create a new ALB that directs traffic to an Amazon EC2 instance running a third-party firewall, which then passes the traffic to the current ALB.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Configure AWS WAF rules and associate them with the ALB.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS WAF (Web Application Firewall)</span></strong><span>: AWS WAF is a managed service that helps protect web applications from common web exploits such as cross-site scripting (XSS) and SQL injection. By configuring AWS WAF rules and associating them with the ALB, the company can efficiently filter and block malicious traffic at the application layer without the need for extensive infrastructure management.</span></p></li><li><p><strong><span>Minimal Infrastructure and Operational Staff</span></strong><span>: AWS WAF is a managed service that reduces the operational burden on the company by automatically handling updates and maintenance. This aligns with the company&#39;s requirement to minimize infrastructure management and operational overhead.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Amazon S3 with Public Hosting</span></strong><span>: While S3 can host static websites, it does not provide the necessary application-level traffic filtering capabilities required to protect against XSS or SQL injection attacks.</span></p><p><span>C. </span><strong><span>AWS Shield Advanced</span></strong><span>: AWS Shield Advanced provides protection against DDoS attacks but does not specifically address application-level attacks such as XSS or SQL injection.</span></p><p><span>D. </span><strong><span>Third-Party Firewall on EC2</span></strong><span>: Deploying a third-party firewall on an EC2 instance adds complexity and operational overhead, which goes against the company&#39;s need to reduce its share of responsibility in managing and securing servers.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-214-converting-csv-files-to-apache-parquet-format-with-minimal-development-effort'><span>Question #214 Converting .csv files to Apache Parquet format with minimal development effort</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company&#39;s reporting system delivers hundreds of .csv files to an Amazon S3 bucket each day. The company must convert these files to Apache Parquet format and must store the files in a transformed data bucket. Which solution will meet these requirements with the LEAST development effort?</span></p><p><span>A. Create an Amazon EMR cluster with Apache Spark installed. Write a Spark application to transform the data. Use EMR File System (EMRFS) to write files to the transformed data bucket.</span></p><p><span>B. Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step.</span></p><p><span>C. Use AWS Batch to create a job definition with Bash syntax to transform the data and output the data to the transformed data bucket. Use the job definition to submit a job. Specify an array job as the job type.</span></p><p><span>D. Create an AWS Lambda function to transform the data and output the data to the transformed data bucket. Configure an event notification for the S3 bucket. Specify the Lambda function as the destination for the event notification.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create an AWS Glue crawler to discover the data. Create an AWS Glue extract, transform, and load (ETL) job to transform the data. Specify the transformed data bucket in the output step.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Glue</span></strong><span>: AWS Glue is a fully managed ETL (extract, transform, and load) service that makes it easy to prepare and transform data for analytics. It provides a simple and efficient way to convert .csv files to Apache Parquet format with minimal development effort.</span></p></li><li><p><strong><span>Glue Crawler</span></strong><span>: The Glue crawler can automatically discover the schema of the .csv files and catalog the data. This reduces the need for manual schema definition.</span></p></li><li><p><strong><span>Glue ETL Job</span></strong><span>: AWS Glue ETL jobs can be used to transform the data from .csv to Parquet format. You can specify the transformed data bucket as the output destination, ensuring that the transformed files are stored appropriately.</span></p></li></ol><p><span>The other solutions have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon EMR with Apache Spark</span></strong><span>: While EMR with Spark can handle the transformation, it requires more development effort to write and manage the Spark application and the EMR cluster.</span></p><p><span>C. </span><strong><span>AWS Batch</span></strong><span>: Using AWS Batch with Bash scripts involves more manual setup and management compared to the managed ETL capabilities of AWS Glue.</span></p><p><span>D. </span><strong><span>AWS Lambda</span></strong><span>: Although Lambda can be used for data transformation, it is not ideal for processing large files or high volumes of data due to its limitations on execution duration and memory. Additionally, setting up and managing the Lambda function and S3 event notifications requires more effort compared to using AWS Glue.</span></p><p>&nbsp;</p><hr /><h3 id='question-215-migrate-700-tb-of-backup-data-to-aws-within-1-month-at-the-lowest-cost'><span>Question #215 Migrate 700 TB of backup data to AWS within 1 month at the lowest cost</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has 700 TB of backup data stored in network attached storage (NAS) in its data center. This backup data needs to be accessible for infrequent regulatory requests and must be retained for 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month. The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer. What should a solutions architect do to migrate and store the data at the lowest cost?</span></p><p><span>A. Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.</span></p><p><span>B. Deploy a VPN connection between the data center and Amazon VPC. Use the AWS CLI to copy the data from on premises to Amazon S3 Glacier.</span></p><p><span>C. Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.</span></p><p><span>D. Use AWS DataSync to transfer the data and deploy a DataSync agent on premises. Use the DataSync task to copy files from the on-premises NAS storage to Amazon S3 Glacier.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Snowball</span></strong><span>: AWS Snowball is a data transfer service that provides secure, high-capacity storage devices that can be used to physically transfer large amounts of data to AWS. Given the large volume of data (700 TB) and the requirement to complete the migration within 1 month, using Snowball devices is the most practical and cost-effective solution. Snowball can handle large data transfers efficiently without relying on internet bandwidth.</span></p></li><li><p><strong><span>Lifecycle Policy to S3 Glacier Deep Archive</span></strong><span>: After the data is transferred to Amazon S3, a lifecycle policy can be used to transition the data to Amazon S3 Glacier Deep Archive, which is the lowest cost storage option for long-term archival and infrequent access.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>VPN Connection and AWS CLI</span></strong><span>: Transferring 700 TB of data over a 500 Mbps internet connection would take too long to complete within 1 month. Additionally, using a VPN connection and AWS CLI would not be as cost-effective or efficient as using Snowball devices.</span></p><p><span>C. </span><strong><span>AWS Direct Connect</span></strong><span>: While AWS Direct Connect provides a dedicated network connection, provisioning a 500 Mbps Direct Connect link and transferring 700 TB of data within 1 month would be costly and still may not meet the required timeline.</span></p><p><span>D. </span><strong><span>AWS DataSync</span></strong><span>: DataSync is designed for transferring data over the network and would be limited by the available 500 Mbps bandwidth. This would also take too long to complete the migration within the required timeframe and would not be as cost-effective as using Snowball devices.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-216-enabling-encryption-for-existing-and-future-objects-in-an-s3-bucket'><span>Question #216 Enabling encryption for existing and future objects in an S3 bucket</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a serverless website with millions of objects in an Amazon S3 bucket. The company uses the S3 bucket as the origin for an Amazon CloudFront distribution. The company did not set encryption on the S3 bucket before the objects were loaded. A solutions architect needs to enable encryption for all existing objects and for all objects that are added to the S3 bucket in the future. Which solution will meet these requirements with the LEAST amount of effort?</span></p><p><span>A. Create a new S3 bucket. Turn on the default encryption settings for the new S3 bucket. Download all existing objects to temporary local storage. Upload the objects to the new S3 bucket.</span></p><p><span>B. Turn on the default encryption settings for the S3 bucket. Use the S3 Inventory feature to create a .csv file that lists the unencrypted objects. Run an S3 Batch Operations job that uses the copy command to encrypt those objects.</span></p><p><span>C. Create a new encryption key by using AWS Key Management Service (AWS KMS). Change the settings on the S3 bucket to use server-side encryption with AWS KMS managed encryption keys (SSE-KMS). Turn on versioning for the S3 bucket.</span></p><p><span>D. Navigate to Amazon S3 in the AWS Management Console. Browse the S3 bucket&#39;s objects. Sort by the encryption field. Select each unencrypted object. Use the Modify button to apply default encryption settings to every unencrypted object in the S3 bucket.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Turn on the default encryption settings for the S3 bucket. Use the S3 Inventory feature to create a .csv file that lists the unencrypted objects. Run an S3 Batch Operations job that uses the copy command to encrypt those objects.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Default Encryption Settings</span></strong><span>: By turning on default encryption settings for the S3 bucket, you ensure that all future objects uploaded to the bucket are automatically encrypted.</span></p></li><li><p><strong><span>S3 Inventory</span></strong><span>: The S3 Inventory feature can generate a list of all objects in the bucket, including their encryption status. This allows you to identify which objects are not encrypted.</span></p></li><li><p><strong><span>S3 Batch Operations</span></strong><span>: Using S3 Batch Operations to run a job that copies existing objects with the copy command allows you to apply encryption to those objects. This approach is automated and can handle the encryption of millions of objects with minimal effort.</span></p></li></ol><p><span>The other solutions have the following drawbacks:</span></p><p><span>A. </span><strong><span>New S3 Bucket and Manual Upload</span></strong><span>: Creating a new bucket and manually downloading and uploading objects is labor-intensive and time-consuming, especially for millions of objects.</span></p><p><span>C. </span><strong><span>AWS KMS and Versioning</span></strong><span>: Changing to AWS KMS managed keys and turning on versioning does not automatically encrypt existing objects. You would still need to manually re-upload or copy the objects to apply encryption.</span></p><p><span>D. </span><strong><span>Manual Modification in Console</span></strong><span>: Manually selecting and modifying each unencrypted object in the S3 console is impractical for millions of objects and involves significant manual effort.</span></p><p>&nbsp;</p><hr /><h3 id='question-217-create-a-disaster-recovery-solution-for-a-global-web-application'><span>Question #217 Create a disaster recovery solution for a global web application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs a global web application on Amazon EC2 instances behind an Application Load Balancer. The application stores data in Amazon Aurora. The company needs to create a disaster recovery solution and can tolerate up to 30 minutes of downtime and potential data loss. The solution does not need to handle the load when the primary infrastructure is healthy. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region.</span></p><p><span>B. Host a scaled-down deployment of the application in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora Replica in the second Region.</span></p><p><span>C. Replicate the primary infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-active failover. Create an Aurora database that is restored from the latest snapshot.</span></p><p><span>D. Back up data with AWS Backup. Use the backup to create the required infrastructure in a second AWS Region. Use Amazon Route 53 to configure active-passive failover. Create an Aurora second primary instance in the second Region.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Active-Passive Failover with Route 53</span></strong><span>: Configuring Route 53 for active-passive failover ensures that the secondary infrastructure is only used when the primary infrastructure fails. This setup is cost-effective as it does not need to handle the load when the primary infrastructure is healthy.</span></p></li><li><p><strong><span>Aurora Replica in a Second Region</span></strong><span>: Creating an Aurora Replica in a second AWS Region provides a near real-time copy of the database. In case of a disaster, the Aurora Replica can be promoted to primary, ensuring minimal data loss and downtime within the tolerated 30 minutes.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Active-Active Failover</span></strong><span>: Active-active failover is more complex and costly as it requires both regions to handle the load simultaneously, which is unnecessary given the company&#39;s requirements.</span></p><p><span>C. </span><strong><span>Restoring from Snapshot</span></strong><span>: Restoring an Aurora database from the latest snapshot in a second region can take more than 30 minutes, which does not meet the downtime requirement.</span></p><p><span>D. </span><strong><span>Using AWS Backup</span></strong><span>: While AWS Backup provides a way to back up data, restoring the entire infrastructure and database from backups in a second region can exceed the 30-minute downtime tolerance. Additionally, managing backups and restores manually may introduce delays and complexities.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-218-making-a-web-server-accessible-on-port-443'><span>Question #218 Making a web server accessible on port 443</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a web server running on an Amazon EC2 instance in a public subnet with an Elastic IP address. The default security group is assigned to the EC2 instance. The default network ACL has been modified to block all traffic. A solutions architect needs to make the web server accessible from everywhere on port 443. Which combination of steps will accomplish this task? (Choose two.)</span></p><p><span>A. Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.</span></p><p><span>B. Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.</span></p><p><span>C. Update the network ACL to allow TCP port 443 from source 0.0.0.0/0.</span></p><p><span>D. Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0.</span></p><p><span>E. Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.</span></p><p><span>E. Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Security Group Rule</span></strong><span>: Security groups act as virtual firewalls for your instance to control inbound and outbound traffic. Creating a security group rule to allow TCP port 443 from source 0.0.0.0/0 ensures that the web server can accept HTTPS traffic from any IP address.</span></p></li><li><p><strong><span>Network ACL Rules</span></strong><span>: Network ACLs (NACLs) provide an additional layer of security at the subnet level. Since the default NACL has been modified to block all traffic, you need to update it to allow the necessary traffic. </span></p><ul><li><p><strong><span>Inbound Rule</span></strong><span>: Allow inbound traffic on TCP port 443 from source 0.0.0.0/0 to permit incoming HTTPS connections.</span></p></li><li><p><strong><span>Outbound Rule</span></strong><span>: Allow outbound traffic on ephemeral ports (32768-65535) to destination 0.0.0.0/0 to ensure that responses to incoming requests can be sent back to the clients.</span></p></li></ul></li></ol><p><span>The other options have the following issues:</span></p><p><span>B. </span><strong><span>Security Group Destination Rule</span></strong><span>: Security groups control inbound rules based on the source IP and outbound rules based on the destination IP. Specifying a destination for an inbound rule is not applicable.</span></p><p><span>C. </span><strong><span>Inbound Network ACL Only</span></strong><span>: Allowing only the inbound traffic on port 443 without the corresponding outbound rule will prevent the server from responding to the incoming requests.</span></p><p><span>D. </span><strong><span>Inbound/Outbound on Port 443 Only</span></strong><span>: Allowing both inbound and outbound traffic on port 443 does not account for the ephemeral ports required for the return traffic.</span></p><p>&nbsp;</p><hr /><h3 id='question-219-improve-performance-of-a-stateful-application-on-amazon-ec2'><span>Question #219 Improve performance of a stateful application on Amazon EC2</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company&#39;s application is having performance issues. The application is stateful and needs to complete in-memory tasks on Amazon EC2 instances. The company used AWS CloudFormation to deploy infrastructure and used the M5 EC2 instance family. As traffic increased, the application performance degraded. Users are reporting delays when they attempt to access the application. Which solution will resolve these issues in the most operationally efficient way?</span></p><p><span>A. Replace the EC2 instances with T3 EC2 instances that run in an Auto Scaling group. Make the changes by using the AWS Management Console.</span></p><p><span>B. Modify the CloudFormation templates to run the EC2 instances in an Auto Scaling group. Increase the desired capacity and the maximum capacity of the Auto Scaling group manually when an increase is necessary.</span></p><p><span>C. Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Use Amazon CloudWatch built-in EC2 memory metrics to track the application performance for future capacity planning.</span></p><p><span>D. Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>R5 EC2 Instances</span></strong><span>: The R5 instance family is optimized for memory-intensive applications. Since the application is stateful and needs to complete in-memory tasks, switching from M5 to R5 instances can provide better performance due to higher memory capacity and memory bandwidth.</span></p></li><li><p><strong><span>CloudFormation Templates</span></strong><span>: Modifying the CloudFormation templates ensures that the changes are managed as infrastructure as code, making the deployment more consistent and repeatable.</span></p></li><li><p><strong><span>Amazon CloudWatch Agent</span></strong><span>: Deploying the CloudWatch agent on the EC2 instances allows for the collection of custom application latency metrics. These metrics are crucial for monitoring and future capacity planning to ensure that the application can handle increased traffic without performance degradation.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>T3 EC2 Instances</span></strong><span>: T3 instances are burstable performance instances and may not provide the consistent performance needed for a stateful, memory-intensive application. This option also does not address the need for in-memory task completion.</span></p><p><span>B. </span><strong><span>Auto Scaling Group with M5 Instances</span></strong><span>: While adding an Auto Scaling group can help handle increased traffic, it does not address the underlying issue of memory capacity and performance for in-memory tasks. Manually increasing capacity is also less operationally efficient.</span></p><p><span>C. </span><strong><span>R5 Instances with Built-in Metrics</span></strong><span>: While switching to R5 instances is a good step, relying only on built-in EC2 memory metrics without custom application latency metrics may not provide enough insight into application performance for future capacity planning.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-220-designing-a-cost-effective-api-with-asynchronous-processing'><span>Question #220 Designing a cost-effective API with asynchronous processing</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect is designing a new API using Amazon API Gateway that will receive requests from users. The volume of requests is highly variable; several hours can pass without receiving a single request. The data processing will take place asynchronously, but should be completed within a few seconds after a request is made. Which compute service should the solutions architect have the API invoke to deliver the requirements at the lowest cost?</span></p><p><span>A. An AWS Glue job</span></p><p><span>B. An AWS Lambda function</span></p><p><span>C. A containerized service hosted in Amazon Elastic Kubernetes Service (Amazon EKS)</span></p><p><span>D. A containerized service hosted in Amazon ECS with Amazon EC2</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. An AWS Lambda function</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Lambda</span></strong><span>: AWS Lambda is a serverless compute service that automatically scales based on the number of requests. It is designed to handle highly variable workloads efficiently. Since Lambda only charges for the compute time consumed (per request), it is cost-effective for scenarios with unpredictable and intermittent request volumes.</span></p></li><li><p><strong><span>Asynchronous Processing</span></strong><span>: Lambda functions can be invoked asynchronously, making them suitable for processing tasks that need to be completed shortly after a request is made.</span></p></li><li><p><strong><span>Low Latency</span></strong><span>: Lambda functions can start executing within milliseconds, ensuring that the data processing is completed within a few seconds after a request is made.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Glue Job</span></strong><span>: AWS Glue is primarily used for ETL (extract, transform, load) jobs and is not optimized for handling highly variable, low-latency request processing.</span></p><p><span>C. </span><strong><span>Amazon EKS</span></strong><span>: Running a containerized service in Amazon EKS involves maintaining a Kubernetes cluster, which introduces additional complexity and cost, especially for highly variable workloads with long idle periods.</span></p><p><span>D. </span><strong><span>Amazon ECS with Amazon EC2</span></strong><span>: Hosting a containerized service on Amazon ECS with Amazon EC2 requires managing EC2 instances, which can be costly and inefficient for handling sporadic requests. The instances would need to be running continuously or scaled dynamically, which adds operational overhead.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-221-cost-effective-storage-solution-for-retaining-application-log-files-for-7-years'><span>Question #221 Cost-effective storage solution for retaining application log files for 7 years</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs an application on a group of Amazon Linux EC2 instances. For compliance reasons, the company must retain all application log files for 7 years. The log files will be analyzed by a reporting tool that must be able to access all the files concurrently. Which storage solution meets these requirements most cost-effectively?</span></p><p><span>A. Amazon Elastic Block Store (Amazon EBS)</span></p><p><span>B. Amazon Elastic File System (Amazon EFS)</span></p><p><span>C. Amazon EC2 instance store</span></p><p><span>D. Amazon S3</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Amazon S3</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3</span></strong><span>: Amazon S3 (Simple Storage Service) is a highly durable and cost-effective storage solution for retaining large amounts of data over long periods. It is ideal for storing log files that need to be retained for compliance reasons. S3 provides scalable storage and allows concurrent access to files, making it suitable for analysis by a reporting tool.</span></p></li><li><p><strong><span>Cost-Effective</span></strong><span>: S3 offers different storage classes (e.g., S3 Standard, S3 Standard-IA, S3 Glacier) that can be used to optimize costs based on access patterns. For long-term retention with infrequent access, S3 Glacier or S3 Glacier Deep Archive can be used to significantly reduce storage costs.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon EBS</span></strong><span>: Elastic Block Store is designed for block storage attached to EC2 instances. It is more expensive compared to S3 for long-term storage of log files and does not provide the same level of scalability and concurrent access.</span></p><p><span>B. </span><strong><span>Amazon EFS</span></strong><span>: Elastic File System is a managed file storage service for EC2 instances. While it supports concurrent access, it is more expensive than S3 for long-term storage of log files.</span></p><p><span>C. </span><strong><span>Amazon EC2 instance store</span></strong><span>: Instance store provides temporary block-level storage for EC2 instances. It is ephemeral and not suitable for long-term storage of log files, as data is lost when the instance is stopped or terminated.</span></p><p>&nbsp;</p><hr /><h3 id='question-222-granting-access-to-an-external-vendors-automated-tool'><span>Question #222 Granting access to an external vendor&#39;s automated tool</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has hired an external vendor to perform work in the company&#39;s AWS account. The vendor uses an automated tool that is hosted in an AWS account that the vendor owns. The vendor does not have IAM access to the company&#39;s AWS account. How should a solutions architect grant this access to the vendor?</span></p><p><span>A. Create an IAM role in the company&#39;s account to delegate access to the vendor&#39;s IAM role. Attach the appropriate IAM policies to the role for the permissions that the vendor requires.</span></p><p><span>B. Create an IAM user in the company&#39;s account with a password that meets the password complexity requirements. Attach the appropriate IAM policies to the user for the permissions that the vendor requires.</span></p><p><span>C. Create an IAM group in the company&#39;s account. Add the tool&#39;s IAM user from the vendor account to the group. Attach the appropriate IAM policies to the group for the permissions that the vendor requires.</span></p><p><span>D. Create a new identity provider by choosing &quot;AWS account&quot; as the provider type in the IAM console. Supply the vendor&#39;s AWS account ID and user name. Attach the appropriate IAM policies to the new provider for the permissions that the vendor requires.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create an IAM role in the company&#39;s account to delegate access to the vendor&#39;s IAM role. Attach the appropriate IAM policies to the role for the permissions that the vendor requires.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>IAM Role Delegation</span></strong><span>: Creating an IAM role and allowing the vendor&#39;s IAM role to assume it is the most secure and scalable way to grant access. This approach uses AWS&#39;s built-in cross-account access capabilities.</span></p></li><li><p><strong><span>Least Privilege</span></strong><span>: By attaching the appropriate IAM policies to the role, you can ensure that the vendor only gets the permissions necessary to perform their tasks.</span></p></li><li><p><strong><span>Temporary Access</span></strong><span>: The vendor can assume the role temporarily, which is more secure than providing long-term credentials. This also makes it easier to revoke access when it&#39;s no longer needed.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>IAM User with Password</span></strong><span>: Creating an IAM user with a password is less secure and harder to manage. It requires the vendor to manage long-term credentials and does not leverage AWS&#39;s built-in cross-account access capabilities.</span></p><p><span>C. </span><strong><span>IAM Group</span></strong><span>: You cannot add IAM users from another AWS account to a group in your account. IAM groups are only for organizing IAM users within the same account.</span></p><p><span>D. </span><strong><span>Identity Provider</span></strong><span>: This option is used for federating access from external identity providers (like SAML or OpenID Connect). It is not suitable for granting access to another AWS account directly.</span></p><p>&nbsp;</p><hr /><h3 id='question-223-ensure-secure-interaction-between-an-eks-pod-and-dynamodb-without-exposing-traffic-to-the-internet'><span>Question #223 Ensure secure interaction between an EKS pod and DynamoDB without exposing traffic to the internet</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has deployed a Java Spring Boot application as a pod that runs on Amazon Elastic Kubernetes Service (Amazon EKS) in private subnets. The application needs to write data to an Amazon DynamoDB table. A solutions architect must ensure that the application can interact with the DynamoDB table without exposing traffic to the internet. Which combination of steps should the solutions architect take to accomplish this goal? (Choose two.)</span></p><p><span>A. Attach an IAM role that has sufficient privileges to the EKS pod.</span></p><p><span>B. Attach an IAM user that has sufficient privileges to the EKS pod.</span></p><p><span>C. Allow outbound connectivity to the DynamoDB table through the private subnets&#39; network ACLs.</span></p><p><span>D. Create a VPC endpoint for DynamoDB.</span></p><p><span>E. Embed the access keys in the Java Spring Boot code.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Attach an IAM role that has sufficient privileges to the EKS pod.</span></p><p><span>D. Create a VPC endpoint for DynamoDB.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>IAM Role for EKS Pod</span></strong><span>: Attaching an IAM role to the EKS pod ensures that the application has the necessary permissions to interact with the DynamoDB table without the need for hardcoding credentials. This is a secure practice that leverages AWS IAM roles and policies.</span></p></li><li><p><strong><span>VPC Endpoint for DynamoDB</span></strong><span>: Creating a VPC endpoint for DynamoDB allows the application to communicate with DynamoDB without routing traffic through the internet. This ensures that the traffic remains within the AWS network, providing secure and private connectivity.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>IAM User</span></strong><span>: Attaching an IAM user to the EKS pod is not recommended as it involves managing long-term credentials, which is less secure compared to using IAM roles.</span></p><p><span>C. </span><strong><span>Network ACLs</span></strong><span>: While allowing outbound connectivity through network ACLs is necessary, it alone does not ensure that traffic to DynamoDB is not exposed to the internet. The VPC endpoint is required to keep the traffic private.</span></p><p><span>E. </span><strong><span>Embedding Access Keys</span></strong><span>: Embedding access keys in the application code is not a secure practice and should be avoided. It can lead to security vulnerabilities if the keys are exposed or compromised.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-224-designing-a-highly-available-and-fault-tolerant-web-application-on-aws'><span>Question #224 Designing a highly available and fault-tolerant web application on AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company recently migrated its web application to AWS by rehosting the application on Amazon EC2 instances in a single AWS Region. The company wants to redesign its application architecture to be highly available and fault tolerant. Traffic must reach all running EC2 instances randomly. Which combination of steps should the company take to meet these requirements? (Choose two.)</span></p><p><span>A. Create an Amazon Route 53 failover routing policy.</span></p><p><span>B. Create an Amazon Route 53 weighted routing policy.</span></p><p><span>C. Create an Amazon Route 53 multivalue answer routing policy.</span></p><p><span>D. Launch three EC2 instances: two instances in one Availability Zone and one instance in another Availability Zone.</span></p><p><span>E. Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create an Amazon Route 53 multivalue answer routing policy.</span></p><p><span>E. Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Route 53 Multivalue Answer Routing Policy</span></strong><span>: This routing policy allows you to return multiple IP addresses in response to DNS queries. It helps distribute traffic randomly across multiple instances, which can improve availability and fault tolerance.</span></p></li><li><p><strong><span>Multiple Availability Zones</span></strong><span>: Launching instances across multiple Availability Zones (AZs) ensures that the application remains highly available and fault-tolerant. By having instances in at least two AZs, you can withstand the failure of an entire AZ.</span></p></li></ol><ul><li><p><strong><span>Option E</span></strong><span>: Launching four EC2 instances, with two instances in each of two Availability Zones, helps distribute the load and provides redundancy.</span></p></li></ul><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Failover Routing Policy</span></strong><span>: This policy is used to route traffic to a primary resource when it is healthy and to a secondary resource when the primary is unhealthy. It does not distribute traffic randomly across all instances.</span></p><p><span>B. </span><strong><span>Weighted Routing Policy</span></strong><span>: This policy allows you to route traffic based on assigned weights. While it can distribute traffic, it does not ensure random distribution and is more complex to manage for high availability and fault tolerance.</span></p><p><span>D. </span><strong><span>Three Instances in Two AZs</span></strong><span>: While this improves availability compared to a single AZ, having only one instance in an AZ does not provide sufficient redundancy if that AZ fails. Two instances per AZ, as in option E, is a better approach.</span></p><p>&nbsp;</p><hr /><h3 id='question-225-build-a-highly-available-data-ingestion-solution-for-on-demand-analytics-with-sql'><span>Question #225 Build a highly available data ingestion solution for on-demand analytics with SQL</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A media company collects and analyzes user activity data on premises. The company wants to migrate this capability to AWS. The user activity data store will continue to grow and will be petabytes in size. The company needs to build a highly available data ingestion solution that facilitates on-demand analytics of existing data and new data with SQL. Which solution will meet these requirements with the least operational overhead?</span></p><p><span>A. Send activity data to an Amazon Kinesis data stream. Configure the stream to deliver the data to an Amazon S3 bucket.</span></p><p><span>B. Send activity data to an Amazon Kinesis Data Firehose delivery stream. Configure the stream to deliver the data to an Amazon Redshift cluster.</span></p><p><span>C. Place activity data in an Amazon S3 bucket. Configure Amazon S3 to run an AWS Lambda function on the data as the data arrives in the S3 bucket.</span></p><p><span>D. Create an ingestion service on Amazon EC2 instances that are spread across multiple Availability Zones. Configure the service to forward data to an Amazon RDS Multi-AZ database.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Send activity data to an Amazon Kinesis Data Firehose delivery stream. Configure the stream to deliver the data to an Amazon Redshift cluster.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Kinesis Data Firehose</span></strong><span>: Kinesis Data Firehose is a fully managed service for real-time data streaming and ingestion. It can automatically scale to handle varying data volumes and provides a simple, low-overhead way to ingest data.</span></p></li><li><p><strong><span>Amazon Redshift</span></strong><span>: Delivering data to an Amazon Redshift cluster allows for on-demand analytics using SQL. Redshift is designed to handle petabyte-scale data warehousing and provides high-performance querying capabilities.</span></p></li><li><p><strong><span>Least Operational Overhead</span></strong><span>: Using Kinesis Data Firehose to deliver data directly to Redshift minimizes the operational overhead as it eliminates the need to manage and scale the ingestion infrastructure manually. Firehose also handles data transformation and compression, reducing the complexity of the solution.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Kinesis Data Stream to S3</span></strong><span>: While this option provides a scalable ingestion solution, it does not directly support SQL-based analytics. Additional steps would be required to load the data from S3 into a database for SQL querying.</span></p><p><span>C. </span><strong><span>S3 with Lambda</span></strong><span>: This option can handle data ingestion and processing, but it requires additional setup and management. It does not directly support SQL-based analytics and would require loading the data into a database like Redshift for querying.</span></p><p><span>D. </span><strong><span>EC2 Instances with RDS</span></strong><span>: This option involves more operational overhead as it requires managing EC2 instances and an RDS database. It is not as scalable or cost-effective as using managed services like Kinesis Data Firehose and Redshift.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-226-designing-a-highly-scalable-data-collection-and-processing-solution'><span>Question #226 Designing a highly scalable data collection and processing solution</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company collects data from thousands of remote devices by using a RESTful web services application that runs on an Amazon EC2 instance. The EC2 instance receives the raw data, transforms the raw data, and stores all the data in an Amazon S3 bucket. The number of remote devices will increase into the millions soon. The company needs a highly scalable solution that minimizes operational overhead. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)</span></p><p><span>A. Use AWS Glue to process the raw data in Amazon S3.</span></p><p><span>B. Use Amazon Route 53 to route traffic to different EC2 instances.</span></p><p><span>C. Add more EC2 instances to accommodate the increasing amount of incoming data.</span></p><p><span>D. Send the raw data to Amazon Simple Queue Service (Amazon SQS). Use EC2 instances to process the data.</span></p><p><span>E. Use Amazon API Gateway to send the raw data to an Amazon Kinesis data stream. Configure Amazon Kinesis Data Firehose to use the data stream as a source to deliver the data to Amazon S3.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use AWS Glue to process the raw data in Amazon S3.</span></p><p><span>E. Use Amazon API Gateway to send the raw data to an Amazon Kinesis data stream. Configure Amazon Kinesis Data Firehose to use the data stream as a source to deliver the data to Amazon S3.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon API Gateway and Amazon Kinesis</span></strong><span>: Using Amazon API Gateway to receive the raw data and send it to an Amazon Kinesis data stream provides a highly scalable and managed solution for handling the increased volume of incoming data from millions of devices. Kinesis Data Streams can handle large-scale data ingestion and real-time processing.</span></p></li><li><p><strong><span>Amazon Kinesis Data Firehose</span></strong><span>: Configuring Kinesis Data Firehose to use the Kinesis data stream as a source allows for the seamless delivery of data to Amazon S3. This setup minimizes operational overhead by leveraging managed services that automatically scale.</span></p></li><li><p><strong><span>AWS Glue</span></strong><span>: Using AWS Glue to process the raw data in Amazon S3 allows for scalable and serverless data transformation. Glue can efficiently handle large volumes of data with minimal operational overhead.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Amazon Route 53</span></strong><span>: While Route 53 can route traffic to different EC2 instances, it does not inherently solve the scalability and operational overhead issues associated with processing large volumes of data.</span></p><p><span>C. </span><strong><span>More EC2 Instances</span></strong><span>: Adding more EC2 instances increases operational overhead and complexity. It requires manual scaling and management, which is not ideal for handling millions of devices.</span></p><p><span>D. </span><strong><span>Amazon SQS and EC2 Instances</span></strong><span>: While SQS can handle large volumes of data, using EC2 instances to process the data still requires managing and scaling the instances, leading to increased operational overhead.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-227-cost-effective-solution-to-delete-old-aws-cloudtrail-logs-from-s3'><span>Question #227 Cost-effective solution to delete old AWS CloudTrail logs from S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs to retain its AWS CloudTrail logs for 3 years. The company is enforcing CloudTrail across a set of AWS accounts by using AWS Organizations from the parent account. The CloudTrail target S3 bucket is configured with S3 Versioning enabled. An S3 Lifecycle policy is in place to delete current objects after 3 years. After the fourth year of use of the S3 bucket, the S3 bucket metrics show that the number of objects has continued to rise. However, the number of new CloudTrail logs that are delivered to the S3 bucket has remained consistent. Which solution will delete objects that are older than 3 years in the most cost-effective manner?</span></p><p><span>A. Configure the organization&#39;s centralized CloudTrail trail to expire objects after 3 years.</span></p><p><span>B. Configure the S3 Lifecycle policy to delete previous versions as well as current versions.</span></p><p><span>C. Create an AWS Lambda function to enumerate and delete objects from Amazon S3 that are older than 3 years.</span></p><p><span>D. Configure the parent account as the owner of all objects that are delivered to the S3 bucket.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Configure the S3 Lifecycle policy to delete previous versions as well as current versions.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>S3 Lifecycle Policy for Versioning</span></strong><span>: The S3 bucket has Versioning enabled, which means that previous versions of objects are being retained even after the current versions are deleted. To manage the number of objects effectively, the Lifecycle policy should be configured to delete both current and previous versions of objects that are older than 3 years.</span></p></li><li><p><strong><span>Cost-Effective</span></strong><span>: Configuring the S3 Lifecycle policy to delete previous versions is a built-in feature of S3 and does not incur additional costs or require custom code, making it the most cost-effective solution.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Centralized CloudTrail Trail Expiration</span></strong><span>: CloudTrail itself does not have a feature to expire objects in S3. Expiration needs to be managed through S3 Lifecycle policies.</span></p><p><span>C. </span><strong><span>AWS Lambda Function</span></strong><span>: Creating a Lambda function to enumerate and delete objects would involve additional complexity and operational overhead. It would also incur costs associated with Lambda execution and S3 API calls.</span></p><p><span>D. </span><strong><span>Parent Account Ownership</span></strong><span>: Changing the ownership of objects does not address the issue of deleting old versions of objects. It is not relevant to the problem of managing object retention and versioning in S3.</span></p><p>&nbsp;</p><hr /><h3 id='question-228-handling-fluctuating-real-time-data-with-minimized-database-connections'><span>Question #228 Handling fluctuating real-time data with minimized database connections</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an API that receives real-time data from a fleet of monitoring devices. The API stores this data in an Amazon RDS DB instance for later analysis. The amount of data that the monitoring devices send to the API fluctuates. During periods of heavy traffic, the API often returns timeout errors. After an inspection of the logs, the company determines that the database is not capable of processing the volume of write traffic that comes from the API. A solutions architect must minimize the number of connections to the database and must ensure that data is not lost during periods of heavy traffic. Which solution will meet these requirements?</span></p><p><span>A. Increase the size of the DB instance to an instance type that has more available memory.</span></p><p><span>B. Modify the DB instance to be a Multi-AZ DB instance. Configure the application to write to all active RDS DB instances.</span></p><p><span>C. Modify the API to write incoming data to an Amazon Simple Queue Service (Amazon SQS) queue. Use an AWS Lambda function that Amazon SQS invokes to write data from the queue to the database.</span></p><p><span>D. Modify the API to write incoming data to an Amazon Simple Notification Service (Amazon SNS) topic. Use an AWS Lambda function that Amazon SNS invokes to write data from the topic to the database.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Modify the API to write incoming data to an Amazon Simple Queue Service (Amazon SQS) queue. Use an AWS Lambda function that Amazon SQS invokes to write data from the queue to the database.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SQS for Buffering</span></strong><span>: Using Amazon SQS to buffer incoming data helps decouple the data ingestion from the database writes. This ensures that even during periods of heavy traffic, data is not lost because it is queued in SQS.</span></p></li><li><p><strong><span>AWS Lambda for Processing</span></strong><span>: AWS Lambda can be triggered by SQS to process the queued messages and write them to the database. This approach minimizes the number of concurrent connections to the database, as Lambda can scale the processing based on the queue size.</span></p></li><li><p><strong><span>Decoupling and Scalability</span></strong><span>: This solution decouples the API from the database, allowing the system to handle fluctuating traffic more effectively. It also leverages the scalability of SQS and Lambda to manage the varying load.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Increasing DB Instance Size</span></strong><span>: While increasing the size of the DB instance might temporarily alleviate the problem, it does not address the fluctuating nature of the traffic and can be more costly. It also does not minimize the number of connections to the database.</span></p><p><span>B. </span><strong><span>Multi-AZ DB Instance</span></strong><span>: Multi-AZ configurations provide high availability and failover support but do not inherently solve the problem of handling fluctuating write traffic. Writing to multiple active instances is not a supported feature for RDS Multi-AZ configurations.</span></p><p><span>D. </span><strong><span>Amazon SNS</span></strong><span>: While SNS can be used to trigger Lambda functions, it is primarily designed for pub-sub messaging and notifications. SQS is more suitable for queuing and buffering data to handle fluctuating traffic and ensure data is not lost.</span></p><p>&nbsp;</p><hr /><h3 id='question-229-simplify-management-of-mysql-databases-with-improved-performance-scaling-and-durability'><span>Question #229 Simplify management of MySQL databases with improved performance, scaling, and durability</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company manages its own Amazon EC2 instances that run MySQL databases. The company is manually managing replication and scaling as demand increases or decreases. The company needs a new solution that simplifies the process of adding or removing compute capacity to or from its database tier as needed. The solution also must offer improved performance, scaling, and durability with minimal effort from operations. Which solution meets these requirements?</span></p><p><span>A. Migrate the databases to Amazon Aurora Serverless for Aurora MySQL.</span></p><p><span>B. Migrate the databases to Amazon Aurora Serverless for Aurora PostgreSQL.</span></p><p><span>C. Combine the databases into one larger MySQL database. Run the larger database on larger EC2 instances.</span></p><p><span>D. Create an EC2 Auto Scaling group for the database tier. Migrate the existing databases to the new environment.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Migrate the databases to Amazon Aurora Serverless for Aurora MySQL.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Aurora Serverless for Aurora MySQL</span></strong><span>: Aurora Serverless is an on-demand, auto-scaling configuration for Amazon Aurora. It automatically adjusts the database capacity based on the application&#39;s needs, which simplifies the process of adding or removing compute capacity. This option provides improved performance, scaling, and durability with minimal operational effort.</span></p></li><li><p><strong><span>Improved Performance and Durability</span></strong><span>: Aurora MySQL is designed to offer enhanced performance and durability compared to standard MySQL. It provides features such as automatic scaling, high availability, fault tolerance, and automated backups.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Aurora Serverless for Aurora PostgreSQL</span></strong><span>: While Aurora PostgreSQL is a powerful database, the company&#39;s current databases are running on MySQL. Migrating to Aurora PostgreSQL would require additional effort to convert the databases and application code to be compatible with PostgreSQL.</span></p><p><span>C. </span><strong><span>Larger MySQL Database on Larger EC2 Instances</span></strong><span>: Combining databases into a larger MySQL database and running it on larger EC2 instances does not address the need for automatic scaling and would still require manual management of replication and scaling.</span></p><p><span>D. </span><strong><span>EC2 Auto Scaling Group for Database Tier</span></strong><span>: Creating an EC2 Auto Scaling group for the database tier is not a recommended approach for database scaling and management. Databases require careful handling of state and consistency, and auto-scaling EC2 instances for databases can introduce complexities in managing replication and data consistency. Aurora Serverless provides a more seamless and managed solution for these requirements.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-230-implementing-a-scalable-and-fault-tolerant-nat-solution'><span>Question #230 Implementing a scalable and fault-tolerant NAT solution</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is concerned that two NAT instances in use will no longer be able to support the traffic needed for the company&#39;s application. A solutions architect wants to implement a solution that is highly available, fault tolerant, and automatically scalable. What should the solutions architect recommend?</span></p><p><span>A. Remove the two NAT instances and replace them with two NAT gateways in the same Availability Zone.</span></p><p><span>B. Use Auto Scaling groups with Network Load Balancers for the NAT instances in different Availability Zones.</span></p><p><span>C. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.</span></p><p><span>D. Replace the two NAT instances with Spot Instances in different Availability Zones and deploy a Network Load Balancer.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>NAT Gateways</span></strong><span>: NAT Gateways are managed services provided by AWS that offer better performance, scalability, and availability compared to NAT instances. They automatically scale to accommodate the traffic and are highly available and fault-tolerant.</span></p></li><li><p><strong><span>Different Availability Zones</span></strong><span>: Deploying NAT Gateways in different Availability Zones ensures high availability and fault tolerance. If one Availability Zone experiences an outage, the other NAT Gateway in a different Availability Zone can handle the traffic.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Same Availability Zone</span></strong><span>: Placing both NAT Gateways in the same Availability Zone does not provide fault tolerance. An outage in that Availability Zone would affect both NAT Gateways.</span></p><p><span>B. </span><strong><span>Auto Scaling and NLB for NAT Instances</span></strong><span>: While this setup can provide scalability, it is more complex to manage and does not inherently provide the same level of fault tolerance and automatic scaling as NAT Gateways.</span></p><p><span>D. </span><strong><span>Spot Instances and NLB</span></strong><span>: Spot Instances can be interrupted, which makes them less reliable for critical network functions like NAT. Additionally, using a Network Load Balancer adds complexity and does not provide the same level of automatic scaling and fault tolerance as NAT Gateways.</span></p><p>&nbsp;</p><hr /><h3 id='question-231-secure-access-to-a-database-in-a-different-vpc'><span>Question #231 Secure access to a database in a different VPC</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An application runs on an Amazon EC2 instance that has an Elastic IP address in VPC A. The application requires access to a database in VPC B. Both VPCs are in the same AWS account. Which solution will provide the required access most securely?</span></p><p><span>A. Create a DB instance security group that allows all traffic from the public IP address of the application server in VPC A.</span></p><p><span>B. Configure a VPC peering connection between VPC A and VPC B.</span></p><p><span>C. Make the DB instance publicly accessible. Assign a public IP address to the DB instance.</span></p><p><span>D. Launch an EC2 instance with an Elastic IP address into VPC B. Proxy all requests through the new EC2 instance.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Configure a VPC peering connection between VPC A and VPC B.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>VPC Peering</span></strong><span>: VPC peering allows direct network connectivity between VPCs in the same AWS account or different accounts. It provides a secure and private way to route traffic between VPCs without exposing the traffic to the internet. This ensures that the application in VPC A can securely access the database in VPC B.</span></p></li><li><p><strong><span>Security</span></strong><span>: VPC peering ensures that the traffic between VPCs remains within the AWS network, providing a high level of security. Security groups and network ACLs can be used to further control and restrict access as needed.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Security Group Allowing Public IP</span></strong><span>: Allowing traffic from the public IP address of the application server is less secure, as it involves exposing the database to the public internet, which increases the risk of unauthorized access.</span></p><p><span>C. </span><strong><span>Publicly Accessible DB Instance</span></strong><span>: Making the DB instance publicly accessible and assigning a public IP address is not a secure practice. It exposes the database to the internet, making it vulnerable to attacks.</span></p><p><span>D. </span><strong><span>Proxy Through EC2 Instance</span></strong><span>: Using an EC2 instance as a proxy adds unnecessary complexity and operational overhead. It is less efficient and secure compared to using VPC peering, which provides a direct and private connection between the VPCs.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-232-notifying-operations-team-about-rdp-or-ssh-access'><span>Question #232 Notifying operations team about RDP or SSH access</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs demonstration environments for its customers on Amazon EC2 instances. Each environment is isolated in its own VPC. The company&#39;s operations team needs to be notified when RDP or SSH access to an environment has been established. </span></p><p><strong><span>Which solution should the solutions architect recommend?</span></strong></p><p><span>A. Configure Amazon CloudWatch Application Insights to create AWS Systems Manager OpsItems when RDP or SSH access is detected.</span></p><p><span>B. Configure the EC2 instances with an IAM instance profile that has an IAM role with the AmazonSSMManagedInstanceCore policy attached.</span></p><p><span>C. Publish VPC flow logs to Amazon CloudWatch Logs. Create required metric filters. Create an Amazon CloudWatch metric alarm with a notification action for when the alarm is in the ALARM state.</span></p><p><span>D. Configure an Amazon EventBridge rule to listen for events of type EC2 Instance State-change Notification. Configure an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the operations team to the topic.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Publish VPC flow logs to Amazon CloudWatch Logs. Create required metric filters. Create an Amazon CloudWatch metric alarm with a notification action for when the alarm is in the ALARM state.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>VPC Flow Logs and CloudWatch Logs</span></strong><span>: By publishing VPC flow logs to CloudWatch Logs, you can capture detailed information about the traffic going to and from your EC2 instances. This includes RDP (port 3389) and SSH (port 22) access attempts.</span></p></li><li><p><strong><span>Metric Filters and Alarms</span></strong><span>: Creating metric filters in CloudWatch Logs allows you to search for specific patterns in the flow logs, such as successful RDP or SSH connections. You can then create CloudWatch alarms based on these metric filters to notify the operations team when such connections are detected.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>CloudWatch Application Insights and OpsItems</span></strong><span>: CloudWatch Application Insights is primarily used for monitoring and troubleshooting applications. It may not be the most straightforward tool for detecting and alerting on RDP or SSH access.</span></p><p><span>B. </span><strong><span>IAM Instance Profile and SSM Managed Policy</span></strong><span>: While attaching the AmazonSSMManagedInstanceCore policy allows you to manage instances using AWS Systems Manager, it does not directly address the need to detect and notify on RDP or SSH access.</span></p><p><span>D. </span><strong><span>EventBridge Rule for Instance State-change Notification</span></strong><span>: This type of rule is used to detect changes in the state of EC2 instances (e.g., starting, stopping, terminating) and does not provide a mechanism for detecting RDP or SSH access specifically.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-233-secure-aws-account-root-user-access'><span>Question #233 Secure AWS account root user access</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect has created a new AWS account and must secure AWS account root user access. Which combination of actions will accomplish this? (Choose two.)</span></p><p><span>A. Ensure the root user uses a strong password.</span></p><p><span>B. Enable multi-factor authentication for the root user.</span></p><p><span>C. Store root user access keys in an encrypted Amazon S3 bucket.</span></p><p><span>D. Add the root user to a group containing administrative permissions.</span></p><p><span>E. Apply the required permissions to the root user with an inline policy document.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Ensure the root user uses a strong password.</span></p><p><span>B. Enable multi-factor authentication for the root user.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Strong Password</span></strong><span>: Ensuring the root user uses a strong password is a fundamental step in securing the account. A strong password reduces the risk of unauthorized access.</span></p></li><li><p><strong><span>Multi-Factor Authentication (MFA)</span></strong><span>: Enabling MFA adds an additional layer of security. Even if the password is compromised, an attacker would still need access to the MFA device to gain entry.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>C. </span><strong><span>Store Root User Access Keys</span></strong><span>: Storing root user access keys in an encrypted S3 bucket is not a recommended practice. The best practice is to avoid using root user access keys entirely and instead create IAM users with the necessary permissions.</span></p><p><span>D. </span><strong><span>Add Root User to Group</span></strong><span>: The root user inherently has full administrative access to the account. Adding the root user to a group with administrative permissions is redundant and does not enhance security.</span></p><p><span>E. </span><strong><span>Inline Policy for Root User</span></strong><span>: The root user already has full permissions by default. Applying additional permissions with an inline policy is unnecessary and does not improve security.</span></p><p>&nbsp;</p><hr /><h3 id='question-234-ensuring-encryption-at-rest-and-in-transit-for-a-web-based-crm-application'><span>Question #234 Ensuring encryption at rest and in transit for a web-based CRM application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is building a new web-based customer relationship management (CRM) application. The application will use several Amazon EC2 instances that are backed by Amazon Elastic Block Store (Amazon EBS) volumes behind an Application Load Balancer (ALB). The application will also use an Amazon Aurora database. All data for the application must be encrypted at rest and in transit. </span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Use AWS Key Management Service (AWS KMS) certificates on the ALB to encrypt data in transit. Use AWS Certificate Manager (ACM) to encrypt the EBS volumes and Aurora database storage at rest.</span></p><p><span>B. Use the AWS root account to log in to the AWS Management Console. Upload the company&#39;s encryption certificates. While in the root account, select the option to turn on encryption for all data at rest and in transit for the account.</span></p><p><span>C. Use AWS Key Management Service (AWS KMS) to encrypt the EBS volumes and Aurora database storage at rest. Attach an AWS Certificate Manager (ACM) certificate to the ALB to encrypt data in transit.</span></p><p><span>D. Use BitLocker to encrypt all data at rest. Import the company&#39;s TLS certificate keys to AWS Key Management Service (AWS KMS). Attach the KMS keys to the ALB to encrypt data in transit.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use AWS Key Management Service (AWS KMS) to encrypt the EBS volumes and Aurora database storage at rest. Attach an AWS Certificate Manager (ACM) certificate to the ALB to encrypt data in transit.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Key Management Service (AWS KMS)</span></strong><span>: AWS KMS is a managed service that makes it easy to create and control the encryption keys used to encrypt your data. You can use KMS to encrypt EBS volumes and Aurora database storage at rest.</span></p></li><li><p><strong><span>AWS Certificate Manager (ACM)</span></strong><span>: ACM handles the complexity of creating, storing, and renewing public and private SSL/TLS certificates. Attaching an ACM certificate to the ALB ensures that data in transit is encrypted.</span></p></li></ol><ul><li><p><strong><span>Encrypting EBS Volumes and Aurora Database</span></strong><span>: Encrypting EBS volumes and Aurora database storage at rest using AWS KMS ensures that the data is protected when stored.</span></p></li><li><p><strong><span>Encrypting Data in Transit</span></strong><span>: Using ACM to attach a certificate to the ALB ensures that all data transmitted between the clients and the load balancer is encrypted using SSL/TLS.</span></p></li></ul><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Incorrect Service Usage</span></strong><span>: AWS KMS certificates are not used directly on the ALB for encrypting data in transit. ACM is the correct service for managing SSL/TLS certificates for ALBs.</span></p><p><span>B. </span><strong><span>Root Account Misuse</span></strong><span>: Using the AWS root account for routine tasks is not recommended due to security best practices. Additionally, there is no single option to turn on encryption for all data at rest and in transit for an account.</span></p><p><span>D. </span><strong><span>BitLocker and Custom Keys</span></strong><span>: BitLocker is a Windows-specific encryption tool and not suitable for use with AWS services like EBS and Aurora. Importing custom TLS certificate keys to KMS and attaching them to the ALB is not the correct approach; ACM is designed for this purpose.</span></p><p>&nbsp;</p><hr /><h3 id='question-235-migrate-on-premises-oracle-database-to-amazon-aurora-postgresql-with-minimal-downtime'><span>Question #235 Migrate on-premises Oracle database to Amazon Aurora PostgreSQL with minimal downtime</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is moving its on-premises Oracle database to Amazon Aurora PostgreSQL. The database has several applications that write to the same tables. The applications need to be migrated one by one with a month in between each migration. Management has expressed concerns that the database has a high number of reads and writes. The data must be kept in sync across both databases throughout the migration. What should a solutions architect recommend?</span></p><p><span>A. Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a change data capture (CDC) replication task and a table mapping to select all tables.</span></p><p><span>B. Use AWS DataSync for the initial migration. Use AWS Database Migration Service (AWS DMS) to create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.</span></p><p><span>C. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.</span></p><p><span>D. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a compute optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select the largest tables.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Schema Conversion Tool (SCT)</span></strong><span>: The AWS Schema Conversion Tool helps convert the database schema from Oracle to PostgreSQL, which is necessary for migrating to Amazon Aurora PostgreSQL. It ensures that the schema is compatible with the target database.</span></p></li><li><p><strong><span>AWS Database Migration Service (DMS)</span></strong><span>: Using AWS DMS with a memory-optimized replication instance ensures that the migration process can handle the high number of reads and writes efficiently. Creating a full load plus change data capture (CDC) replication task ensures that the initial data load is performed and that ongoing changes are captured and replicated to keep both databases in sync.</span></p></li><li><p><strong><span>Full Load Plus CDC</span></strong><span>: This approach allows for the initial migration of the data followed by continuous replication of changes, ensuring that the data remains in sync across both databases throughout the migration period.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS DataSync for Initial Migration</span></strong><span>: AWS DataSync is not typically used for database migrations and does not support CDC. It is more suitable for file transfers.</span></p><p><span>B. </span><strong><span>AWS DataSync for Initial Migration</span></strong><span>: Similar to option A, DataSync is not appropriate for database migrations that require CDC. AWS DMS should be used for both the initial load and ongoing replication.</span></p><p><span>D. </span><strong><span>Compute Optimized Replication Instance</span></strong><span>: While a compute-optimized instance might be beneficial for certain workloads, a memory-optimized instance is generally more suitable for handling high read/write operations and large datasets during database migrations. Additionally, selecting only the largest tables might not ensure that all necessary data remains in sync.</span></p><p><span>Using the AWS Schema Conversion Tool with AWS DMS and a memory-optimized replication instance, along with a full load plus CDC replication task, provides a comprehensive and efficient solution for migrating the database while keeping data in sync.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-236-designing-a-scalable-and-highly-available-solution-for-a-three-tier-application'><span>Question #236 Designing a scalable and highly available solution for a three-tier application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a three-tier application for image sharing. The application uses an Amazon EC2 instance for the front-end layer, another EC2 instance for the application layer, and a third EC2 instance for a MySQL database. A solutions architect must design a scalable and highly available solution that requires the least amount of change to the application.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><span>A. Use Amazon S3 to host the front-end layer. Use AWS Lambda functions for the application layer. Move the database to an Amazon DynamoDB table. Use Amazon S3 to store and serve users&#39; images.</span></p><p><span>B. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an Amazon RDS DB instance with multiple read replicas to serve users&#39; images.</span></p><p><span>C. Use Amazon S3 to host the front-end layer. Use a fleet of EC2 instances in an Auto Scaling group for the application layer. Move the database to a memory optimized instance type to store and serve users&#39; images.</span></p><p><span>D. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an Amazon RDS Multi-AZ DB instance. Use Amazon S3 to store and serve users&#39; images.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end layer and the application layer. Move the database to an Amazon RDS Multi-AZ DB instance. Use Amazon S3 to store and serve users&#39; images.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Elastic Beanstalk for Front-End and Application Layers</span></strong><span>: AWS Elastic Beanstalk provides an easy way to deploy and manage applications in the AWS cloud without worrying about the infrastructure. Using Elastic Beanstalk environments with load balancing and Multi-AZ deployment ensures high availability and scalability for both the front-end and application layers.</span></p></li><li><p><strong><span>Amazon RDS Multi-AZ for Database</span></strong><span>: Moving the MySQL database to an Amazon RDS Multi-AZ instance ensures high availability and fault tolerance for the database layer. RDS handles replication, failover, and maintenance, reducing operational overhead.</span></p></li><li><p><strong><span>Amazon S3 for Image Storage</span></strong><span>: Using Amazon S3 to store and serve users&#39; images is a scalable and cost-effective solution. S3 provides high durability, availability, and performance for storing large amounts of data, such as images.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Significant Changes to Application Architecture</span></strong><span>: This option requires significant changes to the application architecture, including moving to serverless (Lambda) and changing the database to DynamoDB. This does not meet the requirement of requiring the least amount of change.</span></p><p><span>B. </span><strong><span>Multiple Read Replicas for Images</span></strong><span>: While using Elastic Beanstalk for the front-end and application layers is a good choice, using multiple read replicas for the database to serve images is not optimal. S3 is a better choice for storing and serving static content like images.</span></p><p><span>C. </span><strong><span>Amazon S3 for Front-End and Memory Optimized Instance for Database</span></strong><span>: Hosting the front-end on S3 is suitable for static websites but may require changes to the application. Using a memory-optimized instance for the database does not inherently provide high availability and fault tolerance like RDS Multi-AZ.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-237-secure-access-between-ec2-instances-in-separate-vpcs-and-aws-accounts'><span>Question #237 Secure access between EC2 instances in separate VPCs and AWS accounts</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An application running on an Amazon EC2 instance in VPC-A needs to access files in another EC2 instance in VPC-B. Both VPCs are in separate AWS accounts. The network administrator needs to design a solution to configure secure access to the EC2 instance in VPC-B from VPC-A. The connectivity should not have a single point of failure or bandwidth concerns. Which solution will meet these requirements?</span></p><p><span>A. Set up a VPC peering connection between VPC-A and VPC-B.</span></p><p><span>B. Set up VPC gateway endpoints for the EC2 instance running in VPC-B.</span></p><p><span>C. Attach a virtual private gateway to VPC-B and set up routing from VPC-A.</span></p><p><span>D. Create a private virtual interface (VIF) for the EC2 instance running in VPC-B and add appropriate routes from VPC-A.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Set up a VPC peering connection between VPC-A and VPC-B.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>VPC Peering</span></strong><span>: VPC peering allows direct network connectivity between VPCs in the same AWS account or different AWS accounts. It provides a secure and private way to route traffic between VPCs without exposing the traffic to the internet. This ensures that the application in VPC-A can securely access the EC2 instance in VPC-B.</span></p></li><li><p><strong><span>No Single Point of Failure</span></strong><span>: VPC peering is a highly available and redundant solution that does not have a single point of failure. It leverages the AWS backbone network, which ensures high availability and low latency.</span></p></li><li><p><strong><span>Bandwidth Concerns</span></strong><span>: VPC peering connections utilize the AWS backbone network, which provides high bandwidth and low latency, addressing any bandwidth concerns.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>VPC Gateway Endpoints</span></strong><span>: VPC gateway endpoints are used to connect VPCs to AWS services such as S3 and DynamoDB privately, without using an internet gateway. They are not suitable for connecting two EC2 instances in different VPCs.</span></p><p><span>C. </span><strong><span>Virtual Private Gateway</span></strong><span>: Attaching a virtual private gateway to VPC-B and setting up routing from VPC-A is more suited for connecting an on-premises network to a VPC rather than connecting two VPCs. It introduces unnecessary complexity and does not provide the same level of redundancy as VPC peering.</span></p><p><span>D. </span><strong><span>Private Virtual Interface (VIF)</span></strong><span>: A private virtual interface is used for Direct Connect to establish a private connection between an on-premises network and AWS. It is not suitable for connecting two VPCs within AWS and would not address the requirement for no single point of failure or bandwidth concerns.</span></p><p><span>Setting up a VPC peering connection between VPC-A and VPC-B provides a secure, highly available, and high-bandwidth solution for connecting EC2 instances in separate VPCs and AWS accounts.</span></p><hr /><h3 id='question-238-monitoring-ec2-instance-usage-with-cost-effective-notifications'><span>Question #238 Monitoring EC2 instance usage with cost-effective notifications</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to experiment with individual AWS accounts for its engineer team. The company wants to be notified as soon as the Amazon EC2 instance usage for a given month exceeds a specific threshold for each account.</span></p><p><strong><span>What should a solutions architect do to meet this requirement MOST cost-effectively?</span></strong></p><p><span>A. Use Cost Explorer to create a daily report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded.</span></p><p><span>B. Use Cost Explorer to create a monthly report of costs by service. Filter the report by EC2 instances. Configure Cost Explorer to send an Amazon Simple Email Service (Amazon SES) notification when a threshold is exceeded.</span></p><p><span>C. Use AWS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded.</span></p><p><span>D. Use AWS Cost and Usage Reports to create a report with hourly granularity. Integrate the report data with Amazon Athena. Use Amazon EventBridge to schedule an Athena query. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use AWS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Budgets</span></strong><span>: AWS Budgets allows you to set custom cost and usage budgets that alert you when you exceed your thresholds. It is designed specifically for this purpose and is cost-effective.</span></p></li><li><p><strong><span>Monthly Period and Scope to EC2 Instances</span></strong><span>: By setting the period to monthly and the scope to EC2 instances, you can monitor the specific usage and costs for EC2 instances on a monthly basis.</span></p></li><li><p><strong><span>Alert Threshold and SNS Notification</span></strong><span>: Setting an alert threshold ensures that you are notified as soon as the usage exceeds the specified limit. Using Amazon SNS for notifications allows for easy integration with various notification channels, such as email or SMS.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Daily Report with Cost Explorer</span></strong><span>: While Cost Explorer can generate reports, it is not designed for real-time or threshold-based notifications. It also does not provide the same level of integration and automation as AWS Budgets.</span></p><p><span>B. </span><strong><span>Monthly Report with Cost Explorer</span></strong><span>: Similar to option A, Cost Explorer is not designed for threshold-based notifications and lacks the automation and integration capabilities of AWS Budgets.</span></p><p><span>D. </span><strong><span>Cost and Usage Reports with Athena and EventBridge</span></strong><span>: This approach is more complex and involves multiple services, including Athena for querying and EventBridge for scheduling. It is not as cost-effective or straightforward as using AWS Budgets for this specific requirement.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-239-deploy-a-microservice-with-iam-authentication-using-aws-lambda'><span>Question #239 Deploy a microservice with IAM authentication using AWS Lambda</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect needs to design a new microservice for a company&#39;s application. Clients must be able to call an HTTPS endpoint to reach the microservice. The microservice also must use AWS Identity and Access Management (IAM) to authenticate calls. The solutions architect will write the logic for this microservice by using a single AWS Lambda function that is written in Go 1.x. Which solution will deploy the function in the most operationally efficient way?</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Create an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API.</span></p><p><span>B. Create a Lambda function URL for the function. Specify AWS_IAM as the authentication type.</span></p><p><span>C. Create an Amazon CloudFront distribution. Deploy the function to Lambda@Edge. Integrate IAM authentication logic into the Lambda@Edge function.</span></p><p><span>D. Create an Amazon CloudFront distribution. Deploy the function to CloudFront Functions. Specify AWS_IAM as the authentication type.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>A. Create an Amazon API Gateway REST API. Configure the method to use the Lambda function. Enable IAM authentication on the API.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon API Gateway REST API (Option A)</span></strong><span>: Creating an Amazon API Gateway REST API and configuring it to use the Lambda function is the most operationally efficient way to deploy the microservice. API Gateway provides a fully managed service to create, publish, maintain, monitor, and secure APIs at any scale. Enabling IAM authentication on the API ensures that only authenticated IAM users can call the API, thereby securing the microservice.</span></p></li><li><p><strong><span>Lambda Function URL (Option B)</span></strong><span>: While creating a Lambda function URL with IAM authentication is a simpler approach, it may not provide the same level of features and control as API Gateway for managing the API lifecycle.</span></p></li><li><p><strong><span>CloudFront Distribution with Lambda@Edge (Option C)</span></strong><span>: This approach is more complex and is typically used for content delivery and edge computing rather than for deploying microservices with IAM authentication.</span></p></li><li><p><strong><span>CloudFront Distribution with CloudFront Functions (Option D)</span></strong><span>: Similar to Option C, this approach is not suitable for deploying microservices with IAM authentication and adds unnecessary complexity.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Lambda Function URL</span></strong><span>: While creating a Lambda function URL with IAM authentication is a simpler approach, it may not provide the same level of features and control as API Gateway for managing the API lifecycle. API Gateway offers more advanced features such as request validation, throttling, and monitoring.</span></p><p><span>C. </span><strong><span>CloudFront Distribution with Lambda@Edge</span></strong><span>: This approach is more complex and is typically used for content delivery and edge computing rather than for deploying microservices with IAM authentication. It also introduces additional latency and complexity in managing the distribution and the Lambda@Edge function.</span></p><p><span>D. </span><strong><span>CloudFront Distribution with CloudFront Functions</span></strong><span>: Similar to Option C, this approach is not suitable for deploying microservices with IAM authentication and adds unnecessary complexity. CloudFront Functions are designed for lightweight request processing at the edge and do not provide the same capabilities as API Gateway for managing and securing APIs.</span></p><p><span>Using API Gateway with Lambda provides a robust, scalable, and secure solution for deploying the microservice with IAM authentication.</span></p><p>&nbsp;</p><hr /><h3 id='question-240-minimizing-data-transfer-egress-cost-for-a-data-warehouse-solution'><span>Question #240 Minimizing data transfer egress cost for a data warehouse solution</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company previously migrated its data warehouse solution to AWS. The company also has an AWS Direct Connect connection. Corporate office users query the data warehouse using a visualization tool. The average size of a query returned by the data warehouse is 50 MB and each webpage sent by the visualization tool is approximately 500 KB. Result sets returned by the data warehouse are not cached.</span></p><p><strong><span>Which solution provides the LOWEST data transfer egress cost for the company?</span></strong></p><p><span>A. Host the visualization tool on premises and query the data warehouse directly over the internet.</span></p><p><span>B. Host the visualization tool in the same AWS Region as the data warehouse. Access it over the internet.</span></p><p><span>C. Host the visualization tool on premises and query the data warehouse directly over a Direct Connect connection at a location in the same AWS Region.</span></p><p><span>D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Direct Connect</span></strong><span>: Direct Connect provides a dedicated network connection from your premises to AWS. It can reduce network costs, increase bandwidth throughput, and provide a more consistent network experience than internet-based connections.</span></p></li><li><p><strong><span>Same AWS Region</span></strong><span>: Hosting the visualization tool in the same AWS Region as the data warehouse minimizes data transfer costs within the AWS network. Data transfer within the same region is typically free or very low cost.</span></p></li><li><p><strong><span>Direct Connect Egress Costs</span></strong><span>: Using Direct Connect for data transfer out of AWS to on-premises locations is generally cheaper than using the public internet. Since the visualization tool will be hosted within the same AWS region, the data transfer between the data warehouse and the visualization tool will be minimal.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Internet Data Transfer Costs</span></strong><span>: Hosting the visualization tool on premises and querying the data warehouse over the internet incurs higher data transfer egress costs compared to Direct Connect.</span></p><p><span>B. </span><strong><span>Internet Access Costs</span></strong><span>: Accessing the visualization tool over the internet, even within the same AWS region, can incur higher data transfer costs than using Direct Connect.</span></p><p><span>C. </span><strong><span>On-Premises Hosting with Direct Connect</span></strong><span>: While this reduces internet egress costs, it still involves transferring large query results (50 MB) over Direct Connect, which could be more expensive compared to hosting the visualization tool within the same AWS region.</span></p><p><span>By hosting the visualization tool in the same AWS region as the data warehouse and accessing it over Direct Connect, the company can minimize data transfer egress costs effectively.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-241-ensuring-high-availability-and-multi-region-data-access-for-postgresql-database'><span>Question #241 Ensuring high availability and multi-region data access for PostgreSQL database</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An online learning company is migrating to the AWS Cloud. The company maintains its student records in a PostgreSQL database. The company needs a solution in which its data is available and online across multiple AWS Regions at all times.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST amount of operational overhead?</span></strong></p><p><span>A. Migrate the PostgreSQL database to a PostgreSQL cluster on Amazon EC2 instances.</span></p><p><span>B. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance with the Multi-AZ feature turned on.</span></p><p><span>C. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.</span></p><p><span>D. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Set up DB snapshots to be copied to another Region.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon RDS for PostgreSQL with Read Replica</span></strong><span>:</span></p><ul><li><p><strong><span>Cross-Region Read Replica</span></strong><span>: Creating a read replica in another AWS Region ensures that the data is available and online across multiple regions. This setup provides high availability and disaster recovery capabilities.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: Amazon RDS manages the replication process, reducing the operational overhead compared to managing replication manually on EC2 instances.</span></p></li></ul></li><li><p><strong><span>Benefits of Read Replicas</span></strong><span>:</span></p><ul><li><p><strong><span>Availability</span></strong><span>: Read replicas in another region can be promoted to standalone databases in case of a primary region failure, ensuring data availability.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: Read replicas can also be used to offload read traffic, improving performance.</span></p></li></ul></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>PostgreSQL Cluster on EC2 Instances</span></strong><span>: Managing a PostgreSQL cluster on EC2 instances requires significant operational overhead, including setup, maintenance, and replication management.</span></p><p><span>B. </span><strong><span>Multi-AZ Feature</span></strong><span>: The Multi-AZ feature for Amazon RDS provides high availability within a single region but does not provide multi-region availability.</span></p><p><span>D. </span><strong><span>DB Snapshots</span></strong><span>: Setting up DB snapshots to be copied to another region provides data backup but does not ensure that the database is continuously online and available across multiple regions. Snapshots are point-in-time backups and do not provide real-time data access.</span></p><p><span>By migrating the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance and creating a read replica in another region, the company can achieve multi-region availability with minimal operational overhead.</span></p><p>&nbsp;</p><hr /><h3 id='question-242-dns-routing-policy-for-returning-ip-addresses-of-all-healthy-ec2-instances'><span>Question #242 DNS routing policy for returning IP addresses of all healthy EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts its web application on AWS using seven Amazon EC2 instances. The company requires that the IP addresses of all healthy EC2 instances be returned in response to DNS queries. Which policy should be used to meet this requirement?</span></p><p><span>A. Simple routing policy</span></p><p><span>B. Latency routing policy</span></p><p><span>C. Multivalue routing policy</span></p><p><span>D. Geolocation routing policy</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Multivalue routing policy</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Multivalue Routing Policy</span></strong><span>: The multivalue answer routing policy in Amazon Route 53 allows you to configure multiple IP addresses for your DNS records. When a DNS query is made, Route 53 returns multiple IP addresses. Additionally, you can associate health checks with each IP address to ensure that only the IP addresses of healthy instances are returned.</span></p></li><li><p><strong><span>Health Checks</span></strong><span>: By configuring health checks for each EC2 instance, Route 53 ensures that only the IP addresses of healthy instances are included in the DNS responses. This aligns with the requirement to return the IP addresses of all healthy EC2 instances.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Simple Routing Policy</span></strong><span>: The simple routing policy returns a single IP address in response to a DNS query. It does not support returning multiple IP addresses or associating health checks with each IP address.</span></p><p><span>B. </span><strong><span>Latency Routing Policy</span></strong><span>: The latency routing policy routes traffic based on the lowest latency between the user and the AWS region. It does not ensure that all healthy IP addresses are returned in the DNS response.</span></p><p><span>D. </span><strong><span>Geolocation Routing Policy</span></strong><span>: The geolocation routing policy routes traffic based on the geographic location of the user. It does not ensure that all healthy IP addresses are returned in the DNS response.</span></p><p><span>Using the multivalue routing policy with health checks ensures that the IP addresses of all healthy EC2 instances are returned in response to DNS queries, meeting the company&#39;s requirements.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-243-providing-low-latency-access-to-s3-data-for-on-premises-file-based-applications'><span>Question #243 Providing low-latency access to S3 data for on-premises file-based applications</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A medical research lab produces data that is related to a new study. The lab wants to make the data available with minimum latency to clinics across the country for their on-premises, file-based applications. The data files are stored in an Amazon S3 bucket that has read-only permissions for each clinic.</span></p><p><strong><span>What should a solutions architect recommend to meet these requirements?</span></strong></p><p><span>A. Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic.</span></p><p><span>B. Migrate the files to each clinic&#39;s on-premises applications by using AWS DataSync for processing.</span></p><p><span>C. Deploy an AWS Storage Gateway volume gateway as a virtual machine (VM) on premises at each clinic.</span></p><p><span>D. Attach an Amazon Elastic File System (Amazon EFS) file system to each clinic&#39;s on-premises servers.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Deploy an AWS Storage Gateway file gateway as a virtual machine (VM) on premises at each clinic.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Storage Gateway File Gateway</span></strong><span>: The file gateway provides a seamless way to access Amazon S3 objects as files from on-premises applications. It allows on-premises applications to access data stored in S3 with low latency by caching frequently accessed data locally.</span></p></li><li><p><strong><span>Low Latency and File-Based Access</span></strong><span>: By deploying a file gateway as a VM on premises at each clinic, the clinics can access the data with minimal latency. The file gateway caches the frequently accessed data locally, reducing the time it takes to access the data.</span></p></li><li><p><strong><span>Read-Only Permissions</span></strong><span>: The data in the S3 bucket can be accessed in a read-only manner via the file gateway, ensuring that the clinics can access the data without modifying it.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>AWS DataSync</span></strong><span>: DataSync is designed for migrating data between on-premises storage and AWS storage services. It is not intended for providing low-latency, ongoing access to data.</span></p><p><span>C. </span><strong><span>AWS Storage Gateway Volume Gateway</span></strong><span>: The volume gateway is designed for block storage and is not optimized for file-based access. It is more suitable for use cases involving block storage volumes.</span></p><p><span>D. </span><strong><span>Amazon EFS</span></strong><span>: Amazon EFS is a scalable file storage service for use with AWS Cloud services and on-premises resources. However, attaching EFS to on-premises servers requires a VPN or Direct Connect connection, which may introduce latency and complexity compared to a file gateway.</span></p><p><span>By deploying an AWS Storage Gateway file gateway as a virtual machine on premises at each clinic, the solution provides low-latency access to the data stored in Amazon S3, meeting the requirements of the medical research lab.</span></p><p>&nbsp;</p><hr /><h3 id='question-244-high-availability-and-scalability-for-a-content-management-system-on-aws'><span>Question #244 High availability and scalability for a content management system on AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is using a content management system that runs on a single Amazon EC2 instance. The EC2 instance contains both the web server and the database software. The company must make its website platform highly available and must enable the website to scale to meet user demand. What should a solutions architect recommend to meet these requirements?</span></p><p><span>A. Move the database to Amazon RDS, and enable automatic backups. Manually launch another EC2 instance in the same Availability Zone. Configure an Application Load Balancer in the Availability Zone, and set the two instances as targets.</span></p><p><span>B. Migrate the database to an Amazon Aurora instance with a read replica in the same Availability Zone as the existing EC2 instance. Manually launch another EC2 instance in the same Availability Zone. Configure an Application Load Balancer, and set the two EC2 instances as targets.</span></p><p><span>C. Move the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.</span></p><p><span>D. Move the database to a separate EC2 instance, and schedule backups to Amazon S3. Create an Amazon Machine Image (AMI) from the original EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Move the database to Amazon Aurora with a read replica in another Availability Zone. Create an Amazon Machine Image (AMI) from the EC2 instance. Configure an Application Load Balancer in two Availability Zones. Attach an Auto Scaling group that uses the AMI across two Availability Zones.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Aurora with Read Replica</span></strong><span>: Moving the database to Amazon Aurora with a read replica in another Availability Zone ensures high availability and fault tolerance for the database. Aurora is a managed database service that provides automatic backups, failover, and scalability.</span></p></li><li><p><strong><span>Amazon Machine Image (AMI)</span></strong><span>: Creating an AMI from the existing EC2 instance allows for easy replication of the web server across multiple instances.</span></p></li><li><p><strong><span>Application Load Balancer (ALB)</span></strong><span>: Configuring an ALB across two Availability Zones ensures that traffic is distributed evenly across multiple instances, providing high availability and scalability.</span></p></li><li><p><strong><span>Auto Scaling Group</span></strong><span>: Attaching an Auto Scaling group that uses the AMI across two Availability Zones allows the web server to automatically scale in response to user demand. This ensures that the website can handle varying levels of traffic and maintain high availability.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Single Availability Zone</span></strong><span>: Manually launching another EC2 instance in the same Availability Zone does not provide high availability. If the Availability Zone experiences an outage, both instances will be affected.</span></p><p><span>B. </span><strong><span>Single Availability Zone Read Replica</span></strong><span>: Having a read replica in the same Availability Zone does not provide high availability. The solution must span multiple Availability Zones to ensure fault tolerance.</span></p><p><span>D. </span><strong><span>Separate EC2 Instance for Database</span></strong><span>: Moving the database to a separate EC2 instance and scheduling backups to Amazon S3 is less ideal compared to using Aurora for managed backups and high availability. Additionally, this option does not provide the same level of scalability and fault tolerance as using Aurora with a read replica in another Availability Zone.</span></p><p><span>Using Amazon Aurora with a read replica in another Availability Zone, an Application Load Balancer, and an Auto Scaling group provides a robust solution for high availability and scalability for the content management system.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-245-cost-effective-configuration-for-a-development-environment-with-alb-and-ec2-instances'><span>Question #245 Cost-effective configuration for a development environment with ALB and EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is launching an application on AWS. The application uses an Application Load Balancer (ALB) to direct traffic to at least two Amazon EC2 instances in a single target group. The instances are in an Auto Scaling group for each environment. The company requires a development environment and a production environment. The production environment will have periods of high traffic.</span></p><p><strong><span>Which solution will configure the development environment MOST cost-effectively?</span></strong></p><p><strong><span>Options:</span></strong></p><p><span>A. Reconfigure the target group in the development environment to have only one EC2 instance as a target.</span></p><p><span>B. Change the ALB balancing algorithm to least outstanding requests.</span></p><p><span>C. Reduce the size of the EC2 instances in both environments.</span></p><p><span>D. Reduce the maximum number of EC2 instances in the development environment&#39;s Auto Scaling group.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>D. Reduce the maximum number of EC2 instances in the development environment&#39;s Auto Scaling group.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Reducing the Maximum Number of Instances (Option D)</span></strong><span>: Reducing the maximum number of EC2 instances in the development environment&#39;s Auto Scaling group is the most cost-effective solution. This approach ensures that the development environment only runs the minimum number of instances required to handle its workload, thereby reducing costs while maintaining the benefits of Auto Scaling, such as automatic instance replacement in case of failures.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Single EC2 Instance in Target Group</span></strong><span>: Reconfiguring the target group to have only one EC2 instance can save costs but sacrifices the redundancy and availability that Auto Scaling provides. In a development environment, having at least two instances can be beneficial for testing scenarios that involve load balancing and failover.</span></p><p><span>B. </span><strong><span>Changing ALB Balancing Algorithm</span></strong><span>: Changing the ALB balancing algorithm to least outstanding requests is a performance optimization technique and does not directly contribute to cost savings. It helps in distributing traffic more efficiently but does not reduce the number of instances or their operational costs.</span></p><p><span>C. </span><strong><span>Reducing EC2 Instance Size</span></strong><span>: Reducing the size of the EC2 instances in both environments may save costs but can affect the performance, especially in the production environment during high traffic periods. Additionally, this option does not specifically target cost reduction in the development environment.</span></p><p><span>By reducing the maximum number of EC2 instances in the Auto Scaling group for the development environment, the company can effectively manage costs while still benefiting from the scalability and redundancy features provided by Auto Scaling.</span></p><p>&nbsp;</p><hr /><h3 id='question-246-resolving-internet-traffic-issue-for-ec2-instances-behind-an-alb'><span>Question #246 Resolving internet traffic issue for EC2 instances behind an ALB</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs a web application on Amazon EC2 instances in multiple Availability Zones. The EC2 instances are in private subnets. A solutions architect implements an internet-facing Application Load Balancer (ALB) and specifies the EC2 instances as the target group. However, the internet traffic is not reaching the EC2 instances. How should the solutions architect reconfigure the architecture to resolve this issue?</span></p><p><span>A. Replace the ALB with a Network Load Balancer. Configure a NAT gateway in a public subnet to allow internet traffic.</span></p><p><span>B. Move the EC2 instances to public subnets. Add a rule to the EC2 instances&#39; security groups to allow outbound traffic to 0.0.0.0/0.</span></p><p><span>C. Update the route tables for the EC2 instances&#39; subnets to send 0.0.0.0/0 traffic through the internet gateway route. Add a rule to the EC2 instances&#39; security groups to allow outbound traffic to 0.0.0.0/0.</span></p><p><span>D. Create public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Create public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Public Subnets for ALB</span></strong><span>: An internet-facing Application Load Balancer (ALB) needs to be associated with public subnets to receive traffic from the internet. Public subnets have a route to an internet gateway, allowing them to receive inbound traffic from the internet.</span></p></li><li><p><strong><span>Private Subnets for EC2 Instances</span></strong><span>: The EC2 instances can remain in private subnets for security purposes. The ALB will forward the traffic to the EC2 instances in the private subnets.</span></p></li><li><p><strong><span>Route Table Configuration</span></strong><span>: The route tables for the public subnets should have a route to the internet gateway (0.0.0.0/0) to allow inbound traffic. The ALB in the public subnets can then forward the traffic to the EC2 instances in the private subnets.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Network Load Balancer and NAT Gateway</span></strong><span>: Replacing the ALB with a Network Load Balancer and configuring a NAT gateway is not necessary. The issue is with the ALB being in private subnets, not the type of load balancer.</span></p><p><span>B. </span><strong><span>Moving EC2 Instances to Public Subnets</span></strong><span>: Moving the EC2 instances to public subnets is not recommended for security reasons. EC2 instances in public subnets are directly accessible from the internet, which increases the attack surface.</span></p><p><span>C. </span><strong><span>Updating Route Tables for Private Subnets</span></strong><span>: Updating the route tables for the private subnets to send traffic through the internet gateway is not appropriate. Private subnets are meant to keep EC2 instances isolated from direct internet access.</span></p><p><span>By creating public subnets for the ALB and ensuring proper routing, the internet-facing ALB can receive traffic and forward it to the EC2 instances in the private subnets, resolving the issue.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-247-preparing-to-add-a-read-replica-to-an-rds-for-mysql-instance'><span>Question #247 Preparing to add a read replica to an RDS for MySQL instance</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has deployed a database in Amazon RDS for MySQL. Due to increased transactions, the database support team is reporting slow reads against the DB instance and recommends adding a read replica.</span></p><p><strong><span>Which combination of actions should a solutions architect take before implementing this change? (Choose two.)</span></strong></p><p><strong><span>Options:</span></strong></p><p><span>A. Enable binlog replication on the RDS primary node.</span></p><p><span>B. Choose a failover priority for the source DB instance.</span></p><p><span>C. Allow long-running transactions to complete on the source DB instance.</span></p><p><span>D. Create a global table and specify the AWS Regions where the table will be available.</span></p><p><span>E. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0.</span></p><p><strong><span>Correct answers:</span></strong></p><p><span>C. Allow long-running transactions to complete on the source DB instance.</span></p><p><span>E. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Allow Long-Running Transactions to Complete (Option C)</span></strong><span>: Before adding a read replica, it is important to allow any long-running transactions to complete. This ensures that the database is in a stable state and that the read replica will start with a consistent snapshot of the data.</span></p></li><li><p><strong><span>Enable Automatic Backups (Option E)</span></strong><span>: Enabling automatic backups on the source instance with a backup retention period greater than 0 ensures that the database can be restored in case of any issues during the read replica setup. It also allows the read replica to be created from a consistent snapshot of the primary database.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Enable Binlog Replication</span></strong><span>: While enabling binary logging is necessary for replication, in Amazon RDS for MySQL, this is automatically managed by AWS when you create a read replica. Therefore, it is not a manual step required by the solutions architect.</span></p><p><span>B. </span><strong><span>Choose a Failover Priority</span></strong><span>: Choosing a failover priority for the source DB instance is related to Multi-AZ deployments for high availability and does not directly impact the creation of read replicas.</span></p><p><span>D. </span><strong><span>Create a Global Table</span></strong><span>: Creating a global table is not relevant to setting up read replicas in Amazon RDS for MySQL. Global tables are used in Amazon DynamoDB for multi-region replication.</span></p><p><span>By allowing long-running transactions to complete and enabling automatic backups on the source RDS instance, the solutions architect ensures that the database is prepared for the addition of a read replica, facilitating data consistency and recovery options.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-248-improving-performance-and-scaling-for-analytics-software-on-ec2-instances'><span>Question #248 Improving performance and scaling for analytics software on EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs analytics software on Amazon EC2 instances. The software accepts job requests from users to process data that has been uploaded to Amazon S3. Users report that some submitted data is not being processed. Amazon CloudWatch reveals that the EC2 instances have a consistent CPU utilization at or near 100%. The company wants to improve system performance and scale the system based on user load. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Create a copy of the instance. Place all instances behind an Application Load Balancer.</span></p><p><span>B. Create an S3 VPC endpoint for Amazon S3. Update the software to reference the endpoint.</span></p><p><span>C. Stop the EC2 instances. Modify the instance type to one with a more powerful CPU and more memory. Restart the instances.</span></p><p><span>D. Route incoming requests to Amazon Simple Queue Service (Amazon SQS). Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Route incoming requests to Amazon Simple Queue Service (Amazon SQS). Configure an EC2 Auto Scaling group based on queue size. Update the software to read from the queue.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SQS for Decoupling Requests</span></strong><span>: By routing incoming requests to Amazon SQS, you can decouple the job requests from the processing instances. This allows for better handling of varying user load and ensures that all requests are queued up for processing.</span></p></li><li><p><strong><span>Auto Scaling Group Based on Queue Size</span></strong><span>: Configuring an EC2 Auto Scaling group based on the size of the SQS queue allows the system to dynamically scale the number of EC2 instances based on the load. When the queue size increases, more instances are launched to handle the increased load, and when the queue size decreases, instances are terminated to save costs.</span></p></li><li><p><strong><span>Improved Performance and Scalability</span></strong><span>: This approach ensures that the system can handle spikes in user requests without overwhelming the EC2 instances. It also provides a scalable solution that adjusts to the workload, improving overall system performance and user experience.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Application Load Balancer</span></strong><span>: Simply creating a copy of the instance and placing all instances behind an Application Load Balancer does not address the issue of scaling based on user load. It also does not handle the queuing of job requests.</span></p><p><span>B. </span><strong><span>S3 VPC Endpoint</span></strong><span>: Creating an S3 VPC endpoint may improve network performance and reduce costs but does not address the core issue of high CPU utilization and scaling based on user load.</span></p><p><span>C. </span><strong><span>More Powerful Instance Type</span></strong><span>: Upgrading to a more powerful instance type may temporarily alleviate the high CPU utilization but does not provide a scalable solution. As user load increases, the upgraded instances may also become overwhelmed.</span></p><p><span>By using Amazon SQS and an EC2 Auto Scaling group, the solution architect can create a robust, scalable, and efficient system that meets the company&#39;s requirements for improved performance and scalability based on user load.</span></p><p>&nbsp;</p><hr /><h3 id='question-249-implementing-a-shared-storage-solution-with-smb-access'><span>Question #249 Implementing a shared storage solution with SMB access</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is implementing a shared storage solution for a media application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed.</span></p><p><strong><span>Which AWS solution meets these requirements?</span></strong></p><p><span>A. Create an AWS Storage Gateway volume gateway. Create a file share that uses the required client protocol. Connect the application server to the file share.</span></p><p><span>B. Create an AWS Storage Gateway tape gateway. Configure tapes to use Amazon S3. Connect the application server to the tape gateway.</span></p><p><span>C. Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.</span></p><p><span>D. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon FSx for Windows File Server</span></strong><span>:</span></p><ul><li><p><strong><span>Fully Managed</span></strong><span>: Amazon FSx for Windows File Server provides fully managed Windows file systems that are accessible via the SMB protocol. This service is designed to be fully managed, which aligns with the requirement of the company.</span></p></li><li><p><strong><span>SMB Protocol</span></strong><span>: It natively supports the SMB protocol, making it easy for SMB clients to access the shared storage.</span></p></li></ul></li><li><p><strong><span>Suitable for Media Applications</span></strong><span>: Amazon FSx for Windows File Server is optimized for a wide range of workloads, including media applications that require high throughput and consistent performance.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Storage Gateway Volume Gateway</span></strong><span>: While Storage Gateway volume gateway can provide shared storage, it is primarily used for block storage and does not natively support SMB for file sharing.</span></p><p><span>B. </span><strong><span>AWS Storage Gateway Tape Gateway</span></strong><span>: Tape Gateway is designed for backup and archival purposes using virtual tapes and is not suitable for providing shared file storage with SMB access.</span></p><p><span>C. </span><strong><span>Amazon EC2 Windows Instance</span></strong><span>: Setting up a Windows file share on an EC2 instance requires manual management and maintenance, which does not meet the requirement of a fully managed solution.</span></p><p><span>By using Amazon FSx for Windows File Server, the company can implement a shared storage solution that is fully managed and accessible via SMB clients, meeting their requirements effectively.</span></p><p>&nbsp;</p><hr /><h3 id='question-250-capturing-vpc-flow-logs-with-frequent-and-intermittent-access'><span>Question #250 Capturing VPC Flow Logs with frequent and intermittent access</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company&#39;s security team requests that network traffic be captured in VPC Flow Logs. The logs will be frequently accessed for 90 days and then accessed intermittently. What should a solutions architect do to meet these requirements when configuring the logs?</span></p><p><span>A. Use Amazon CloudWatch as the target. Set the CloudWatch log group with an expiration of 90 days.</span></p><p><span>B. Use Amazon Kinesis as the target. Configure the Kinesis stream to always retain the logs for 90 days.</span></p><p><span>C. Use AWS CloudTrail as the target. Configure CloudTrail to save to an Amazon S3 bucket, and enable S3 Intelligent-Tiering.</span></p><p><span>D. Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use Amazon S3 as the target. Enable an S3 Lifecycle policy to transition the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3 as the Target</span></strong><span>: Storing VPC Flow Logs in Amazon S3 is a cost-effective solution that allows for easy access and long-term retention. S3 is highly durable and scalable, making it suitable for storing large volumes of log data.</span></p></li><li><p><strong><span>S3 Lifecycle Policy</span></strong><span>: By configuring an S3 Lifecycle policy, you can automatically transition the logs to a different storage class based on their age. In this case, transitioning the logs to S3 Standard-Infrequent Access (S3 Standard-IA) after 90 days ensures cost savings for infrequently accessed data while still providing quick access when needed.</span></p></li><li><p><strong><span>Cost Efficiency and Accessibility</span></strong><span>: Using S3 Standard-IA for logs that are accessed intermittently after 90 days reduces storage costs compared to keeping them in S3 Standard. This approach balances cost efficiency with the need for occasional access to the logs.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon CloudWatch</span></strong><span>: Using CloudWatch for storing VPC Flow Logs with an expiration of 90 days is not cost-effective for long-term storage. CloudWatch is more suitable for short-term monitoring and alerting rather than long-term log retention.</span></p><p><span>B. </span><strong><span>Amazon Kinesis</span></strong><span>: Kinesis is designed for real-time data streaming and processing, not long-term log storage. Configuring Kinesis to retain logs for 90 days is not practical and would be more expensive compared to using S3 with a lifecycle policy.</span></p><p><span>C. </span><strong><span>AWS CloudTrail</span></strong><span>: CloudTrail is used for logging API calls and user activity within AWS, not for capturing network traffic in VPC Flow Logs. While it can save logs to an S3 bucket, it is not the appropriate service for this use case.</span></p><p><span>By using Amazon S3 with a lifecycle policy to transition logs to S3 Standard-IA after 90 days, the solutions architect can meet the requirements for frequent access initially and intermittent access later, while optimizing storage costs.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-251-enabling-outbound-internet-access-for-an-ec2-instance-in-a-private-subnet'><span>Question #251 Enabling outbound internet access for an EC2 instance in a private subnet</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An Amazon EC2 instance is located in a private subnet in a new VPC. This subnet does not have outbound internet access, but the EC2 instance needs the ability to download monthly security updates from an outside vendor. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Create an internet gateway, and attach it to the VPC. Configure the private subnet route table to use the internet gateway as the default route.</span></p><p><span>B. Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.</span></p><p><span>C. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the NAT instance as the default route.</span></p><p><span>D. Create an internet gateway, and attach it to the VPC. Create a NAT instance, and place it in the same subnet where the EC2 instance is located. Configure the private subnet route table to use the internet gateway as the default route.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create a NAT gateway, and place it in a public subnet. Configure the private subnet route table to use the NAT gateway as the default route.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>NAT Gateway</span></strong><span>: A NAT gateway allows instances in a private subnet to initiate outbound traffic to the internet while preventing inbound traffic from the internet. This is the recommended solution for providing internet access to instances in a private subnet.</span></p></li><li><p><strong><span>Public Subnet</span></strong><span>: The NAT gateway must be placed in a public subnet, which has a route to the internet gateway. This ensures that the NAT gateway can route traffic to and from the internet.</span></p></li><li><p><strong><span>Private Subnet Route Table</span></strong><span>: The route table for the private subnet should have a route that directs all internet-bound traffic (0.0.0.0/0) to the NAT gateway. This allows the EC2 instances in the private subnet to use the NAT gateway for outbound internet access.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Internet Gateway for Private Subnet</span></strong><span>: Configuring the private subnet route table to use the internet gateway as the default route would make the subnet public, exposing the EC2 instances to inbound internet traffic, which is not secure.</span></p><p><span>C. </span><strong><span>NAT Instance in Private Subnet</span></strong><span>: Placing a NAT instance in the same private subnet as the EC2 instance does not provide internet access, as the private subnet itself does not have a route to the internet gateway. NAT instances should be placed in a public subnet.</span></p><p><span>D. </span><strong><span>Internet Gateway and NAT Instance in Private Subnet</span></strong><span>: Configuring the private subnet route table to use the internet gateway as the default route, even with a NAT instance, would still expose the private subnet to inbound internet traffic, which is not secure.</span></p><p><span>By creating a NAT gateway in a public subnet and updating the private subnet&#39;s route table to use the NAT gateway as the default route, the solutions architect can provide secure outbound internet access for the EC2 instance to download monthly security updates.</span></p><p>&nbsp;</p><hr /><h3 id='question-252-designing-a-system-to-store-and-access-client-case-files-with-redundancy'><span>Question #252 Designing a system to store and access client case files with redundancy</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect needs to design a system to store client case files. The files are core company assets and are important. The number of files will grow over time. The files must be simultaneously accessible from multiple application servers that run on Amazon EC2 instances. The solution must have built-in redundancy.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><span>A. Amazon Elastic File System (Amazon EFS)</span></p><p><span>B. Amazon Elastic Block Store (Amazon EBS)</span></p><p><span>C. Amazon S3 Glacier Deep Archive</span></p><p><span>D. AWS Backup</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Amazon Elastic File System (Amazon EFS)</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Elastic File System (Amazon EFS)</span></strong><span>:</span></p><ul><li><p><strong><span>Simultaneous Access</span></strong><span>: Amazon EFS is a fully managed file storage service that provides scalable file storage for use with Amazon EC2 instances. It supports simultaneous access from multiple EC2 instances, making it suitable for applications that require shared access to files.</span></p></li><li><p><strong><span>Built-in Redundancy</span></strong><span>: EFS automatically replicates data across multiple Availability Zones (AZs) within a region, providing built-in redundancy and high availability.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: EFS can scale automatically as the number of files grows, without requiring any manual intervention.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon Elastic Block Store (Amazon EBS)</span></strong><span>: EBS provides block storage for a single EC2 instance and does not support simultaneous access from multiple instances. It is not suitable for shared storage needs.</span></p></li><li><p><strong><span>Amazon S3 Glacier Deep Archive</span></strong><span>: S3 Glacier Deep Archive is designed for long-term archival storage with infrequent access. It is not suitable for use cases requiring simultaneous access and low-latency file operations.</span></p></li><li><p><strong><span>AWS Backup</span></strong><span>: AWS Backup is a service for centralized backup management across AWS services. It is not a storage solution for simultaneous access to files.</span></p></li></ul></li></ol><p><span>By using Amazon EFS, the solutions architect can design a system that meets the requirements for storing client case files with built-in redundancy and simultaneous access from multiple EC2 instances.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-253-understanding-iam-policies-and-actions'><span>Question #253 Understanding IAM Policies and Actions</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.</span></p><p><strong><span>Policy 1:</span></strong></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="json" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="json"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 32.5px; left: 26.5px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">{</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-string cm-property">"Version"</span>: <span class="cm-string">"2012-10-17"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-string cm-property">"Statement"</span>: [</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  {</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Effect"</span>: <span class="cm-string">"Allow"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Action"</span>: [</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string">"iam:Get*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string">"iam:List*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string">"kms:List*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string">"ec2:*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string">"ds:*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string">"logs:Get*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string">"logs:Describe*"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  ],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Resource"</span>: <span class="cm-string">"*"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  }</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  ]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">}</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 477px;"></div><div class="CodeMirror-gutters" style="display: none; height: 477px;"></div></div></div></pre><p><strong><span>Policy 2:</span></strong></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="json"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="json"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 32.5px; left: 26.5px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">{</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-string cm-property">"Version"</span>: <span class="cm-string">"2012-10-17"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-string cm-property">"Statement"</span>: [</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  {</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Effect"</span>: <span class="cm-string">"Deny"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Action"</span>: <span class="cm-string">"ds:Delete*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Resource"</span>: <span class="cm-string">"*"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  }</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  ]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">}</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 285px;"></div><div class="CodeMirror-gutters" style="display: none; height: 285px;"></div></div></div></pre><p><span>A cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Deleting IAM users</span></p><p><span>B. Deleting directories</span></p><p><span>C. Deleting Amazon EC2 instances</span></p><p><span>D. Deleting logs from Amazon CloudWatch Logs</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>C. Deleting Amazon EC2 instances</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Policy 1</span></strong><span> allows various actions on different services, including all actions on EC2 instances (</span><code>&quot;ec2:*&quot;</code><span>), which includes the ability to delete EC2 instances.</span></p></li><li><p><strong><span>Policy 2</span></strong><span> explicitly denies the action </span><code>&quot;ds:Delete*&quot;</code><span> on the </span><code>ds</code><span> (Directory Service), which means the cloud engineer cannot delete directories.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Deleting IAM users</span></strong><span>: Policy 1 allows </span><code>iam:Get*</code><span> and </span><code>iam:List*</code><span> actions but does not include </span><code>iam:Delete*</code><span> actions, so the cloud engineer cannot delete IAM users.</span></p><p><span>B. </span><strong><span>Deleting directories</span></strong><span>: Policy 2 explicitly denies any delete actions on Directory Service (</span><code>&quot;ds:Delete*&quot;</code><span>), so the cloud engineer cannot delete directories.</span></p><p><span>D. </span><strong><span>Deleting logs from Amazon CloudWatch Logs</span></strong><span>: Policy 1 allows </span><code>logs:Get*</code><span> and </span><code>logs:Describe*</code><span> actions but does not include </span><code>logs:Delete*</code><span> actions, so the cloud engineer cannot delete logs from Amazon CloudWatch Logs.</span></p><p><span>By analyzing the policies, we can determine that the cloud engineer will be able to perform the action of deleting Amazon EC2 instances, as this action is allowed by Policy 1 and not restricted by Policy 2.</span></p><p>&nbsp;</p><hr /><h3 id='question-254-applying-the-principle-of-least-privilege-to-ec2-security-group-rules'><span>Question #254 Applying the principle of least privilege to EC2 security group rules</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is reviewing a recent migration of a three-tier application to a VPC. The security team discovers that the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers.</span></p><p><strong><span>What should a solutions architect do to correct this issue?</span></strong></p><p><span>A. Create security group rules using the instance ID as the source or destination.</span></p><p><span>B. Create security group rules using the security group ID as the source or destination.</span></p><p><span>C. Create security group rules using the VPC CIDR blocks as the source or destination.</span></p><p><span>D. Create security group rules using the subnet CIDR blocks as the source or destination.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create security group rules using the security group ID as the source or destination.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Security Group ID as Source/Destination</span></strong><span>:</span></p><ul><li><p><strong><span>Principle of Least Privilege</span></strong><span>: Using security group IDs as the source or destination in security group rules allows for more granular control over network traffic. This approach ensures that only traffic from specific groups of instances is allowed, adhering to the principle of least privilege.</span></p></li><li><p><strong><span>Dynamic Membership</span></strong><span>: Security group rules that reference other security groups allow for dynamic membership. As instances are added or removed from the source security group, the rules automatically apply without needing updates.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Instance ID</span></strong><span>: Security group rules cannot use instance IDs directly as the source or destination. Security groups are designed to manage traffic at a higher level of abstraction.</span></p></li><li><p><strong><span>VPC CIDR Blocks</span></strong><span>: Using VPC CIDR blocks as the source or destination is too broad and does not enforce the principle of least privilege. It allows traffic from any instance within the VPC, which is not restrictive enough.</span></p></li><li><p><strong><span>Subnet CIDR Blocks</span></strong><span>: Similarly, using subnet CIDR blocks is broader than necessary and does not provide the fine-grained control required to enforce least privilege.</span></p></li></ul></li></ol><p><span>By creating security group rules using the security group ID as the source or destination, the solutions architect can ensure that the security group rules are more restrictive and aligned with the principle of least privilege. This approach limits access to only the necessary instances within specific security groups, enhancing the overall security posture of the application.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-255-preventing-multiple-orders-in-an-ecommerce-checkout-workflow'><span>Question #255 Preventing multiple orders in an ecommerce checkout workflow</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an ecommerce checkout workflow that writes an order to a database and calls a service to process the payment. Users are experiencing timeouts during the checkout process. When users resubmit the checkout form, multiple unique orders are created for the same desired transaction. How should a solutions architect refactor this workflow to prevent the creation of multiple orders?</span></p><p><span>A. Configure the web application to send an order message to Amazon Kinesis Data Firehose. Set the payment service to retrieve the message from Kinesis Data Firehose and process the order.</span></p><p><span>B. Create a rule in AWS CloudTrail to invoke an AWS Lambda function based on the logged application path request. Use Lambda to query the database, call the payment service, and pass in the order information.</span></p><p><span>C. Store the order in the database. Send a message that includes the order number to Amazon Simple Notification Service (Amazon SNS). Set the payment service to poll Amazon SNS, retrieve the message, and process the order.</span></p><p><span>D. Store the order in the database. Send a message that includes the order number to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the payment service to retrieve the message and process the order. Delete the message from the queue.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Store the order in the database. Send a message that includes the order number to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the payment service to retrieve the message and process the order. Delete the message from the queue.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SQS FIFO Queue</span></strong><span>: Using a FIFO (First-In-First-Out) queue ensures that messages are processed in the exact order they are sent and prevents duplicate messages from being processed. This is crucial for ensuring that each order is processed exactly once, even if users resubmit the checkout form.</span></p></li><li><p><strong><span>Message Deduplication</span></strong><span>: SQS FIFO queues support deduplication, which prevents the creation of multiple unique orders for the same transaction. This ensures that resubmitted checkout forms do not result in duplicate orders.</span></p></li><li><p><strong><span>Decoupling</span></strong><span>: By decoupling the order creation and payment processing using SQS, the system can handle timeouts and retries more gracefully. The payment service retrieves messages from the queue and processes them independently, ensuring reliable and consistent order processing.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon Kinesis Data Firehose</span></strong><span>: Kinesis Data Firehose is designed for real-time data streaming to destinations such as S3, Redshift, and Elasticsearch. It does not provide the same level of message ordering and deduplication guarantees as SQS FIFO queues.</span></p><p><span>B. </span><strong><span>AWS CloudTrail and Lambda</span></strong><span>: Using CloudTrail to invoke a Lambda function based on logged requests adds unnecessary complexity and does not provide the same level of message ordering and deduplication guarantees as SQS FIFO queues.</span></p><p><span>C. </span><strong><span>Amazon SNS</span></strong><span>: SNS is a pub/sub messaging service that is not designed for message ordering or deduplication. It is more suitable for broadcasting messages to multiple subscribers rather than ensuring exactly-once processing of messages.</span></p><p><span>By using an Amazon SQS FIFO queue, the solutions architect can ensure that each order is processed exactly once, preventing the creation of multiple unique orders for the same transaction and improving the reliability of the ecommerce checkout workflow.</span></p><p>&nbsp;</p><hr /><h3 id='question-256-implementing-a-document-review-application-with-s3-and-preventing-accidental-deletions'><span>Question #256 Implementing a document review application with S3 and preventing accidental deletions</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect is implementing a document review application using an Amazon S3 bucket for storage. The solution must prevent accidental deletion of the documents and ensure that all versions of the documents are available. Users must be able to download, modify, and upload documents.</span></p><p><strong><span>Which combination of actions should be taken to meet these requirements? (Choose two.)</span></strong></p><p><span>A. Enable a read-only bucket ACL.</span></p><p><span>B. Enable versioning on the bucket.</span></p><p><span>C. Attach an IAM policy to the bucket.</span></p><p><span>D. Enable MFA Delete on the bucket.</span></p><p><span>E. Encrypt the bucket using AWS KMS.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Enable versioning on the bucket.</span></p><p><span>D. Enable MFA Delete on the bucket.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Enable Versioning on the Bucket</span></strong><span>:</span></p><ul><li><p><strong><span>Action B</span></strong><span>: Enabling versioning on the S3 bucket ensures that all versions of the documents are available. This allows users to access previous versions of documents and helps prevent data loss due to accidental deletions or modifications.</span></p></li></ul></li><li><p><strong><span>Enable MFA Delete on the Bucket</span></strong><span>:</span></p><ul><li><p><strong><span>Action D</span></strong><span>: Enabling MFA Delete adds an extra layer of protection by requiring multi-factor authentication (MFA) for delete operations. This helps prevent accidental deletions by ensuring that only authorized users with MFA can delete objects or versions.</span></p></li></ul></li></ol><p><span>The other options have the following considerations:</span></p><p><span>A. </span><strong><span>Read-Only Bucket ACL</span></strong><span>: Enabling a read-only bucket ACL would prevent users from modifying and uploading documents, which does not meet the requirement that users must be able to download, modify, and upload documents.</span></p><p><span>C. </span><strong><span>Attach an IAM Policy to the Bucket</span></strong><span>: While attaching an IAM policy can help control access, it does not inherently provide versioning or prevent accidental deletions. It can be used in conjunction with other actions for fine-grained access control.</span></p><p><span>E. </span><strong><span>Encrypt the Bucket Using AWS KMS</span></strong><span>: Encrypting the bucket using AWS KMS enhances data security by ensuring that the data is encrypted at rest. However, it does not address the requirements of preventing accidental deletions or ensuring availability of all document versions.</span></p><p><span>By enabling versioning and MFA Delete on the S3 bucket, the solutions architect can meet the requirements of preventing accidental deletions and ensuring that all versions of the documents are available, while allowing users to download, modify, and upload documents.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-257-reporting-ec2-auto-scaling-events-to-amazon-s3-using-a-serverless-solution'><span>Question #257 Reporting EC2 Auto Scaling events to Amazon S3 using a serverless solution</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is building a solution that will report Amazon EC2 Auto Scaling events across all the applications in an AWS account. The company needs to use a serverless solution to store the EC2 Auto Scaling status data in Amazon S3. The company then will use the data in Amazon S3 to provide near-real-time updates in a dashboard. The solution must not affect the speed of EC2 instance launches. How should the company move the data to Amazon S3 to meet these requirements?</span></p><p><span>A. Use an Amazon CloudWatch metric stream to send the EC2 Auto Scaling status data to Amazon Kinesis Data Firehose. Store the data in Amazon S3.</span></p><p><span>B. Launch an Amazon EMR cluster to collect the EC2 Auto Scaling status data and send the data to Amazon Kinesis Data Firehose. Store the data in Amazon S3.</span></p><p><span>C. Create an Amazon EventBridge rule to invoke an AWS Lambda function on a schedule. Configure the Lambda function to send the EC2 Auto Scaling status data directly to Amazon S3.</span></p><p><span>D. Use a bootstrap script during the launch of an EC2 instance to install Amazon Kinesis Agent. Configure Kinesis Agent to collect the EC2 Auto Scaling status data and send the data to Amazon Kinesis Data Firehose. Store the data in Amazon S3.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use an Amazon CloudWatch metric stream to send the EC2 Auto Scaling status data to Amazon Kinesis Data Firehose. Store the data in Amazon S3.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon CloudWatch Metric Stream</span></strong><span>: Metric streams allow you to continuously stream CloudWatch metrics to a destination of your choice, such as Amazon Kinesis Data Firehose. This provides a near-real-time solution for capturing EC2 Auto Scaling events without adding latency to instance launches.</span></p></li><li><p><strong><span>Amazon Kinesis Data Firehose</span></strong><span>: Kinesis Data Firehose is a fully managed service for delivering real-time streaming data to destinations like Amazon S3. It can buffer, transform, and batch data before storing it in S3, ensuring efficient and reliable delivery.</span></p></li><li><p><strong><span>Serverless and Efficient</span></strong><span>: Using CloudWatch metric streams and Kinesis Data Firehose together provides a serverless and scalable solution that does not impact the speed of EC2 instance launches. This approach ensures that the EC2 Auto Scaling status data is captured and stored in S3 with minimal operational overhead.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Amazon EMR Cluster</span></strong><span>: Launching an EMR cluster adds unnecessary complexity and cost. EMR is designed for big data processing and is not suitable for a serverless and near-real-time solution.</span></p><p><span>C. </span><strong><span>EventBridge and Lambda</span></strong><span>: While EventBridge and Lambda can be used to capture and process events, this approach requires scheduling and may introduce delays. It is not as efficient as using a continuous metric stream for near-real-time updates.</span></p><p><span>D. </span><strong><span>Bootstrap Script and Kinesis Agent</span></strong><span>: Using a bootstrap script to install Kinesis Agent on EC2 instances can impact the speed of instance launches. Additionally, this approach requires managing and configuring agents on each instance, which adds operational complexity.</span></p><p><span>By using an Amazon CloudWatch metric stream to send EC2 Auto Scaling status data to Amazon Kinesis Data Firehose and storing the data in Amazon S3, the company can achieve a serverless, efficient, and near-real-time solution that meets the requirements without affecting the speed of EC2 instance launches.</span></p><p>&nbsp;</p><hr /><h3 id='question-258-converting-csv-files-to-parquet-format-with-minimal-operational-overhead'><span>Question #258 Converting CSV files to Parquet format with minimal operational overhead</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an application that places hundreds of .csv files into an Amazon S3 bucket every hour. The files are 1 GB in size. Each time a file is uploaded, the company needs to convert the file to Apache Parquet format and place the output file into an S3 bucket.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST operational overhead?</span></strong></p><p><span>A. Create an AWS Lambda function to download the .csv files, convert the files to Parquet format, and place the output files in an S3 bucket. Invoke the Lambda function for each S3 PUT event.</span></p><p><span>B. Create an Apache Spark job to read the .csv files, convert the files to Parquet format, and place the output files in an S3 bucket. Create an AWS Lambda function for each S3 PUT event to invoke the Spark job.</span></p><p><span>C. Create an AWS Glue table and an AWS Glue crawler for the S3 bucket where the application places the .csv files. Schedule an AWS Lambda function to periodically use Amazon Athena to query the AWS Glue table, convert the query results into Parquet format, and place the output files into an S3 bucket.</span></p><p><span>D. Create an AWS Glue extract, transform, and load (ETL) job to convert the .csv files to Parquet format and place the output files into an S3 bucket. Create an AWS Lambda function for each S3 PUT event to invoke the ETL job.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Create an AWS Glue extract, transform, and load (ETL) job to convert the .csv files to Parquet format and place the output files into an S3 bucket. Create an AWS Lambda function for each S3 PUT event to invoke the ETL job.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Glue ETL Job</span></strong><span>:</span></p><ul><li><p><strong><span>Purpose-Built for ETL</span></strong><span>: AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and transform data for analytics. It is designed to handle large-scale data processing tasks, such as converting CSV files to Parquet format.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: AWS Glue can handle large volumes of data efficiently and scales automatically, reducing the operational overhead of managing the infrastructure.</span></p></li></ul></li><li><p><strong><span>Triggering with AWS Lambda</span></strong><span>:</span></p><ul><li><p><strong><span>Event-Driven Processing</span></strong><span>: By creating an AWS Lambda function to trigger the Glue ETL job for each S3 PUT event, the solution ensures that each CSV file is processed as soon as it is uploaded. This approach leverages the event-driven architecture of AWS Lambda to automate the workflow.</span></p></li><li><p><strong><span>Minimal Overhead</span></strong><span>: The combination of AWS Glue and AWS Lambda minimizes the operational overhead, as AWS Glue handles the heavy lifting of data transformation, and AWS Lambda provides a lightweight mechanism to trigger the process.</span></p></li></ul></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Lambda Function for Conversion</span></strong><span>: While AWS Lambda can be used to process files, it has limitations on execution time (15 minutes) and memory (up to 10 GB). Processing 1 GB files might exceed these limits, making it less suitable for this use case.</span></p><p><span>B. </span><strong><span>Apache Spark Job</span></strong><span>: Running an Apache Spark job requires managing the Spark cluster, which introduces additional operational overhead. AWS Glue provides a managed Spark environment, making it a better choice.</span></p><p><span>C. </span><strong><span>Athena Queries</span></strong><span>: Using Amazon Athena to query the Glue table and convert the results to Parquet format is not the most efficient approach for this use case. Athena is designed for querying data, not for large-scale data transformations.</span></p><p><span>By using AWS Glue for the ETL job and AWS Lambda to trigger the job based on S3 PUT events, the company can achieve the required data transformation with the least operational overhead.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-259-implementing-data-retention-policies-for-amazon-rds'><span>Question #259 Implementing data retention policies for Amazon RDS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is implementing new data retention policies for all databases that run on Amazon RDS DB instances. The company must retain daily backups for a minimum period of 2 years. The backups must be consistent and restorable. Which solution should a solutions architect recommend to meet these requirements?</span></p><p><span>A. Create a backup vault in AWS Backup to retain RDS backups. Create a new backup plan with a daily schedule and an expiration period of 2 years after creation. Assign the RDS DB instances to the backup plan.</span></p><p><span>B. Configure a backup window for the RDS DB instances for daily snapshots. Assign a snapshot retention policy of 2 years to each RDS DB instance. Use Amazon Data Lifecycle Manager (Amazon DLM) to schedule snapshot deletions.</span></p><p><span>C. Configure database transaction logs to be automatically backed up to Amazon CloudWatch Logs with an expiration period of 2 years.</span></p><p><span>D. Configure an AWS Database Migration Service (AWS DMS) replication task. Deploy a replication instance, and configure a change data capture (CDC) task to stream database changes to Amazon S3 as the target. Configure S3 Lifecycle policies to delete the snapshots after 2 years.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create a backup vault in AWS Backup to retain RDS backups. Create a new backup plan with a daily schedule and an expiration period of 2 years after creation. Assign the RDS DB instances to the backup plan.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Backup</span></strong><span>: AWS Backup is a fully managed service that provides centralized backup management for AWS services, including Amazon RDS. It allows you to create backup plans with specific schedules and retention policies.</span></p></li><li><p><strong><span>Backup Vault</span></strong><span>: Creating a backup vault in AWS Backup allows you to securely store backups and manage their retention. You can set an expiration period to automatically delete backups after 2 years.</span></p></li><li><p><strong><span>Consistent and Restorable Backups</span></strong><span>: AWS Backup ensures that the backups are consistent and can be easily restored. By assigning the RDS DB instances to the backup plan, you can automate the backup process and ensure compliance with the retention policy.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Manual Snapshot Management</span></strong><span>: While configuring a backup window for daily snapshots and assigning a retention policy can work, it requires manual management and does not provide the same level of automation and centralized management as AWS Backup. Amazon Data Lifecycle Manager (DLM) is not designed for managing RDS snapshots.</span></p><p><span>C. </span><strong><span>Transaction Logs to CloudWatch Logs</span></strong><span>: Backing up transaction logs to CloudWatch Logs does not provide a full consistent backup of the database. It only captures changes and may not be sufficient for full database restoration.</span></p><p><span>D. </span><strong><span>AWS DMS for Backup</span></strong><span>: Using AWS DMS for change data capture (CDC) and streaming changes to S3 is more suited for migration and replication scenarios. It does not provide a straightforward way to create consistent and restorable daily backups with a 2-year retention policy.</span></p><p><span>By using AWS Backup with a backup vault and a backup plan, the company can meet its data retention requirements in a consistent, automated, and manageable way.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-260-ensuring-access-control-for-amazon-fsx-for-windows-file-server-with-on-premises-active-directory'><span>Question #260 Ensuring access control for Amazon FSx for Windows File Server with on-premises Active Directory</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company&#39;s compliance team needs to move its file shares to AWS. The shares run on a Windows Server SMB file share. A self-managed on-premises Active Directory controls access to the files and folders.</span></p><p><span>The company wants to use Amazon FSx for Windows File Server as part of the solution. The company must ensure that the on-premises Active Directory groups restrict access to the FSx for Windows File Server SMB compliance shares, folders, and files after the move to AWS. The company has created an FSx for Windows File Server file system.</span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Create an Active Directory Connector to connect to the Active Directory. Map the Active Directory groups to IAM groups to restrict access.</span></p><p><span>B. Assign a tag with a Restrict tag key and a Compliance tag value. Map the Active Directory groups to IAM groups to restrict access.</span></p><p><span>C. Create an IAM service-linked role that is linked directly to FSx for Windows File Server to restrict access.</span></p><p><span>D. Join the file system to the Active Directory to restrict access.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Join the file system to the Active Directory to restrict access.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Joining FSx to Active Directory</span></strong><span>:</span></p><ul><li><p><strong><span>Seamless Integration</span></strong><span>: By joining the Amazon FSx for Windows File Server file system to the on-premises Active Directory, the existing AD groups and policies can be used to control access to the file shares. This ensures that the same permissions and restrictions apply to the files and folders after the migration to AWS.</span></p></li><li><p><strong><span>Access Control</span></strong><span>: The Active Directory integration allows FSx to use AD-based authentication and authorization, ensuring that the compliance requirements are met by leveraging the existing AD groups and permissions.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Active Directory Connector (Option A)</span></strong><span>: While an AD Connector can be used to connect AWS services to an on-premises AD, it is not necessary for FSx for Windows File Server, which natively supports joining an AD domain.</span></p></li><li><p><strong><span>Tag-Based Access Control (Option B)</span></strong><span>: Tags are not used for managing file system access in this context. Access control for FSx for Windows File Server is managed through AD permissions, not IAM tags.</span></p></li><li><p><strong><span>IAM Service-Linked Role (Option C)</span></strong><span>: IAM roles are not used to manage access to FSx for Windows File Server. Access control is managed through Active Directory permissions.</span></p></li></ul></li></ol><p><span>By joining the Amazon FSx for Windows File Server file system to the on-premises Active Directory, the company can ensure that the existing AD groups and permissions continue to restrict access to the file shares, folders, and files, meeting the compliance requirements.</span></p><p>&nbsp;</p><hr /><h3 id='question-261-providing-device-specific-content-for-a-global-retail-website'><span>Question #261 Providing device-specific content for a global retail website</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company recently announced the deployment of its retail website to a global audience. The website runs on multiple Amazon EC2 instances behind an Elastic Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The company wants to provide its customers with different versions of content based on the devices that the customers use to access the website. Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)</span></p><p><span>A. Configure Amazon CloudFront to cache multiple versions of the content.</span></p><p><span>B. Configure a host header in a Network Load Balancer to forward traffic to different instances.</span></p><p><span>C. Configure a Lambda@Edge function to send specific objects to users based on the User-Agent header.</span></p><p><span>D. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up host-based routing to different EC2 instances.</span></p><p><span>E. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up path-based routing to different EC2 instances.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Configure Amazon CloudFront to cache multiple versions of the content.</span></p><p><span>C. Configure a Lambda@Edge function to send specific objects to users based on the User-Agent header.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon CloudFront</span></strong><span>: CloudFront is a global content delivery network (CDN) that caches content at edge locations around the world. By configuring CloudFront to cache multiple versions of the content, you can ensure that different versions of the website are served based on the user&#39;s device, improving performance and user experience.</span></p></li><li><p><strong><span>Lambda@Edge</span></strong><span>: Lambda@Edge allows you to run Lambda functions at AWS edge locations in response to CloudFront events. By configuring a Lambda@Edge function to inspect the User-Agent header, you can determine the type of device the user is using and send the appropriate version of the content. This approach enables dynamic content delivery based on device type without modifying the backend infrastructure.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Host Header in Network Load Balancer</span></strong><span>: Configuring a host header in a Network Load Balancer (NLB) is not suitable for distinguishing between different device types. NLBs are primarily used for TCP/UDP traffic and do not provide the same level of HTTP header inspection and routing capabilities as Application Load Balancers (ALBs).</span></p><p><span>D. </span><strong><span>AWS Global Accelerator with Host-Based Routing</span></strong><span>: While AWS Global Accelerator can improve global performance and availability, using it with host-based routing in an NLB does not address the requirement to serve different content based on device type. NLBs do not support host-based routing for HTTP traffic.</span></p><p><span>E. </span><strong><span>AWS Global Accelerator with Path-Based Routing</span></strong><span>: Similar to the previous point, using AWS Global Accelerator with path-based routing in an NLB does not address the requirement to serve different content based on device type. NLBs do not support path-based routing for HTTP traffic.</span></p><p><span>By using Amazon CloudFront to cache multiple versions of the content and Lambda@Edge to dynamically serve content based on the User-Agent header, the solutions architect can effectively meet the requirement to provide device-specific content to a global audience.</span></p><p>&nbsp;</p><hr /><h3 id='question-262-providing-ec2-instances-access-to-an-elasticache-cluster-across-vpcs'><span>Question #262 Providing EC2 instances access to an ElastiCache cluster across VPCs</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company plans to use Amazon ElastiCache for its multi-tier web application. A solutions architect creates a Cache VPC for the ElastiCache cluster and an App VPC for the application&#39;s Amazon EC2 instances. Both VPCs are in the us-east-1 Region.</span></p><p><span>The solutions architect must implement a solution to provide the application&#39;s EC2 instances with access to the ElastiCache cluster.</span></p><p><strong><span>Which solution will meet these requirements MOST cost-effectively?</span></strong></p><p><span>A. Create a peering connection between the VPCs. Add a route table entry for the peering connection in both VPCs. Configure an inbound rule for the ElastiCache cluster&#39;s security group to allow inbound connection from the application&#39;s security group.</span></p><p><span>B. Create a Transit VPC. Update the VPC route tables in the Cache VPC and the App VPC to route traffic through the Transit VPC. Configure an inbound rule for the ElastiCache cluster&#39;s security group to allow inbound connection from the application&#39;s security group.</span></p><p><span>C. Create a peering connection between the VPCs. Add a route table entry for the peering connection in both VPCs. Configure an inbound rule for the peering connection&#39;s security group to allow inbound connection from the application&#39;s security group.</span></p><p><span>D. Create a Transit VPC. Update the VPC route tables in the Cache VPC and the App VPC to route traffic through the Transit VPC. Configure an inbound rule for the Transit VPC&#39;s security group to allow inbound connection from the application&#39;s security group.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create a peering connection between the VPCs. Add a route table entry for the peering connection in both VPCs. Configure an inbound rule for the ElastiCache cluster&#39;s security group to allow inbound connection from the application&#39;s security group.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>VPC Peering Connection</span></strong><span>:</span></p><ul><li><p><strong><span>Cost-Effective</span></strong><span>: VPC peering is a cost-effective solution for connecting two VPCs within the same region. There are no data transfer charges for traffic within the same region, making it a budget-friendly option.</span></p></li><li><p><strong><span>Simplicity</span></strong><span>: Setting up a VPC peering connection is straightforward and involves fewer components compared to a Transit VPC.</span></p></li></ul></li><li><p><strong><span>Steps to Implement</span></strong><span>:</span></p><ul><li><p><strong><span>Peering Connection</span></strong><span>: Create a VPC peering connection between the Cache VPC and the App VPC.</span></p></li><li><p><strong><span>Route Table Entries</span></strong><span>: Add route table entries in both VPCs to route traffic through the peering connection.</span></p></li><li><p><strong><span>Security Group Rules</span></strong><span>: Configure the security group for the ElastiCache cluster to allow inbound connections from the security group of the application&#39;s EC2 instances. This ensures that only the intended application instances can access the ElastiCache cluster.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Transit VPC (Options B and D)</span></strong><span>: A Transit VPC involves additional components such as VPN connections and virtual routers, leading to higher complexity and cost. It is more suitable for complex network architectures involving multiple VPCs and regions.</span></p></li><li><p><strong><span>Incorrect Security Group Configuration (Option C)</span></strong><span>: Configuring an inbound rule for the peering connection&#39;s security group is incorrect. Security groups are associated with instances and resources, not with peering connections. The correct approach is to configure the security group of the ElastiCache cluster.</span></p></li></ul></li></ol><p><span>By creating a VPC peering connection and configuring the necessary route table entries and security group rules, the solutions architect can provide the application&#39;s EC2 instances with access to the ElastiCache cluster in a cost-effective and efficient manner.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-263-deploying-microservices-with-minimal-maintenance-and-scaling-effort'><span>Question #263 Deploying microservices with minimal maintenance and scaling effort</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is building an application that consists of several microservices. The company has decided to use container technologies to deploy its software on AWS. The company needs a solution that minimizes the amount of ongoing effort for maintenance and scaling. The company cannot manage additional infrastructure. Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)</span></p><p><span>A. Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.</span></p><p><span>B. Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.</span></p><p><span>C. Deploy an Amazon Elastic Container Service (Amazon ECS) service with an Amazon EC2 launch type. Specify a desired task number level of greater than or equal to 2.</span></p><p><span>D. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.</span></p><p><span>E. Deploy Kubernetes worker nodes on Amazon EC2 instances that span multiple Availability Zones. Create a deployment that specifies two or more replicas for each microservice.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.</span></p><p><span>D. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon ECS Cluster</span></strong><span>: Amazon ECS (Elastic Container Service) is a fully managed container orchestration service that simplifies the deployment, management, and scaling of containerized applications. Using ECS minimizes the operational overhead compared to managing Kubernetes clusters manually.</span></p></li><li><p><strong><span>Fargate Launch Type</span></strong><span>: Fargate is a serverless compute engine for containers that allows you to run containers without having to manage the underlying infrastructure. By using the Fargate launch type, you eliminate the need to provision and manage EC2 instances, further reducing the maintenance effort.</span></p></li><li><p><strong><span>Desired Task Number</span></strong><span>: Specifying a desired task number level ensures that multiple instances of each microservice are running, providing high availability and the ability to scale automatically based on demand.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Kubernetes Control Plane on EC2</span></strong><span>: Deploying the Kubernetes control plane on EC2 instances requires managing the control plane infrastructure, which adds operational complexity and maintenance effort. This does not align with the requirement to minimize ongoing effort.</span></p><p><span>C. </span><strong><span>ECS with EC2 Launch Type</span></strong><span>: Using the EC2 launch type for ECS requires managing the underlying EC2 instances, which increases the operational overhead compared to using Fargate.</span></p><p><span>E. </span><strong><span>Kubernetes Worker Nodes on EC2</span></strong><span>: Deploying Kubernetes worker nodes on EC2 instances also requires managing the infrastructure, including scaling and maintaining the nodes, which does not meet the requirement to minimize ongoing effort.</span></p><p><span>By deploying an Amazon ECS cluster and using the Fargate launch type, the solutions architect can meet the company&#39;s requirements for minimal maintenance and scaling effort while avoiding the need to manage additional infrastructure.</span></p><hr /><h3 id='question-264-resolving-timeout-errors-by-ensuring-dns-queries-return-healthy-instances'><span>Question #264 Resolving timeout errors by ensuring DNS queries return healthy instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a web application hosted over 10 Amazon EC2 instances with traffic directed by Amazon Route 53. The company occasionally experiences a timeout error when attempting to browse the application. The networking team finds that some DNS queries return IP addresses of unhealthy instances, resulting in the timeout error.</span></p><p><strong><span>What should a solutions architect implement to overcome these timeout errors?</span></strong></p><p><span>A. Create a Route 53 simple routing policy record for each EC2 instance. Associate a health check with each record.</span></p><p><span>B. Create a Route 53 failover routing policy record for each EC2 instance. Associate a health check with each record.</span></p><p><span>C. Create an Amazon CloudFront distribution with EC2 instances as its origin. Associate a health check with the EC2 instances.</span></p><p><span>D. Create an Application Load Balancer (ALB) with a health check in front of the EC2 instances. Route to the ALB from Route 53.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Create an Application Load Balancer (ALB) with a health check in front of the EC2 instances. Route to the ALB from Route 53.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Application Load Balancer (ALB)</span></strong><span>:</span></p><ul><li><p><strong><span>Health Checks</span></strong><span>: An ALB includes built-in health checks that continuously monitor the health of the EC2 instances. If an instance becomes unhealthy, the ALB automatically stops routing traffic to it.</span></p></li><li><p><strong><span>Load Balancing</span></strong><span>: The ALB distributes incoming traffic across multiple EC2 instances, ensuring high availability and fault tolerance.</span></p></li></ul></li><li><p><strong><span>Integration with Route 53</span></strong><span>:</span></p><ul><li><p><strong><span>DNS Routing</span></strong><span>: By routing traffic to the ALB from Route 53, you ensure that DNS queries always resolve to the ALB&#39;s IP address, which then forwards the traffic to healthy instances. This eliminates the issue of DNS queries returning IP addresses of unhealthy instances.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Route 53 Simple Routing Policy (Option A)</span></strong><span>: While associating health checks with simple routing policy records can help, it does not provide the same level of load balancing and automatic failover as an ALB.</span></p></li><li><p><strong><span>Route 53 Failover Routing Policy (Option B)</span></strong><span>: Similar to the simple routing policy, failover routing policy with health checks can help, but it is more suitable for primary and secondary resource failover scenarios rather than load balancing multiple instances.</span></p></li><li><p><strong><span>Amazon CloudFront (Option C)</span></strong><span>: CloudFront is a content delivery network (CDN) that can cache and distribute content globally, but it does not provide the same level of health check and load balancing capabilities as an ALB.</span></p></li></ul></li></ol><p><span>By using an Application Load Balancer (ALB) with health checks and routing traffic to the ALB from Route 53, the solutions architect can ensure that only healthy instances receive traffic, thereby overcoming the timeout errors and improving the reliability of the web application.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-265-designing-a-highly-available-and-secure-application-with-edge-delivery'><span>Question #265 Designing a highly available and secure application with edge delivery</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect needs to design a highly available application consisting of web, application, and database tiers. HTTPS content delivery should be as close to the edge as possible, with the least delivery time. Which solution meets these requirements and is MOST secure?</span></p><p><span>A. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.</span></p><p><span>B. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.</span></p><p><span>C. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.</span></p><p><span>D. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Public Application Load Balancer (ALB)</span></strong><span>: The ALB should be public to accept incoming HTTPS requests from the internet. This ensures that the load balancer can distribute traffic to the backend instances.</span></p></li><li><p><strong><span>EC2 Instances in Private Subnets</span></strong><span>: Placing the EC2 instances in private subnets enhances security by restricting direct access from the internet. The instances can only be accessed through the ALB, reducing the attack surface.</span></p></li><li><p><strong><span>Amazon CloudFront</span></strong><span>: CloudFront is a content delivery network (CDN) that caches content at edge locations around the world, reducing latency and improving delivery times. By using CloudFront to deliver HTTPS content, the application can achieve low-latency delivery close to the users.</span></p></li><li><p><strong><span>Public ALB as the Origin</span></strong><span>: Configuring CloudFront to use the public ALB as the origin ensures that the ALB can handle incoming requests and distribute them to the EC2 instances in private subnets. This setup provides a secure and highly available architecture.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>EC2 Instances in Public Subnets</span></strong><span>: Placing EC2 instances in public subnets exposes them to direct internet access, which is less secure compared to private subnets.</span></p><p><span>B. </span><strong><span>EC2 Instances as Origin</span></strong><span>: Configuring CloudFront to use EC2 instances directly as the origin is not a common practice and can complicate the architecture. The ALB should be the origin to manage traffic distribution effectively.</span></p><p><span>D. </span><strong><span>EC2 Instances in Public Subnets</span></strong><span>: Similar to option A, placing EC2 instances in public subnets reduces security by exposing them to the internet.</span></p><p><span>By configuring a public ALB with multiple redundant EC2 instances in private subnets and using CloudFront to deliver HTTPS content with the ALB as the origin, the solutions architect can design a highly available, low-latency, and secure application architecture.</span></p><p>&nbsp;</p><hr /><h3 id='question-266-implementing-latency-sensitive-health-monitoring-and-traffic-redirection-for-a-gaming-platform'><span>Question #266 Implementing latency-sensitive health monitoring and traffic redirection for a gaming platform</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a popular gaming platform running on AWS. The application is sensitive to latency because latency can impact the user experience and introduce unfair advantages to some players. The application is deployed in every AWS Region. It runs on Amazon EC2 instances that are part of Auto Scaling groups configured behind Application Load Balancers (ALBs). A solutions architect needs to implement a mechanism to monitor the health of the application and redirect traffic to healthy endpoints.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><span>A. Configure an accelerator in AWS Global Accelerator. Add a listener for the port that the application listens on, and attach it to a Regional endpoint in each Region. Add the ALB as the endpoint.</span></p><p><span>B. Create an Amazon CloudFront distribution and specify the ALB as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.</span></p><p><span>C. Create an Amazon CloudFront distribution and specify Amazon S3 as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.</span></p><p><span>D. Configure an Amazon DynamoDB database to serve as the data store for the application. Create a DynamoDB Accelerator (DAX) cluster to act as the in-memory cache for DynamoDB hosting the application data.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Configure an accelerator in AWS Global Accelerator. Add a listener for the port that the application listens on, and attach it to a Regional endpoint in each Region. Add the ALB as the endpoint.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Global Accelerator</span></strong><span>:</span></p><ul><li><p><strong><span>Low Latency</span></strong><span>: AWS Global Accelerator provides a global fixed entry point to your application, improving the performance and availability of your applications with low latency. It uses the AWS global network to route traffic to the nearest healthy endpoint based on health checks.</span></p></li><li><p><strong><span>Health Monitoring</span></strong><span>: Global Accelerator continuously monitors the health of your application endpoints and automatically redirects traffic to the nearest healthy endpoint if an issue is detected.</span></p></li><li><p><strong><span>Regional Endpoints</span></strong><span>: By configuring Regional endpoints and attaching the ALBs as endpoints, you ensure that traffic is directed to the appropriate region and load balancer, optimizing for latency and availability.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon CloudFront with ALB (Option B)</span></strong><span>: While CloudFront can help with caching and reducing latency for static content, it is not designed for real-time health monitoring and traffic redirection for dynamic gaming applications.</span></p></li><li><p><strong><span>Amazon CloudFront with S3 (Option C)</span></strong><span>: This option is more suitable for static content delivery and does not address the need for real-time health monitoring and traffic redirection.</span></p></li><li><p><strong><span>Amazon DynamoDB with DAX (Option D)</span></strong><span>: DynamoDB and DAX are used for data storage and caching, not for traffic routing and health monitoring of application endpoints.</span></p></li></ul></li></ol><p><span>By using AWS Global Accelerator, the solutions architect can implement a mechanism that provides low-latency access to the gaming platform, continuously monitors the health of the application, and redirects traffic to healthy endpoints, ensuring a smooth and fair user experience across all regions.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-267-analyzing-and-storing-mobile-app-data-in-near-real-time'><span>Question #267 Analyzing and storing mobile app data in near-real time</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has one million users that use its mobile app. The company must analyze the data usage in near-real time. The company also must encrypt the data in near-real time and must store the data in a centralized location in Apache Parquet format for further processing. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Create an Amazon Kinesis data stream to store the data in Amazon S3. Create an Amazon Kinesis Data Analytics application to analyze the data. Invoke an AWS Lambda function to send the data to the Kinesis Data Analytics application.</span></p><p><span>B. Create an Amazon Kinesis data stream to store the data in Amazon S3. Create an Amazon EMR cluster to analyze the data. Invoke an AWS Lambda function to send the data to the EMR cluster.</span></p><p><span>C. Create an Amazon Kinesis Data Firehose delivery stream to store the data in Amazon S3. Create an Amazon EMR cluster to analyze the data.</span></p><p><span>D. Create an Amazon Kinesis Data Firehose delivery stream to store the data in Amazon S3. Create an Amazon Kinesis Data Analytics application to analyze the data.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Create an Amazon Kinesis Data Firehose delivery stream to store the data in Amazon S3. Create an Amazon Kinesis Data Analytics application to analyze the data.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Kinesis Data Firehose</span></strong><span>: Kinesis Data Firehose is a fully managed service for delivering real-time streaming data to destinations like Amazon S3. It supports automatic encryption of data in transit and at rest, and it can convert data to Apache Parquet format before storing it in S3. This reduces operational overhead by eliminating the need to manage intermediate steps for data transformation and encryption.</span></p></li><li><p><strong><span>Amazon Kinesis Data Analytics</span></strong><span>: Kinesis Data Analytics allows you to process and analyze streaming data in real time. By using Kinesis Data Analytics, you can analyze the data as it is ingested by Kinesis Data Firehose, providing near-real-time insights with minimal operational overhead.</span></p></li><li><p><strong><span>Least Operational Overhead</span></strong><span>: This solution leverages fully managed services (Kinesis Data Firehose and Kinesis Data Analytics) that handle scaling, data transformation, and encryption automatically. This significantly reduces the operational burden compared to managing custom data processing pipelines or EMR clusters.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Kinesis Data Stream and Lambda</span></strong><span>: This option involves more components and manual management, including invoking a Lambda function to send data to Kinesis Data Analytics. This increases complexity and operational overhead.</span></p><p><span>B. </span><strong><span>Kinesis Data Stream and EMR</span></strong><span>: Using an EMR cluster requires managing the cluster, including scaling and maintenance, which adds operational overhead. Additionally, invoking a Lambda function to send data to the EMR cluster increases complexity.</span></p><p><span>C. </span><strong><span>Kinesis Data Firehose and EMR</span></strong><span>: While Kinesis Data Firehose simplifies data delivery to S3, using an EMR cluster for analysis still requires managing the cluster, which adds operational overhead.</span></p><p><span>By using Amazon Kinesis Data Firehose to deliver and store data in Amazon S3 and Amazon Kinesis Data Analytics to analyze the data, the company can achieve near-real-time data analysis and storage with encryption and minimal operational overhead.</span></p><hr /><p>&nbsp;</p><h3 id='question-268-improving-database-read-performance-for-a-gaming-web-application'><span>Question #268 Improving database read performance for a gaming web application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A gaming company has a web application that displays scores. The application runs on Amazon EC2 instances behind an Application Load Balancer. The application stores data in an Amazon RDS for MySQL database. Users are starting to experience long delays and interruptions that are caused by database read performance. The company wants to improve the user experience while minimizing changes to the application&#39;s architecture.</span></p><p><strong><span>What should a solutions architect do to meet these requirements?</span></strong></p><p><span>A. Use Amazon ElastiCache in front of the database.</span></p><p><span>B. Use RDS Proxy between the application and the database.</span></p><p><span>C. Migrate the application from EC2 instances to AWS Lambda.</span></p><p><span>D. Migrate the database from Amazon RDS for MySQL to Amazon DynamoDB.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use Amazon ElastiCache in front of the database.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon ElastiCache</span></strong><span>:</span></p><ul><li><p><strong><span>Caching Layer</span></strong><span>: By using Amazon ElastiCache, you can implement a caching layer in front of the RDS for MySQL database. This will significantly reduce the read load on the database by serving frequently accessed data from the cache, thus improving read performance and reducing latency.</span></p></li><li><p><strong><span>Minimal Changes</span></strong><span>: Implementing ElastiCache requires minimal changes to the existing architecture. The application can be modified to check the cache before querying the database, which is a straightforward update.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>RDS Proxy (Option B)</span></strong><span>: RDS Proxy helps improve application availability and database efficiency by managing connections to the database. However, it primarily addresses connection management and does not directly improve read performance.</span></p></li><li><p><strong><span>Migrating to AWS Lambda (Option C)</span></strong><span>: Migrating the application from EC2 instances to AWS Lambda involves significant architectural changes and does not directly address the database read performance issue.</span></p></li><li><p><strong><span>Migrating to DynamoDB (Option D)</span></strong><span>: Migrating from RDS for MySQL to Amazon DynamoDB is a major architectural change. While DynamoDB can provide high performance for certain use cases, it requires re-architecting the application to work with a NoSQL database, which is not minimal.</span></p></li></ul></li></ol><p><span>By using Amazon ElastiCache in front of the RDS for MySQL database, the solutions architect can improve the read performance and user experience with minimal changes to the application&#39;s architecture. This approach leverages caching to reduce the load on the database and serve data more quickly to the users.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-269-solving-performance-degradation-due-to-read-only-sql-queries'><span>Question #269 Solving performance degradation due to read-only SQL queries</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An ecommerce company has noticed performance degradation of its Amazon RDS-based web application. The performance degradation is attributed to an increase in the number of read-only SQL queries triggered by business analysts. A solutions architect needs to solve the problem with minimal changes to the existing web application. What should the solutions architect recommend?</span></p><p><span>A. Export the data to Amazon DynamoDB and have the business analysts run their queries.</span></p><p><span>B. Load the data into Amazon ElastiCache and have the business analysts run their queries.</span></p><p><span>C. Create a read replica of the primary database and have the business analysts run their queries.</span></p><p><span>D. Copy the data into an Amazon Redshift cluster and have the business analysts run their queries.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create a read replica of the primary database and have the business analysts run their queries.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Read Replica</span></strong><span>: Creating a read replica of the primary Amazon RDS database allows you to offload read-only queries to a separate instance, thereby reducing the load on the primary database. This is a straightforward solution that requires minimal changes to the existing web application.</span></p></li><li><p><strong><span>Minimal Changes</span></strong><span>: By using a read replica, the existing web application can continue to interact with the primary database as usual, while business analysts can be directed to the read replica for their queries. This approach minimizes disruption and changes to the current setup.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: Amazon RDS supports the creation of multiple read replicas, providing the ability to scale read operations horizontally as needed. This ensures that the system can handle increased read query loads without affecting the performance of the primary database.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon DynamoDB</span></strong><span>: Exporting data to DynamoDB would require significant changes to the existing application and the query patterns, as DynamoDB is a NoSQL database with different data modeling and querying mechanisms compared to an RDBMS.</span></p><p><span>B. </span><strong><span>Amazon ElastiCache</span></strong><span>: While ElastiCache can improve read performance by caching frequently accessed data, it requires changes to the application to manage cache invalidation and ensure data consistency. Additionally, ElastiCache is not a direct replacement for running complex SQL queries.</span></p><p><span>D. </span><strong><span>Amazon Redshift</span></strong><span>: Copying data into Amazon Redshift involves setting up ETL processes to keep the data in sync. Redshift is designed for OLAP (Online Analytical Processing) and may not be the best fit for handling real-time read queries from a transactional RDS database. This approach also introduces complexity and requires changes to the application and query patterns.</span></p><p><span>By creating a read replica of the primary database, the solutions architect can effectively address the performance degradation issue with minimal changes to the existing web application, ensuring that business analysts can run their read-only queries without impacting the primary database&#39;s performance.</span></p><hr /><p>&nbsp;</p><h3 id='question-270-ensuring-encryption-for-log-data-in-amazon-s3'><span>Question #270 Ensuring encryption for log data in Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is using a centralized AWS account to store log data in various Amazon S3 buckets. A solutions architect needs to ensure that the data is encrypted at rest before the data is uploaded to the S3 buckets. The data also must be encrypted in transit.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><strong><span>Options:</span></strong></p><p><span>A. Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.</span></p><p><span>B. Use server-side encryption to encrypt the data that is being uploaded to the S3 buckets.</span></p><p><span>C. Create bucket policies that require the use of server-side encryption with S3 managed encryption keys (SSE-S3) for S3 uploads.</span></p><p><span>D. Enable the security option to encrypt the S3 buckets through the use of a default AWS Key Management Service (AWS KMS) key.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>A. Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Client-Side Encryption (Option A)</span></strong><span>: Using client-side encryption ensures that the data is encrypted before it is uploaded to the S3 buckets. This means the data is encrypted at rest as soon as it is written to the bucket. Additionally, data is encrypted in transit if HTTPS is used for the upload, satisfying both encryption requirements.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Server-Side Encryption</span></strong><span>: While server-side encryption (SSE) encrypts data at rest, it does not encrypt data before it is uploaded. Therefore, the data is not encrypted during transit unless HTTPS is used.</span></p><p><span>C. </span><strong><span>Bucket Policies for SSE-S3</span></strong><span>: Requiring server-side encryption with S3 managed encryption keys (SSE-S3) through bucket policies ensures data is encrypted at rest, but it does not ensure encryption before upload or during transit.</span></p><p><span>D. </span><strong><span>Encrypting S3 Buckets with AWS KMS</span></strong><span>: Enabling encryption with a default AWS KMS key ensures that data is encrypted at rest, but like SSE-S3, it does not guarantee encryption before upload or during transit unless HTTPS is used.</span></p><p><span>By using client-side encryption, the solutions architect ensures that the data is encrypted before being uploaded to the S3 buckets and remains encrypted in transit if HTTPS is used. This approach fully meets the requirement for encryption at rest and in transit.</span></p><p>&nbsp;</p><hr /><h3 id='question-271-cost-effective-scaling-for-nightly-batch-processing-job'><span>Question #271 Cost-effective scaling for nightly batch processing job</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost-effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete. What should the solutions architect do to meet these requirements?</span></p><p><span>A. Increase the minimum capacity for the Auto Scaling group.</span></p><p><span>B. Increase the maximum capacity for the Auto Scaling group.</span></p><p><span>C. Configure scheduled scaling to scale up to the desired compute level.</span></p><p><span>D. Change the scaling policy to add more EC2 instances during each scaling operation.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Configure scheduled scaling to scale up to the desired compute level.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Scheduled Scaling</span></strong><span>: Scheduled scaling allows you to set a specific time to scale your Auto Scaling group to a desired capacity. Since the batch job starts at the same time every night (1 AM) and the peak capacity is known, you can configure a scheduled scaling action to ensure that the desired capacity is reached just before the batch job starts. This ensures that the required instances are available immediately when the job begins, without waiting for the scaling process to complete.</span></p></li><li><p><strong><span>Cost-Effective</span></strong><span>: By using scheduled scaling, you can ensure that the Auto Scaling group scales up to the required capacity just in time for the batch job and scales down after the job is complete. This approach avoids maintaining a higher minimum capacity throughout the day, reducing costs.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Increase Minimum Capacity</span></strong><span>: Increasing the minimum capacity would ensure that the instances are always available, but it would also result in higher costs as the instances would be running even when not needed.</span></p><p><span>B. </span><strong><span>Increase Maximum Capacity</span></strong><span>: Increasing the maximum capacity alone does not address the issue of reaching the desired capacity quickly. It only sets the upper limit for scaling but does not ensure that the instances are provisioned in time for the batch job.</span></p><p><span>D. </span><strong><span>Change Scaling Policy</span></strong><span>: Changing the scaling policy to add more instances during each scaling operation could help reach the desired capacity faster, but it may still not guarantee that the instances are available exactly when needed. Scheduled scaling is a more precise and reliable solution for this scenario.</span></p><p><span>By configuring scheduled scaling to scale up to the desired compute level just before the batch job starts, the solutions architect can ensure that the required EC2 capacity is reached quickly and cost-effectively, and the Auto Scaling group can scale down after the batch jobs are complete.</span></p><p>&nbsp;</p><hr /><h3 id='question-272-improving-website-performance-for-global-users-without-recreating-architecture-across-multiple-regions'><span>Question #272 Improving website performance for global users without recreating architecture across multiple regions</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company serves a dynamic website from a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The website needs to support multiple languages to serve customers around the world. The website&#39;s architecture is running in the us-west-1 Region and is exhibiting high request latency for users that are located in other parts of the world.</span></p><p><span>The website needs to serve requests quickly and efficiently regardless of a user&#39;s location. However, the company does not want to recreate the existing architecture across multiple Regions.</span></p><p><strong><span>What should a solutions architect do to meet these requirements?</span></strong></p><p><span>A. Replace the existing architecture with a website that is served from an Amazon S3 bucket. Configure an Amazon CloudFront distribution with the S3 bucket as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.</span></p><p><span>B. Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.</span></p><p><span>C. Create an Amazon API Gateway API that is integrated with the ALB. Configure the API to use the HTTP integration type. Set up an API Gateway stage to enable the API cache based on the Accept-Language request header.</span></p><p><span>D. Launch an EC2 instance in each additional Region and configure NGINX to act as a cache server for that Region. Put all the EC2 instances and the ALB behind an Amazon Route 53 record set with a geolocation routing policy.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon CloudFront Distribution</span></strong><span>:</span></p><ul><li><p><strong><span>Global Content Delivery</span></strong><span>: Amazon CloudFront is a content delivery network (CDN) that caches content at edge locations around the world, reducing latency for users by serving cached content from the nearest edge location.</span></p></li><li><p><strong><span>Origin Configuration</span></strong><span>: By configuring the CloudFront distribution with the ALB as the origin, you ensure that the existing architecture remains intact, and CloudFront handles the distribution of content globally.</span></p></li><li><p><strong><span>Cache Behavior</span></strong><span>: Setting the cache behavior to cache based on the </span><code>Accept-Language</code><span> request header allows CloudFront to deliver language-specific content efficiently, improving the user experience for customers around the world.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon S3 Bucket (Option A)</span></strong><span>: Replacing the existing architecture with an S3 bucket is not feasible for a dynamic website that relies on EC2 instances and an ALB. S3 is suitable for static content, not dynamic websites.</span></p></li><li><p><strong><span>API Gateway (Option C)</span></strong><span>: While API Gateway can be used to integrate with the ALB and enable caching, it introduces additional complexity and is not specifically designed for global content delivery like CloudFront.</span></p></li><li><p><strong><span>NGINX Cache Servers (Option D)</span></strong><span>: Launching EC2 instances in multiple regions and configuring NGINX as cache servers introduces additional operational overhead and complexity. It is not as efficient or cost-effective as using CloudFront for global content delivery.</span></p></li></ul></li></ol><p><span>By configuring an Amazon CloudFront distribution with the ALB as the origin and setting the cache behavior to cache based on the </span><code>Accept-Language</code><span> request header, the solutions architect can ensure that the website serves requests quickly and efficiently regardless of the user&#39;s location, without needing to recreate the architecture across multiple regions. This approach leverages CloudFront&#39;s global edge network to minimize latency and improve performance for users worldwide.</span></p><p>&nbsp;</p><hr /><h3 id='question-273-disaster-recovery-strategy-with-low-rto-for-an-ecommerce-company'><span>Question #273 Disaster recovery strategy with low RTO for an ecommerce company</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A rapidly growing ecommerce company is running its workloads in a single AWS Region. A solutions architect must create a disaster recovery (DR) strategy that includes a different AWS Region. The company wants its database to be up to date in the DR Region with the least possible latency. The remaining infrastructure in the DR Region needs to run at reduced capacity and must be able to scale up if necessary. Which solution will meet these requirements with the LOWEST recovery time objective (RTO)?</span></p><p><span>A. Use an Amazon Aurora global database with a pilot light deployment.</span></p><p><span>B. Use an Amazon Aurora global database with a warm standby deployment.</span></p><p><span>C. Use an Amazon RDS Multi-AZ DB instance with a pilot light deployment.</span></p><p><span>D. Use an Amazon RDS Multi-AZ DB instance with a warm standby deployment.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Use an Amazon Aurora global database with a warm standby deployment.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Aurora Global Database</span></strong><span>: Aurora global databases are designed for low-latency global replication, allowing you to replicate your database across multiple AWS Regions with minimal lag. This ensures that your database in the DR Region is up to date with the least possible latency.</span></p></li><li><p><strong><span>Warm Standby Deployment</span></strong><span>: A warm standby deployment involves running a scaled-down version of your full environment in the DR Region. This setup ensures that the infrastructure is already provisioned and can be quickly scaled up in case of a disaster, resulting in a low recovery time objective (RTO).</span></p></li><li><p><strong><span>Low RTO</span></strong><span>: Using an Aurora global database with a warm standby deployment provides the lowest RTO because the database replication is near real-time, and the infrastructure in the DR Region is already running (albeit at reduced capacity), allowing for quick scaling and recovery.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Aurora Global Database with Pilot Light</span></strong><span>: A pilot light deployment involves keeping critical systems running in the DR Region but not the full infrastructure, which may result in a higher RTO compared to a warm standby deployment.</span></p><p><span>C. </span><strong><span>RDS Multi-AZ with Pilot Light</span></strong><span>: RDS Multi-AZ provides high availability within a single region but does not offer cross-region replication. Additionally, a pilot light deployment may have a higher RTO compared to a warm standby deployment.</span></p><p><span>D. </span><strong><span>RDS Multi-AZ with Warm Standby</span></strong><span>: While a warm standby deployment provides a low RTO, RDS Multi-AZ does not support cross-region replication. This means that your database in the DR Region would not be up to date with the least possible latency.</span></p><p><span>By using an Amazon Aurora global database with a warm standby deployment, the solutions architect can ensure that the database is up to date in the DR Region with minimal latency and that the infrastructure can quickly scale up in case of a disaster, resulting in the lowest possible RTO.</span></p><p>&nbsp;</p><hr /><h3 id='question-274-implementing-a-disaster-recovery-solution-with-an-rto-of-less-than-4-hours'><span>Question #274 Implementing a Disaster Recovery solution with an RTO of less than 4 hours</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs an application on Amazon EC2 instances. The company needs to implement a disaster recovery (DR) solution for the application. The DR solution needs to have a recovery time objective (RTO) of less than 4 hours. The DR solution also needs to use the fewest possible AWS resources during normal operations.</span></p><p><strong><span>Which solution will meet these requirements in the MOST operationally efficient way?</span></strong></p><p><span>A. Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIS to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS Lambda and custom scripts.</span></p><p><span>B. Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIS to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation.</span></p><p><span>C. Launch EC2 instances in a secondary AWS Region. Keep the EC2 instances in the secondary Region active at all times.</span></p><p><span>D. Launch EC2 instances in a secondary Availability Zone. Keep the EC2 instances in the secondary Availability Zone active at all times.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIS to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Machine Images (AMIs)</span></strong><span>:</span></p><ul><li><p><strong><span>Backup and Copy</span></strong><span>: Creating AMIs of the EC2 instances and copying them to a secondary AWS Region ensures that you have up-to-date backups of your instances in case of a disaster.</span></p></li></ul></li><li><p><strong><span>AWS CloudFormation</span></strong><span>:</span></p><ul><li><p><strong><span>Infrastructure as Code</span></strong><span>: Using AWS CloudFormation to automate the deployment of infrastructure in the secondary region ensures a consistent and repeatable process. CloudFormation templates can define the entire infrastructure stack, making it easy to spin up the required resources quickly.</span></p></li><li><p><strong><span>Operational Efficiency</span></strong><span>: This approach uses minimal AWS resources during normal operations, as the infrastructure in the secondary region is only deployed when needed.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Lambda and Custom Scripts (Option A)</span></strong><span>: While this approach can also automate infrastructure deployment, it requires custom scripting and management, which can introduce complexity and potential for errors. CloudFormation provides a more standardized and manageable solution.</span></p></li><li><p><strong><span>Active EC2 Instances in Secondary Region (Option C)</span></strong><span>: Keeping EC2 instances active in a secondary region at all times incurs ongoing costs and does not align with the requirement to use the fewest possible AWS resources during normal operations.</span></p></li><li><p><strong><span>Active EC2 Instances in Secondary Availability Zone (Option D)</span></strong><span>: This approach provides high availability within the same region but does not offer true disaster recovery across regions. It also incurs ongoing costs similar to Option C.</span></p></li></ul></li></ol><p><span>By creating AMIs, copying them to a secondary region, and using AWS CloudFormation to automate the deployment of infrastructure in the secondary region, the company can achieve an RTO of less than 4 hours while using minimal AWS resources during normal operations. This approach ensures operational efficiency and quick recovery in case of a disaster.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-275-improving-application-performance-during-work-hours'><span>Question #275 Improving application performance during work hours</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs an internal browser-based application. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during work hours but scales down to 2 instances overnight. Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning. How should the scaling be changed to address the staff complaints and keep costs to a minimum?</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.</span></p><p><span>B. Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.</span></p><p><span>C. Implement a target tracking action triggered at a lower CPU threshold, and decrease the cooldown period.</span></p><p><span>D. Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>C. Implement a target tracking action triggered at a lower CPU threshold, and decrease the cooldown period.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Target Tracking Action (Option C)</span></strong><span>: Implementing a target tracking action triggered at a lower CPU threshold and decreasing the cooldown period allows the Auto Scaling group to respond more quickly to changes in load. This approach ensures that additional instances are launched as soon as the CPU usage starts to increase, helping to handle the initial surge in traffic when the workday begins. By setting a lower CPU threshold, instances are added proactively, improving application performance while still allowing for scaling down during periods of lower demand, thus keeping costs to a minimum.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Scheduled Action for Desired Capacity</span></strong><span>: While setting the desired capacity to 20 shortly before the office opens ensures that the necessary number of instances are available, it may not be the most cost-effective solution as it does not dynamically respond to actual usage patterns and may result in over-provisioning.</span></p><p><span>B. </span><strong><span>Step Scaling Action</span></strong><span>: Step scaling actions can help react to increased load, but they may not be as responsive as target tracking actions. Step scaling typically requires multiple steps and may not add instances quickly enough to handle the initial surge in traffic.</span></p><p><span>D. </span><strong><span>Scheduled Action for Minimum and Maximum Capacity</span></strong><span>: Setting both the minimum and maximum capacity to 20 shortly before the office opens ensures that all instances are available, but it does not allow for scaling down during periods of lower demand, leading to higher costs. This approach is not cost-effective as it maintains a high number of instances even when not needed.</span></p><p><span>By implementing a target tracking action with a lower CPU threshold and a decreased cooldown period, the company can ensure that the application performs well at the start of the day while maintaining cost efficiency by dynamically adjusting the number of instances based on actual load.</span></p><p>&nbsp;</p><hr /><h3 id='question-276-ensuring-automatic-scaling-for-a-multi-tier-application-with-increasing-traffic'><span>Question #276 Ensuring automatic scaling for a multi-tier application with increasing traffic</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a multi-tier application deployed on several Amazon EC2 instances in an Auto Scaling group. An Amazon RDS for Oracle instance is the application&#39;s data layer that uses Oracle-specific PL/SQL functions. Traffic to the application has been steadily increasing, causing the EC2 instances to become overloaded and the RDS instance to run out of storage. The Auto Scaling group does not have any scaling metrics and defines the minimum healthy instance count only. The company predicts that traffic will continue to increase at a steady but unpredictable rate before leveling off.</span></p><p><strong><span>What should a solutions architect do to ensure the system can automatically scale for the increased traffic? (Choose two.)</span></strong></p><p><span>A. Configure storage Auto Scaling on the RDS for Oracle instance.</span></p><p><span>B. Migrate the database to Amazon Aurora to use Auto Scaling storage.</span></p><p><span>C. Configure an alarm on the RDS for Oracle instance for low free storage space.</span></p><p><span>D. Configure the Auto Scaling group to use the average CPU as the scaling metric.</span></p><p><span>E. Configure the Auto Scaling group to use the average free memory as the scaling metric.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Configure storage Auto Scaling on the RDS for Oracle instance.</span></p><p><span>D. Configure the Auto Scaling group to use the average CPU as the scaling metric.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Configure Storage Auto Scaling on the RDS for Oracle Instance</span></strong><span>:</span></p><ul><li><p><strong><span>Action A</span></strong><span>: Enabling storage Auto Scaling on the RDS for Oracle instance ensures that the database can automatically scale its storage capacity as needed, preventing it from running out of storage space. This is crucial for handling increased traffic and data growth without manual intervention.</span></p></li></ul></li><li><p><strong><span>Configure the Auto Scaling Group to Use the Average CPU as the Scaling Metric</span></strong><span>:</span></p><ul><li><p><strong><span>Action D</span></strong><span>: Configuring the Auto Scaling group to use the average CPU utilization as the scaling metric helps ensure that the EC2 instances can automatically scale out (add more instances) when the CPU load increases and scale in (remove instances) when the load decreases. This helps manage the increased traffic and prevents the instances from becoming overloaded.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Migrate to Amazon Aurora (Option B)</span></strong><span>: While Amazon Aurora provides auto-scaling storage, migrating from RDS for Oracle to Aurora involves significant changes and may not support Oracle-specific PL/SQL functions. This option is not necessary if the current Oracle database meets the requirements.</span></p></li><li><p><strong><span>Configure an Alarm for Low Free Storage (Option C)</span></strong><span>: Setting an alarm for low free storage space on the RDS instance is useful for monitoring, but it does not automatically resolve the issue. Auto Scaling storage directly addresses the need for automatic scaling.</span></p></li><li><p><strong><span>Use Average Free Memory as the Scaling Metric (Option E)</span></strong><span>: While monitoring memory usage is important, CPU utilization is typically a more reliable metric for scaling web applications. Memory usage can be influenced by various factors and might not directly correlate with the need to scale out instances.</span></p></li></ul></li></ol><p><span>By configuring storage Auto Scaling on the RDS for Oracle instance and using average CPU utilization as the scaling metric for the Auto Scaling group, the solutions architect can ensure that the system can automatically scale to handle increased traffic efficiently. This approach addresses both the database storage and the application server scaling needs.</span></p><p>&nbsp;</p><hr /><h3 id='question-277-cost-effective-storage-solution-for-video-content'><span>Question #277 Cost-effective storage solution for video content</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company provides an online service for posting video content and transcoding it for use by any mobile platform. The application architecture uses Amazon Elastic File System (Amazon EFS) Standard to collect and store the videos so that multiple Amazon EC2 Linux instances can access the video content for processing. As the popularity of the service has grown over time, the storage costs have become too expensive. Which storage solution is MOST cost-effective?</span></p><p><span>A. Use AWS Storage Gateway for files to store and process the video content.</span></p><p><span>B. Use AWS Storage Gateway for volumes to store and process the video content.</span></p><p><span>C. Use Amazon EFS for storing the video content. Once processing is complete, transfer the files to Amazon Elastic Block Store (Amazon EBS).</span></p><p><span>D. Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon Elastic Block Store (Amazon EBS) volume attached to the server for processing.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon Elastic Block Store (Amazon EBS) volume attached to the server for processing.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3 for Storage</span></strong><span>: Amazon S3 is a highly scalable, durable, and cost-effective storage solution for storing large amounts of data, such as video content. It provides various storage classes, including S3 Standard, S3 Standard-IA (Infrequent Access), and S3 Glacier, which can help optimize costs based on access patterns.</span></p></li><li><p><strong><span>Temporary Processing with Amazon EBS</span></strong><span>: By moving the video files temporarily to an Amazon EBS volume attached to the EC2 instance for processing, the company can leverage the high performance and low latency of EBS for the transcoding tasks. After processing, the files can be stored back in S3 or moved to a more cost-effective storage class.</span></p></li><li><p><strong><span>Cost-Effectiveness</span></strong><span>: This approach leverages the cost-effectiveness of Amazon S3 for long-term storage and the performance of Amazon EBS for temporary processing. It helps reduce overall storage costs while ensuring efficient processing of video content.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Storage Gateway for Files</span></strong><span>: Storage Gateway is typically used for hybrid cloud storage solutions and may not be the most cost-effective option for storing and processing large volumes of video content entirely in the cloud.</span></p><p><span>B. </span><strong><span>AWS Storage Gateway for Volumes</span></strong><span>: Similar to Storage Gateway for files, this option is designed for hybrid cloud storage and may not provide the same cost benefits as using S3 and EBS for cloud-native storage and processing.</span></p><p><span>C. </span><strong><span>Amazon EFS and EBS</span></strong><span>: Using Amazon EFS for initial storage and then transferring files to EBS for processing can be more expensive compared to using S3 for long-term storage and EBS for temporary processing. EFS is generally more costly than S3 for storing large amounts of data.</span></p><p><span>By using Amazon S3 for storing the video content and moving the files temporarily to an Amazon EBS volume for processing, the company can achieve a cost-effective solution that balances storage costs and processing performance.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-278-storing-hierarchical-employee-data-with-low-latency-queries-and-monthly-financial-information-notifications'><span>Question #278 Storing hierarchical employee data with low-latency queries and monthly financial information notifications</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to create an application to store employee data in a hierarchical structured relationship. The company needs a minimum-latency response to traffic queries for the employee data and must protect any sensitive data. The company also needs to receive monthly email messages if any financial information is present in the employee data.</span></p><p><strong><span>Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)</span></strong></p><p><span>A. Use Amazon Redshift to store the employee data in hierarchies. Unload the data to Amazon S3 every month.</span></p><p><span>B. Use Amazon DynamoDB to store the employee data in hierarchies. Export the data to Amazon S3 every month.</span></p><p><span>C. Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly events to AWS Lambda.</span></p><p><span>D. Use Amazon Athena to analyze the employee data in Amazon S3. Integrate Athena with Amazon QuickSight to publish analysis dashboards and share the dashboards with users.</span></p><p><span>E. Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly notifications through an Amazon Simple Notification Service (Amazon SNS) subscription.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>B. Use Amazon DynamoDB to store the employee data in hierarchies. Export the data to Amazon S3 every month.</span></p><p><span>E. Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly notifications through an Amazon Simple Notification Service (Amazon SNS) subscription.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon DynamoDB for Hierarchical Data with Low-Latency Queries</span></strong><span>:</span></p><ul><li><p><strong><span>Action B</span></strong><span>: Amazon DynamoDB is a NoSQL database service that provides low-latency responses to queries. It is well-suited for storing hierarchical data using its flexible schema design. By exporting the data to Amazon S3 every month, the company can perform additional analysis or backup the data as needed.</span></p></li></ul></li><li><p><strong><span>Amazon Macie for Sensitive Data Detection and Notifications</span></strong><span>:</span></p><ul><li><p><strong><span>Action E</span></strong><span>: Amazon Macie is a data security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. By integrating Macie with Amazon EventBridge, the company can set up monthly notifications through Amazon SNS to alert if any financial information is present in the employee data. This ensures that sensitive data is monitored and notifications are sent as required.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon Redshift (Option A)</span></strong><span>: Amazon Redshift is a data warehousing service designed for large-scale data analysis, not for low-latency hierarchical data queries. It is not the best fit for this use case.</span></p></li><li><p><strong><span>Amazon Athena and QuickSight (Option D)</span></strong><span>: Athena and QuickSight are used for querying and visualizing data stored in Amazon S3, but they do not provide the low-latency response required for the application. They are more suited for ad-hoc analysis and reporting.</span></p></li><li><p><strong><span>Amazon Macie with AWS Lambda (Option C)</span></strong><span>: While integrating Macie with AWS Lambda can automate tasks based on events, using SNS for notifications is more straightforward and aligns with the requirement to receive monthly email messages.</span></p></li></ul></li></ol><p><span>By using Amazon DynamoDB for low-latency hierarchical data storage and Amazon Macie integrated with Amazon EventBridge and SNS for sensitive data detection and notifications, the solutions architect can meet the company&#39;s requirements efficiently.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-279-meeting-compliance-requirements-for-dynamodb-backups'><span>Question #279 Meeting compliance requirements for DynamoDB backups</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an application that is backed by an Amazon DynamoDB table. The company&#39;s compliance requirements specify that database backups must be taken every month, must be available for 6 months, and must be retained for 7 years. Which solution will meet these requirements?</span></p><p><span>A. Create an AWS Backup plan to back up the DynamoDB table on the first day of each month. Specify a lifecycle policy that transitions the backup to cold storage after 6 months. Set the retention period for each backup to 7 years.</span></p><p><span>B. Create a DynamoDB on-demand backup of the DynamoDB table on the first day of each month. Transition the backup to Amazon S3 Glacier Flexible Retrieval after 6 months. Create an S3 Lifecycle policy to delete backups that are older than 7 years.</span></p><p><span>C. Use the AWS SDK to develop a script that creates an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the script on the first day of each month. Create a second script that will run on the second day of each month to transition DynamoDB backups that are older than 6 months to cold storage and to delete backups that are older than 7 years.</span></p><p><span>D. Use the AWS CLI to create an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the command on the first day of each month with a cron expression. Specify in the command to transition the backups to cold storage after 6 months and to delete the backups after 7 years.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create an AWS Backup plan to back up the DynamoDB table on the first day of each month. Specify a lifecycle policy that transitions the backup to cold storage after 6 months. Set the retention period for each backup to 7 years.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Backup</span></strong><span>: AWS Backup is a fully managed backup service that simplifies and automates the backup process for AWS resources, including Amazon DynamoDB. It allows you to create backup plans that define backup schedules, retention policies, and lifecycle management.</span></p></li><li><p><strong><span>Lifecycle Policy</span></strong><span>: AWS Backup supports lifecycle policies that can automatically transition backups to lower-cost storage tiers (e.g., cold storage) after a specified period. This helps in managing storage costs while ensuring compliance with retention requirements.</span></p></li><li><p><strong><span>Retention Period</span></strong><span>: AWS Backup allows you to set retention periods for your backups, ensuring that they are retained for the required duration (e.g., 7 years) before being automatically deleted.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Manual Transition to S3 Glacier</span></strong><span>: This option requires additional steps to transition backups to S3 Glacier Flexible Retrieval and manage lifecycle policies, which adds complexity compared to using AWS Backup.</span></p><p><span>C. </span><strong><span>Custom Script with EventBridge</span></strong><span>: Developing a custom script and using Amazon EventBridge to schedule and manage backups adds operational overhead and complexity. AWS Backup provides a more streamlined and automated solution.</span></p><p><span>D. </span><strong><span>AWS CLI with EventBridge</span></strong><span>: Similar to option C, using the AWS CLI with EventBridge to manage backups and lifecycle transitions requires additional manual configuration and management, making it less efficient compared to AWS Backup.</span></p><p><span>By creating an AWS Backup plan to back up the DynamoDB table on the first day of each month, specifying a lifecycle policy to transition the backup to cold storage after 6 months, and setting the retention period for each backup to 7 years, the solutions architect can meet the compliance requirements with minimal operational overhead and maximum automation.</span></p><p>&nbsp;</p><hr /><h3 id='question-280-analyzing-and-visualizing-cloudfront-logs-stored-in-amazon-s3'><span>Question #280 Analyzing and visualizing CloudFront logs stored in Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is using Amazon CloudFront with its website. The company has enabled logging on the CloudFront distribution, and logs are saved in one of the company&#39;s Amazon S3 buckets. The company needs to perform advanced analyses on the logs and build visualizations.</span></p><p><strong><span>What should a solutions architect do to meet these requirements?</span></strong></p><p><span>A. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.</span></p><p><span>B. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.</span></p><p><span>C. Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.</span></p><p><span>D. Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Athena for Analyzing Logs</span></strong><span>:</span></p><ul><li><p><strong><span>Athena</span></strong><span>: Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL. It is serverless, so there is no infrastructure to manage, and you pay only for the queries you run. Athena is well-suited for analyzing log data stored in S3.</span></p></li></ul></li><li><p><strong><span>Amazon QuickSight for Visualization</span></strong><span>:</span></p><ul><li><p><strong><span>QuickSight</span></strong><span>: Amazon QuickSight is a scalable, serverless, embeddable, machine learning-powered business intelligence (BI) service built for the cloud. It allows you to create and publish interactive dashboards that can be accessed from any device. QuickSight integrates seamlessly with Athena, making it easy to visualize the results of your queries.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Glue (Option A)</span></strong><span>: AWS Glue is a fully managed ETL (extract, transform, and load) service that makes it easy to move data between data stores. However, it is not primarily a visualization tool. QuickSight is more appropriate for visualization.</span></p></li><li><p><strong><span>Amazon DynamoDB (Options C and D)</span></strong><span>: DynamoDB is a NoSQL database service designed for high performance and scalability. It is not intended for querying and analyzing log data stored in S3. Athena is a better fit for this use case.</span></p></li></ul></li></ol><p><span>By using Amazon Athena to analyze the CloudFront logs stored in the S3 bucket and Amazon QuickSight to visualize the results, the solutions architect can meet the company&#39;s requirements for advanced analysis and visualization of the log data. This combination leverages the strengths of both services, providing an efficient and effective solution.</span></p><p>&nbsp;</p><hr /><h3 id='question-281-meeting-an-rpo-of-less-than-1-second-for-postgresql-db-instance'><span>Question #281 Meeting an RPO of less than 1 second for PostgreSQL DB instance</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs a fleet of web servers using an Amazon RDS for PostgreSQL DB instance. After a routine compliance check, the company sets a standard that requires a recovery point objective (RPO) of less than 1 second for all its production databases. Which solution meets these requirements?</span></p><p><span>A. Enable a Multi-AZ deployment for the DB instance.</span></p><p><span>B. Enable auto scaling for the DB instance in one Availability Zone.</span></p><p><span>C. Configure the DB instance in one Availability Zone, and create multiple read replicas in a separate Availability Zone.</span></p><p><span>D. Configure the DB instance in one Availability Zone, and configure AWS Database Migration Service (AWS DMS) change data capture (CDC) tasks.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Enable a Multi-AZ deployment for the DB instance.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Multi-AZ Deployment</span></strong><span>: Enabling a Multi-AZ deployment for an Amazon RDS instance provides high availability and automatic failover support. In a Multi-AZ configuration, Amazon RDS automatically replicates the data synchronously to a standby instance in a different Availability Zone. This ensures that the data is highly available and can be recovered with minimal data loss, meeting the requirement of an RPO of less than 1 second.</span></p></li><li><p><strong><span>Synchronous Replication</span></strong><span>: Multi-AZ deployments use synchronous replication, which means that any changes to the primary instance are immediately replicated to the standby instance. This ensures that the standby instance is always up to date with the primary instance, providing the necessary data protection to meet the RPO requirement.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Auto Scaling in One Availability Zone</span></strong><span>: Enabling auto scaling for the DB instance in one Availability Zone does not provide the necessary high availability and data protection to meet an RPO of less than 1 second. Auto scaling is more relevant to compute resources rather than database availability.</span></p><p><span>C. </span><strong><span>Read Replicas in a Separate Availability Zone</span></strong><span>: While read replicas can provide increased read scalability and some level of redundancy, they use asynchronous replication. This means that there can be a lag between the primary instance and the read replicas, which does not guarantee an RPO of less than 1 second.</span></p><p><span>D. </span><strong><span>AWS DMS Change Data Capture (CDC) Tasks</span></strong><span>: Using AWS DMS with change data capture (CDC) tasks can help in replicating changes, but it does not provide the same level of immediate data consistency and automatic failover as a Multi-AZ deployment. This setup is more complex and may not meet the stringent RPO requirement.</span></p><p><span>By enabling a Multi-AZ deployment for the DB instance, the company can ensure high availability, automatic failover, and synchronous data replication, all of which are necessary to meet the RPO of less than 1 second for its production databases.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-282-restricting-inbound-traffic-from-the-alb-to-ec2-instances-in-a-private-subnet'><span>Question #282 Restricting inbound traffic from the ALB to EC2 instances in a private subnet</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs a web application that is deployed on Amazon EC2 instances in the private subnet of a VPC. An Application Load Balancer (ALB) that extends across the public subnets directs web traffic to the EC2 instances. The company wants to implement new security measures to restrict inbound traffic from the ALB to the EC2 instances while preventing access from any other source inside or outside the private subnet of the EC2 instances.</span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Configure a route in a route table to direct traffic from the internet to the private IP addresses of the EC2 instances.</span></p><p><span>B. Configure the security group for the EC2 instances to only allow traffic that comes from the security group for the ALB.</span></p><p><span>C. Move the EC2 instances into the public subnet. Give the EC2 instances a set of Elastic IP addresses.</span></p><p><span>D. Configure the security group for the ALB to allow any TCP traffic on any port.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Configure the security group for the EC2 instances to only allow traffic that comes from the security group for the ALB.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Security Group Configuration</span></strong><span>:</span></p><ul><li><p><strong><span>Security Group for EC2 Instances</span></strong><span>: By configuring the security group for the EC2 instances to only allow inbound traffic from the security group of the ALB, you ensure that only traffic coming from the ALB can reach the EC2 instances. This effectively restricts access and prevents any other source from accessing the instances.</span></p></li><li><p><strong><span>Security Group for ALB</span></strong><span>: The ALB&#39;s security group should allow inbound traffic from the internet on the ports that the web application uses (e.g., HTTP/HTTPS).</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Route Table Configuration (Option A)</span></strong><span>: Configuring a route in a route table to direct traffic from the internet to the private IP addresses of the EC2 instances is not a security measure and does not restrict access as required.</span></p></li><li><p><strong><span>Public Subnet and Elastic IP (Option C)</span></strong><span>: Moving the EC2 instances to the public subnet and giving them Elastic IP addresses would expose the instances to the internet, which is contrary to the requirement of restricting access.</span></p></li><li><p><strong><span>ALB Security Group Configuration (Option D)</span></strong><span>: Configuring the security group for the ALB to allow any TCP traffic on any port does not address the requirement of restricting access to the EC2 instances. It would allow unrestricted access to the ALB, which is not desired.</span></p></li></ul></li></ol><p><span>By configuring the security group for the EC2 instances to only allow traffic from the security group of the ALB, the company can meet the security requirements effectively. This ensures that only the ALB can direct traffic to the EC2 instances, and no other source, whether inside or outside the private subnet, can access the instances.</span></p><p>&nbsp;</p><hr /><h3 id='question-283-migrating-simulation-and-visualization-applications-to-aws'><span>Question #283 Migrating simulation and visualization applications to AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A research company runs experiments that are powered by a simulation application and a visualization application. The simulation application runs on Linux and outputs intermediate data to an NFS share every 5 minutes. The visualization application is a Windows desktop application that displays the simulation output and requires an SMB file system. The company maintains two synchronized file systems. This strategy is causing data duplication and inefficient resource usage. The company needs to migrate the applications to AWS without making code changes to either application. Which solution will meet these requirements?</span></p><p><span>A. Migrate both applications to AWS Lambda. Create an Amazon S3 bucket to exchange data between the applications.</span></p><p><span>B. Migrate both applications to Amazon Elastic Container Service (Amazon ECS). Configure Amazon FSx File Gateway for storage.</span></p><p><span>C. Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon Simple Queue Service (Amazon SQS) to exchange data between the applications.</span></p><p><span>D. Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon FSx for NetApp ONTAP for storage.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Migrate the simulation application to Linux Amazon EC2 instances. Migrate the visualization application to Windows EC2 instances. Configure Amazon FSx for NetApp ONTAP for storage.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon FSx for NetApp ONTAP</span></strong><span>: Amazon FSx for NetApp ONTAP provides fully managed shared storage with support for both NFS and SMB protocols. This allows you to use a single file system for both Linux and Windows applications without requiring code changes. It eliminates the need for maintaining two synchronized file systems, thereby reducing data duplication and improving resource efficiency.</span></p></li><li><p><strong><span>Linux and Windows EC2 Instances</span></strong><span>: Migrating the simulation application to Linux EC2 instances and the visualization application to Windows EC2 instances ensures that both applications can run in their native environments. This approach avoids the need for code changes and ensures compatibility with the existing applications.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Lambda and Amazon S3</span></strong><span>: Migrating the applications to AWS Lambda and using Amazon S3 for data exchange would require significant changes to how the applications interact with storage. Additionally, AWS Lambda may not be suitable for long-running simulation tasks.</span></p><p><span>B. </span><strong><span>Amazon ECS and FSx File Gateway</span></strong><span>: While Amazon ECS can run containerized applications, it may require changes to how the applications are packaged and deployed. FSx File Gateway does not provide the same level of integration and support for both NFS and SMB protocols as FSx for NetApp ONTAP.</span></p><p><span>C. </span><strong><span>EC2 Instances and SQS</span></strong><span>: Using Amazon SQS for data exchange would require changes to how the applications handle data storage and retrieval. SQS is a message queue service and is not designed for file storage, making it unsuitable for this use case.</span></p><p><span>By migrating the simulation application to Linux EC2 instances and the visualization application to Windows EC2 instances, and configuring Amazon FSx for NetApp ONTAP for storage, the company can meet its requirements without making code changes to either application. This solution provides a unified storage system that supports both NFS and SMB protocols, reducing data duplication and improving resource efficiency.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-284-generating-a-report-of-aws-billed-items-listed-by-user-for-budget-planning'><span>Question #284 Generating a report of AWS billed items listed by user for budget planning</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>As part of budget planning, management wants a report of AWS billed items listed by user. The data will be used to create department budgets. A solutions architect needs to determine the most efficient way to obtain this report information.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><span>A. Run a query with Amazon Athena to generate the report.</span></p><p><span>B. Create a report in Cost Explorer and download the report.</span></p><p><span>C. Access the bill details from the billing dashboard and download the bill.</span></p><p><span>D. Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES).</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create a report in Cost Explorer and download the report.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Cost Explorer</span></strong><span>:</span></p><ul><li><p><strong><span>Detailed Cost Reports</span></strong><span>: AWS Cost Explorer provides detailed cost and usage reports that can be filtered and grouped by various dimensions, including user, service, and tags. This makes it easy to generate a report of AWS billed items listed by user.</span></p></li><li><p><strong><span>Downloadable Reports</span></strong><span>: Cost Explorer allows you to create and download custom reports, making it straightforward to obtain the required information for budget planning.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon Athena (Option A)</span></strong><span>: While Amazon Athena can be used to query detailed billing data stored in Amazon S3, it requires setting up AWS Cost and Usage Reports (CUR) and writing SQL queries. This approach is more complex and less efficient than using Cost Explorer for this specific requirement.</span></p></li><li><p><strong><span>Billing Dashboard (Option C)</span></strong><span>: Accessing the bill details from the billing dashboard provides a high-level overview of costs but does not offer the same level of detail and filtering capabilities as Cost Explorer. It is not as efficient for generating user-specific reports.</span></p></li><li><p><strong><span>AWS Budgets and Amazon SES (Option D)</span></strong><span>: AWS Budgets can be used to set budget thresholds and receive alerts, but it is not designed for generating detailed cost reports by user. It does not provide the reporting capabilities needed for this requirement.</span></p></li></ul></li></ol><p><span>By using AWS Cost Explorer to create and download a report, the solutions architect can efficiently obtain detailed information about AWS billed items listed by user. This approach leverages Cost Explorer&#39;s powerful filtering and grouping capabilities to generate the necessary data for creating department budgets.</span></p><p>&nbsp;</p><hr /><h3 id='question-285-adding-a-dynamic-contact-form-to-a-static-website-hosted-on-amazon-s3'><span>Question #285 Adding a dynamic contact form to a static website hosted on Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts its static website by using Amazon S3. The company wants to add a contact form to its webpage. The contact form will have dynamic server-side components for users to input their name, email address, phone number, and user message. The company anticipates that there will be fewer than 100 site visits each month. Which solution will meet these requirements MOST cost-effectively?</span></p><p><span>A. Host a dynamic contact form page in Amazon Elastic Container Service (Amazon ECS). Set up Amazon Simple Email Service (Amazon SES) to connect to any third-party email provider.</span></p><p><span>B. Create an Amazon API Gateway endpoint with an AWS Lambda backend that makes a call to Amazon Simple Email Service (Amazon SES).</span></p><p><span>C. Convert the static webpage to dynamic by deploying Amazon Lightsail. Use client-side scripting to build the contact form. Integrate the form with Amazon WorkMail.</span></p><p><span>D. Create a t2.micro Amazon EC2 instance. Deploy a LAMP (Linux, Apache, MySQL, PHP/Perl/Python) stack to host the webpage. Use client-side scripting to build the contact form. Integrate the form with Amazon WorkMail.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create an Amazon API Gateway endpoint with an AWS Lambda backend that makes a call to Amazon Simple Email Service (Amazon SES).</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon API Gateway and AWS Lambda</span></strong><span>: This combination allows you to create a serverless architecture that can handle dynamic server-side components without the need to manage servers. API Gateway can expose an endpoint that the contact form can call, and AWS Lambda can handle the backend processing.</span></p></li><li><p><strong><span>Amazon Simple Email Service (SES)</span></strong><span>: SES is a cost-effective and scalable email service that can be used to send emails from the contact form. The Lambda function can use SES to send the form data to the desired email address.</span></p></li><li><p><strong><span>Cost-Effectiveness</span></strong><span>: This solution is highly cost-effective, especially given the low traffic (fewer than 100 site visits each month). AWS Lambda and API Gateway have a generous free tier, and the usage costs are minimal for low traffic scenarios. SES also offers a free tier and low-cost email sending.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon ECS and SES</span></strong><span>: Hosting a dynamic contact form on ECS is more complex and involves managing containerized applications. This is overkill for a low-traffic website and is not as cost-effective as a serverless solution.</span></p><p><span>C. </span><strong><span>Amazon Lightsail and WorkMail</span></strong><span>: Converting the static webpage to dynamic using Lightsail and client-side scripting is unnecessary for adding a contact form. Additionally, WorkMail is more suited for enterprise email solutions rather than simple contact form submissions.</span></p><p><span>D. </span><strong><span>Amazon EC2 and WorkMail</span></strong><span>: Deploying a LAMP stack on an EC2 instance is not cost-effective for such low traffic. It involves managing and maintaining the server and is more complex than a serverless solution.</span></p><p><span>By creating an Amazon API Gateway endpoint with an AWS Lambda backend that makes a call to Amazon SES, the company can add a dynamic contact form to its static website in a cost-effective and scalable manner. This solution leverages serverless technologies, minimizing the need for server management and reducing costs.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-286-ensuring-a-static-website-on-cloudfront-reflects-updates-from-the-git-repository'><span>Question #286 Ensuring a static website on CloudFront reflects updates from the Git repository</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a static website that is hosted on Amazon CloudFront in front of Amazon S3. The static website uses a database backend. The company notices that the website does not reflect updates that have been made in the website&#39;s Git repository. The company checks the continuous integration and continuous delivery (CI/CD) pipeline between the Git repository and Amazon S3. The company verifies that the webhooks are configured properly and that the CI/CD pipeline is sending messages that indicate successful deployments.</span></p><p><span>A solutions architect needs to implement a solution that displays the updates on the website.</span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Add an Application Load Balancer.</span></p><p><span>B. Add Amazon ElastiCache for Redis or Memcached to the database layer of the web application.</span></p><p><span>C. Invalidate the CloudFront cache.</span></p><p><span>D. Use AWS Certificate Manager (ACM) to validate the website&#39;s SSL certificate.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Invalidate the CloudFront cache.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>CloudFront Cache Invalidation</span></strong><span>:</span></p><ul><li><p><strong><span>Caching Behavior</span></strong><span>: Amazon CloudFront caches content at edge locations to reduce latency and improve performance. However, this means that updates to the content in the S3 bucket may not be immediately reflected on the website because CloudFront is serving cached content.</span></p></li><li><p><strong><span>Invalidation</span></strong><span>: To ensure that updates are displayed on the website, you need to invalidate the CloudFront cache. This forces CloudFront to fetch the updated content from the origin (S3 bucket) and serve it to users.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Application Load Balancer (Option A)</span></strong><span>: Adding an Application Load Balancer is not relevant to the issue of caching and will not help in ensuring that the static website reflects updates from the Git repository.</span></p></li><li><p><strong><span>ElastiCache for Redis or Memcached (Option B)</span></strong><span>: Adding ElastiCache to the database layer is not related to the issue of updating static content served by CloudFront. ElastiCache is used for caching database queries to improve performance, not for invalidating CloudFront caches.</span></p></li><li><p><strong><span>AWS Certificate Manager (ACM) (Option D)</span></strong><span>: Using AWS Certificate Manager to validate the website&#39;s SSL certificate is unrelated to the issue of content updates. ACM handles SSL/TLS certificates for securing connections, not for managing content updates or caching.</span></p></li></ul></li></ol><p><span>By invalidating the CloudFront cache, the solutions architect can ensure that the static website reflects the latest updates from the Git repository. This approach directly addresses the issue of outdated content being served from the cache and ensures that users see the most recent version of the website.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-287-migrating-a-windows-based-application-with-sql-server-to-aws'><span>Question #287 Migrating a Windows-based application with SQL Server to AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to migrate a Windows-based application from on premises to the AWS Cloud. The application has three tiers: an application tier, a business tier, and a database tier with Microsoft SQL Server. The company wants to use specific features of SQL Server such as native backups and Data Quality Services. The company also needs to share files for processing between the tiers. How should a solutions architect design the architecture to meet these requirements?</span></p><p><span>A. Host all three tiers on Amazon EC2 instances. Use Amazon FSx File Gateway for file sharing between the tiers.</span></p><p><span>B. Host all three tiers on Amazon EC2 instances. Use Amazon FSx for Windows File Server for file sharing between the tiers.</span></p><p><span>C. Host the application tier and the business tier on Amazon EC2 instances. Host the database tier on Amazon RDS. Use Amazon Elastic File System (Amazon EFS) for file sharing between the tiers.</span></p><p><span>D. Host the application tier and the business tier on Amazon EC2 instances. Host the database tier on Amazon RDS. Use a Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volume for file sharing between the tiers.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Host all three tiers on Amazon EC2 instances. Use Amazon FSx for Windows File Server for file sharing between the tiers.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon EC2 for All Three Tiers</span></strong><span>: Hosting all three tiers (application, business, and database) on Amazon EC2 instances allows the company to fully manage and configure the environment to meet specific requirements, such as using native SQL Server features like backups and Data Quality Services.</span></p></li><li><p><strong><span>Amazon FSx for Windows File Server</span></strong><span>: FSx for Windows File Server provides a fully managed, highly reliable, and scalable file storage that is accessible over the SMB protocol. This is ideal for Windows-based applications and supports file sharing between the different tiers of the application.</span></p></li><li><p><strong><span>SQL Server Features</span></strong><span>: By hosting the database tier on Amazon EC2 instances, the company can leverage all the native features of SQL Server, including native backups and Data Quality Services, which may not be fully supported on Amazon RDS for SQL Server.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>FSx File Gateway</span></strong><span>: FSx File Gateway is designed for hybrid cloud storage and may not be the best fit for fully cloud-native applications. It is more complex to set up and manage compared to FSx for Windows File Server.</span></p><p><span>C. </span><strong><span>Amazon RDS and EFS</span></strong><span>: While Amazon RDS for SQL Server is a managed service, it may not support all the specific SQL Server features required by the company. Additionally, Amazon EFS is primarily designed for Linux workloads and may not be the best fit for Windows-based file sharing.</span></p><p><span>D. </span><strong><span>Amazon RDS and EBS</span></strong><span>: Using Provisioned IOPS SSD (io2) EBS volumes for file sharing is not ideal as EBS volumes are block storage and not designed for file sharing between multiple instances. This setup would require additional management and may not provide the necessary file sharing capabilities.</span></p><p><span>By hosting all three tiers on Amazon EC2 instances and using Amazon FSx for Windows File Server for file sharing, the company can meet its requirements for specific SQL Server features and efficient file sharing between the tiers in a Windows-native environment.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-288-migrating-a-linux-based-web-server-group-to-aws-with-a-shared-file-store'><span>Question #288 Migrating a Linux-based web server group to AWS with a shared file store</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is migrating a Linux-based web server group to AWS. The web servers must access files in a shared file store for some content. The company must not make any changes to the application.</span></p><p><strong><span>What should a solutions architect do to meet these requirements?</span></strong></p><p><span>A. Create an Amazon S3 Standard bucket with access to the web servers.</span></p><p><span>B. Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin.</span></p><p><span>C. Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on all web servers.</span></p><p><span>D. Configure a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume to all web servers.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system on all web servers.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Elastic File System (Amazon EFS)</span></strong><span>:</span></p><ul><li><p><strong><span>Shared File System</span></strong><span>: Amazon EFS provides a scalable and fully managed Network File System (NFS) for use with AWS Cloud services and on-premises resources. It is designed to be accessed concurrently by multiple EC2 instances, making it ideal for shared file storage.</span></p></li><li><p><strong><span>No Application Changes</span></strong><span>: By mounting the EFS file system on all web servers, you can provide a shared file store without requiring any changes to the application. The web servers can access the shared files as if they were local files.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon S3 Standard Bucket (Option A)</span></strong><span>: While Amazon S3 is a highly durable and scalable object storage service, it is not designed for use as a shared file system that can be mounted directly on EC2 instances. It would require changes to the application to access files via the S3 API.</span></p></li><li><p><strong><span>Amazon CloudFront with S3 (Option B)</span></strong><span>: CloudFront is a content delivery network (CDN) that can cache and deliver content from an S3 bucket, but it does not provide a shared file system that can be mounted on EC2 instances. This option would also require changes to the application.</span></p></li><li><p><strong><span>Amazon EBS Volume (Option D)</span></strong><span>: Amazon EBS volumes are block storage devices that can be attached to EC2 instances. However, an EBS volume can only be attached to a single EC2 instance at a time, making it unsuitable for a shared file system across multiple web servers.</span></p></li></ul></li></ol><p><span>By creating an Amazon EFS file system and mounting it on all web servers, the solutions architect can provide a shared file store that meets the company&#39;s requirements without requiring any changes to the application. This approach leverages EFS&#39;s capabilities to provide a scalable, fully managed, and highly available file system that can be accessed concurrently by multiple instances.</span></p><hr /><p>&nbsp;</p><h3 id='question-289-securing-read-access-to-an-s3-bucket-for-an-aws-lambda-function'><span>Question #289 Securing read access to an S3 bucket for an AWS Lambda function</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an AWS Lambda function that needs read access to an Amazon S3 bucket that is located in the same AWS account. Which solution will meet these requirements in the MOST secure manner?</span></p><p><span>A. Apply an S3 bucket policy that grants read access to the S3 bucket.</span></p><p><span>B. Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to the S3 bucket.</span></p><p><span>C. Embed an access key and a secret key in the Lambda function&#39;s code to grant the required IAM permissions for read access to the S3 bucket.</span></p><p><span>D. Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to all S3 buckets in the account.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Apply an IAM role to the Lambda function. Apply an IAM policy to the role to grant read access to the S3 bucket.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>IAM Role for Lambda</span></strong><span>: Assigning an IAM role to the Lambda function is the most secure and recommended way to grant permissions. This approach ensures that the Lambda function assumes the role and inherits the permissions defined in the attached IAM policy.</span></p></li><li><p><strong><span>Fine-Grained Permissions</span></strong><span>: By applying an IAM policy to the role that grants read access specifically to the required S3 bucket, you ensure the principle of least privilege. This minimizes the risk by granting only the necessary permissions.</span></p></li><li><p><strong><span>Security Best Practices</span></strong><span>: Embedding access keys and secret keys in the Lambda function&#39;s code (option C) is not a secure practice and should be avoided. It exposes sensitive credentials and increases the risk of compromise.</span></p></li><li><p><strong><span>Specific Bucket Access</span></strong><span>: Option D grants read access to all S3 buckets in the account, which is broader than necessary and does not adhere to the principle of least privilege. It is more secure to grant access only to the specific S3 bucket needed by the Lambda function.</span></p></li><li><p><strong><span>S3 Bucket Policy</span></strong><span>: While applying an S3 bucket policy (option A) can grant the necessary access, it is generally better to manage access permissions through IAM roles and policies for better control and auditing.</span></p></li></ol><p><span>By applying an IAM role to the Lambda function and attaching an IAM policy that grants read access to the specific S3 bucket, the company ensures secure and controlled access to the required resources. This approach follows AWS security best practices and the principle of least privilege.</span></p><p>&nbsp;</p><hr /><h3 id='question-290-optimizing-cost-savings-for-a-web-application-on-ec2-instances'><span>Question #290 Optimizing cost savings for a web application on EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a web application on multiple Amazon EC2 instances. The EC2 instances are in an Auto Scaling group that scales in response to user demand. The company wants to optimize cost savings without making a long-term commitment.</span></p><p><strong><span>Which EC2 instance purchasing option should a solutions architect recommend to meet these requirements?</span></strong></p><p><span>A. Dedicated Instances only</span></p><p><span>B. On-Demand Instances only</span></p><p><span>C. A mix of On-Demand Instances and Spot Instances</span></p><p><span>D. A mix of On-Demand Instances and Reserved Instances</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. A mix of On-Demand Instances and Spot Instances</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>On-Demand Instances</span></strong><span>:</span></p><ul><li><p><strong><span>Flexibility</span></strong><span>: On-Demand Instances provide the flexibility to scale up or down based on user demand without any long-term commitment. They are suitable for applications with unpredictable workloads.</span></p></li><li><p><strong><span>Cost</span></strong><span>: While On-Demand Instances are more expensive than other purchasing options, they offer the flexibility needed for dynamic scaling.</span></p></li></ul></li><li><p><strong><span>Spot Instances</span></strong><span>:</span></p><ul><li><p><strong><span>Cost Savings</span></strong><span>: Spot Instances allow you to take advantage of unused EC2 capacity at significantly reduced prices compared to On-Demand Instances. They are ideal for workloads that can tolerate interruptions.</span></p></li><li><p><strong><span>Auto Scaling</span></strong><span>: By mixing Spot Instances with On-Demand Instances in an Auto Scaling group, you can optimize cost savings while maintaining the flexibility to handle varying user demand. The Auto Scaling group can be configured to use Spot Instances when available and fall back to On-Demand Instances when Spot Instances are not available.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Dedicated Instances (Option A)</span></strong><span>: Dedicated Instances are designed for workloads that require physical isolation at the host hardware level. They are more expensive and not necessary for this use case, which focuses on cost savings without long-term commitment.</span></p></li><li><p><strong><span>On-Demand Instances Only (Option B)</span></strong><span>: Using only On-Demand Instances provides flexibility but does not optimize cost savings as effectively as combining On-Demand with Spot Instances.</span></p></li><li><p><strong><span>Reserved Instances (Option D)</span></strong><span>: Reserved Instances offer significant cost savings but require a long-term commitment (1 or 3 years). This option is not suitable for the company&#39;s requirement to avoid long-term commitments.</span></p></li></ul></li></ol><p><span>By recommending a mix of On-Demand Instances and Spot Instances, the solutions architect can help the company optimize cost savings while maintaining the flexibility to scale in response to user demand. This approach leverages the cost benefits of Spot Instances and the flexibility of On-Demand Instances to provide an efficient and cost-effective solution.</span></p><p>&nbsp;</p><hr /><h3 id='question-291-securing-streaming-video-content-on-amazon-cloudfront'><span>Question #291 Securing streaming video content on Amazon CloudFront</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A media company uses Amazon CloudFront for its publicly available streaming video content. The company wants to secure the video content that is hosted in Amazon S3 by controlling who has access. Some of the company&#39;s users are using a custom HTTP client that does not support cookies. Some of the company&#39;s users are unable to change the hardcoded URLs that they are using for access. Which services or methods will meet these requirements with the LEAST impact to the users? (Choose two.)</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Signed cookies</span></p><p><span>B. Signed URLs</span></p><p><span>C. AWS AppSync</span></p><p><span>D. JSON Web Token (JWT)</span></p><p><span>E. AWS Secrets Manager</span></p><p><strong><span>Correct answers:</span></strong></p><p><span>A. Signed cookies</span></p><p><span>B. Signed URLs</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Signed Cookies (Option A)</span></strong><span>: Signed cookies allow you to control access to multiple files in your CloudFront distribution. They are useful when you want to grant access to a group of files, such as all the video files in a directory, without changing the URLs. This method is suitable for users who cannot change the hardcoded URLs they are using, as the cookies are set in the user&#39;s browser and do not require URL modifications.</span></p></li><li><p><strong><span>Signed URLs (Option B)</span></strong><span>: Signed URLs provide a way to grant temporary access to individual files in your CloudFront distribution. They are particularly useful for users who cannot support cookies, as the access control is embedded in the URL itself. This method allows you to control access to specific files and can include an expiration time to limit the duration of access.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>C. </span><strong><span>AWS AppSync</span></strong><span>: AWS AppSync is a managed service for building scalable GraphQL APIs. While it provides a way to control access to data, it is not directly relevant to securing streaming video content in CloudFront and would require significant changes to the existing infrastructure.</span></p><p><span>D. </span><strong><span>JSON Web Token (JWT)</span></strong><span>: JWTs are typically used for authorization and information exchange but are not directly supported by CloudFront for securing content. Implementing JWTs would require additional infrastructure and changes to the existing system, which may not be the least impactful solution for the users.</span></p><p><span>E. </span><strong><span>AWS Secrets Manager</span></strong><span>: AWS Secrets Manager is a service for managing and retrieving secrets such as database credentials and API keys. It is not directly applicable to controlling access to streaming video content in CloudFront.</span></p><p><span>By using Signed Cookies and Signed URLs, the media company can secure its streaming video content with minimal impact on users, ensuring that access is controlled without requiring support for cookies or changes to hardcoded URLs.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-292-ingesting-transforming-and-querying-real-time-streaming-data'><span>Question #292 Ingesting, transforming, and querying real-time streaming data</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is preparing a new data platform that will ingest real-time streaming data from multiple sources. The company needs to transform the data before writing the data to Amazon S3. The company needs the ability to use SQL to query the transformed data.</span></p><p><strong><span>Which solutions will meet these requirements? (Choose two.)</span></strong></p><p><span>A. Use Amazon Kinesis Data Streams to stream the data. Use Amazon Kinesis Data Analytics to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.</span></p><p><span>B. Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use AWS Glue to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.</span></p><p><span>C. Use AWS Database Migration Service (AWS DMS) to ingest the data. Use Amazon EMR to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.</span></p><p><span>D. Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use Amazon Kinesis Data Analytics to transform the data and to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3.</span></p><p><span>E. Use Amazon Kinesis Data Streams to stream the data. Use AWS Glue to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use the Amazon RDS query editor to query the transformed data from Amazon S3.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Use Amazon Kinesis Data Streams to stream the data. Use Amazon Kinesis Data Analytics to transform the data. Use Amazon Kinesis Data Firehose to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.</span></p><p><span>B. Use Amazon Managed Streaming for Apache Kafka (Amazon MSK) to stream the data. Use AWS Glue to transform the data and to write the data to Amazon S3. Use Amazon Athena to query the transformed data from Amazon S3.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Kinesis Data Streams and Kinesis Data Analytics</span></strong><span>:</span></p><ul><li><p><strong><span>Streaming Data</span></strong><span>: Amazon Kinesis Data Streams is designed for real-time data streaming.</span></p></li><li><p><strong><span>Data Transformation</span></strong><span>: Amazon Kinesis Data Analytics can be used to process and transform the streaming data in real-time using SQL.</span></p></li><li><p><strong><span>Data Delivery</span></strong><span>: Amazon Kinesis Data Firehose can be used to deliver the transformed data to Amazon S3.</span></p></li><li><p><strong><span>Querying Data</span></strong><span>: Amazon Athena can be used to run SQL queries on the data stored in Amazon S3.</span></p></li></ul></li><li><p><strong><span>Amazon MSK and AWS Glue</span></strong><span>:</span></p><ul><li><p><strong><span>Streaming Data</span></strong><span>: Amazon Managed Streaming for Apache Kafka (Amazon MSK) is another option for real-time data streaming.</span></p></li><li><p><strong><span>Data Transformation</span></strong><span>: AWS Glue can be used to transform the data before writing it to Amazon S3.</span></p></li><li><p><strong><span>Querying Data</span></strong><span>: Amazon Athena can be used to query the transformed data stored in Amazon S3.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS DMS and Amazon EMR (Option C)</span></strong><span>: AWS DMS is typically used for database migration and not for real-time data streaming. While Amazon EMR can transform and write data to S3, it is more complex and not as streamlined for this use case.</span></p></li><li><p><strong><span>Amazon RDS Query Editor (Options D and E)</span></strong><span>: The Amazon RDS query editor is not designed for querying data stored in Amazon S3. Amazon Athena is the appropriate service for querying data in S3.</span></p></li></ul></li></ol><p><span>By using Amazon Kinesis Data Streams with Kinesis Data Analytics and Kinesis Data Firehose, or Amazon MSK with AWS Glue, and querying the data with Amazon Athena, the solutions architect can meet the requirements for real-time data ingestion, transformation, and SQL querying efficiently.</span></p><p>&nbsp;</p><hr /><h3 id='question-293-implementing-a-new-backup-solution-with-aws-while-maintaining-local-access'><span>Question #293 Implementing a new backup solution with AWS while maintaining local access</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an on-premises volume backup solution that has reached its end of life. The company wants to use AWS as part of a new backup solution and wants to maintain local access to all the data while it is backed up on AWS. The company wants to ensure that the data backed up on AWS is automatically and securely transferred. Which solution meets these requirements?</span></p><p><span>A. Use AWS Snowball to migrate data out of the on-premises solution to Amazon S3. Configure on-premises systems to mount the Snowball S3 endpoint to provide local access to the data.</span></p><p><span>B. Use AWS Snowball Edge to migrate data out of the on-premises solution to Amazon S3. Use the Snowball Edge file interface to provide on-premises systems with local access to the data.</span></p><p><span>C. Use AWS Storage Gateway and configure a cached volume gateway. Run the Storage Gateway software appliance on premises and configure a percentage of data to cache locally. Mount the gateway storage volumes to provide local access to the data.</span></p><p><span>D. Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on-premises storage. Mount the gateway storage volumes to provide local access to the data.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on-premises storage. Mount the gateway storage volumes to provide local access to the data.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Storage Gateway - Stored Volume Gateway</span></strong><span>: The stored volume gateway configuration allows you to maintain a complete copy of the data on-premises while asynchronously backing up point-in-time snapshots of the data to AWS. This ensures that you have local access to all the data while it is securely backed up to AWS.</span></p></li><li><p><strong><span>Local Access and Backup</span></strong><span>: Stored volumes are ideal for use cases where you need low-latency access to your entire dataset locally, while also ensuring that the data is securely and automatically backed up to AWS. The data is stored on-premises, and AWS Storage Gateway manages the replication to AWS.</span></p></li><li><p><strong><span>Automatic and Secure Transfer</span></strong><span>: The data is automatically and securely transferred to AWS using the Storage Gateway service, which handles encryption and secure transmission of data to AWS.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Snowball</span></strong><span>: AWS Snowball is primarily used for large-scale data migration and does not provide ongoing local access to data. It is not designed for continuous backup and access scenarios.</span></p><p><span>B. </span><strong><span>AWS Snowball Edge</span></strong><span>: Similar to Snowball, Snowball Edge is used for data migration and temporary local storage. It does not provide a long-term solution for continuous backup and local access.</span></p><p><span>C. </span><strong><span>AWS Storage Gateway - Cached Volume Gateway</span></strong><span>: The cached volume gateway configuration caches frequently accessed data locally while storing the full dataset in AWS. It is suitable for scenarios where you need low-latency access to active data but not the entire dataset locally.</span></p><p><span>By using AWS Storage Gateway with a stored volume gateway configuration, the company can ensure that it maintains local access to all its data while securely and automatically backing up the data to AWS. This solution meets the requirements for continuous backup and local access without the need for significant changes to the existing setup.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-294-configuring-access-to-an-amazon-s3-bucket-without-traversing-the-internet'><span>Question #294 Configuring access to an Amazon S3 bucket without traversing the internet</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An application that is hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Traffic must not traverse the internet.</span></p><p><strong><span>How should a solutions architect configure access to meet these requirements?</span></strong></p><p><span>A. Create a private hosted zone by using Amazon Route 53.</span></p><p><span>B. Set up a gateway VPC endpoint for Amazon S3 in the VPC.</span></p><p><span>C. Configure the EC2 instances to use a NAT gateway to access the S3 bucket.</span></p><p><span>D. Establish an AWS Site-to-Site VPN connection between the VPC and the S3 bucket.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Set up a gateway VPC endpoint for Amazon S3 in the VPC.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Gateway VPC Endpoint for S3</span></strong><span>:</span></p><ul><li><p><strong><span>Direct Access</span></strong><span>: A gateway VPC endpoint allows you to privately connect your VPC to supported AWS services, such as Amazon S3, without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.</span></p></li><li><p><strong><span>No Internet Traffic</span></strong><span>: By setting up a gateway VPC endpoint for Amazon S3, traffic between the EC2 instances and the S3 bucket does not traverse the internet. This ensures secure and private communication within the AWS network.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Private Hosted Zone (Option A)</span></strong><span>: Creating a private hosted zone in Amazon Route 53 helps with DNS resolution within a VPC but does not address the requirement to keep traffic from traversing the internet.</span></p></li><li><p><strong><span>NAT Gateway (Option C)</span></strong><span>: A NAT gateway allows instances in a private subnet to access the internet or other AWS services, but it does so by routing traffic through the internet, which does not meet the requirement.</span></p></li><li><p><strong><span>Site-to-Site VPN (Option D)</span></strong><span>: Establishing a Site-to-Site VPN connection is used to connect an on-premises network to an AWS VPC. It is not applicable for connecting EC2 instances in a VPC to S3 without traversing the internet.</span></p></li></ul></li></ol><p><span>By setting up a gateway VPC endpoint for Amazon S3, the solutions architect can ensure that the EC2 instances access the S3 bucket without traversing the internet, meeting the requirement for secure and private communication.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-295-managing-pii-data-for-multiple-applications-with-minimal-operational-overhead'><span>Question #295 Managing PII data for multiple applications with minimal operational overhead</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An ecommerce company stores terabytes of customer data in the AWS Cloud. The data contains personally identifiable information (PII). The company wants to use the data in three applications. Only one of the applications needs to process the PII. The PII must be removed before the other two applications process the data. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Store the data in an Amazon DynamoDB table. Create a proxy application layer to intercept and process the data that each application requests.</span></p><p><span>B. Store the data in an Amazon S3 bucket. Process and transform the data by using S3 Object Lambda before returning the data to the requesting application.</span></p><p><span>C. Process the data and store the transformed data in three separate Amazon S3 buckets so that each application has its own custom dataset. Point each application to its respective S3 bucket.</span></p><p><span>D. Process the data and store the transformed data in three separate Amazon DynamoDB tables so that each application has its own custom dataset. Point each application to its respective DynamoDB table.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Store the data in an Amazon S3 bucket. Process and transform the data by using S3 Object Lambda before returning the data to the requesting application.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3 and S3 Object Lambda</span></strong><span>: By storing the data in an Amazon S3 bucket and using S3 Object Lambda, you can dynamically process and transform the data as it is requested by the applications. This allows you to remove PII from the data for the two applications that do not need it, while providing the full dataset to the application that requires the PII.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: S3 Object Lambda allows you to add custom code to process the data without needing to manage separate datasets or additional infrastructure. This approach minimizes operational overhead as you do not need to maintain multiple copies of the data.</span></p></li><li><p><strong><span>On-Demand Transformation</span></strong><span>: With S3 Object Lambda, the transformation of the data (such as removing PII) happens on-demand when the data is requested. This ensures that the data is always up-to-date and reduces the need for pre-processing and storing multiple versions of the data.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Proxy Application Layer</span></strong><span>: Creating a proxy application layer to intercept and process the data adds complexity and operational overhead. It requires managing and maintaining additional infrastructure.</span></p><p><span>C. </span><strong><span>Separate S3 Buckets</span></strong><span>: Storing transformed data in three separate S3 buckets requires maintaining multiple copies of the data, which increases storage costs and operational complexity.</span></p><p><span>D. </span><strong><span>Separate DynamoDB Tables</span></strong><span>: Storing transformed data in three separate DynamoDB tables also requires maintaining multiple copies of the data and managing the synchronization between them, leading to increased operational overhead.</span></p><p><span>By using Amazon S3 with S3 Object Lambda, the company can efficiently manage and transform the data with minimal operational overhead, ensuring that PII is removed for the applications that do not need it while providing the necessary data to the application that requires PII.</span></p><p>&nbsp;</p><hr /><h3 id='question-296-creating-a-new-vpc-cidr-block-for-vpc-peering'><span>Question #296 Creating a new VPC CIDR block for VPC peering</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A development team has launched a new application that is hosted on Amazon EC2 instances inside a development VPC. A solutions architect needs to create a new VPC in the same account. The new VPC will be peered with the development VPC. The VPC CIDR block for the development VPC is 192.168.0.0/24. The solutions architect needs to create a CIDR block for the new VPC. The CIDR block must be valid for a VPC peering connection to the development VPC.</span></p><p><strong><span>What is the SMALLEST CIDR block that meets these requirements?</span></strong></p><p><span>A. 192.168.0.0/26</span></p><p><span>B. 192.168.0.0/24</span></p><p><span>C. 192.168.1.0/32</span></p><p><span>D. 10.0.1.0/24</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. 10.0.1.0/24</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>VPC Peering Requirements</span></strong><span>:</span></p><ul><li><p><strong><span>Non-overlapping CIDR Blocks</span></strong><span>: For VPC peering to work, the CIDR blocks of the VPCs involved must not overlap. This means that the CIDR block for the new VPC must be different from the CIDR block of the development VPC (192.168.0.0/24).</span></p></li></ul></li><li><p><strong><span>CIDR Block Analysis</span></strong><span>:</span></p><ul><li><p><strong><span>192.168.0.0/26 (Option A)</span></strong><span>: This CIDR block overlaps with the development VPC&#39;s CIDR block (192.168.0.0/24) and is not valid for VPC peering.</span></p></li><li><p><strong><span>192.168.0.0/24 (Option B)</span></strong><span>: This is the same CIDR block as the development VPC, so it is not valid for VPC peering.</span></p></li><li><p><strong><span>192.168.1.0/32 (Option C)</span></strong><span>: This CIDR block is too small for a VPC and also overlaps with the 192.168.0.0/24 block.</span></p></li><li><p><strong><span>10.0.1.0/24 (Option D)</span></strong><span>: This CIDR block does not overlap with 192.168.0.0/24 and is valid for VPC peering. It is the smallest non-overlapping CIDR block provided in the options.</span></p></li></ul></li></ol><p><span>By choosing the 10.0.1.0/24 CIDR block, the solutions architect ensures that the new VPC has a non-overlapping CIDR block with the development VPC, making it valid for VPC peering. This option meets the requirement for the smallest valid CIDR block for the new VPC.</span></p><p>&nbsp;</p><hr /><h3 id='question-297-automating-scalability-of-an-application-on-amazon-ec2-instances'><span>Question #297 Automating scalability of an application on Amazon EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company deploys an application on five Amazon EC2 instances. An Application Load Balancer (ALB) distributes traffic to the instances by using a target group. The average CPU usage on each of the instances is below 10% most of the time, with occasional surges to 65%. A solutions architect needs to implement a solution to automate the scalability of the application. The solution must optimize the cost of the architecture and must ensure that the application has enough CPU resources when surges occur. Which solution will meet these requirements?</span></p><p><span>A. Create an Amazon CloudWatch alarm that enters the ALARM state when the CPUUtilization metric is less than 20%. Create an AWS Lambda function that the CloudWatch alarm invokes to terminate one of the EC2 instances in the ALB target group.</span></p><p><span>B. Create an EC2 Auto Scaling group. Select the existing ALB as the load balancer and the existing target group as the target group. Set a target tracking scaling policy that is based on the ASGAverageCPUUtilization metric. Set the minimum instances to 2, the desired capacity to 3, the maximum instances to 6, and the target value to 50%. Add the EC2 instances to the Auto Scaling group.</span></p><p><span>C. Create an EC2 Auto Scaling group. Select the existing ALB as the load balancer and the existing target group as the target group. Set the minimum instances to 2, the desired capacity to 3, and the maximum instances to 6. Add the EC2 instances to the Auto Scaling group.</span></p><p><span>D. Create two Amazon CloudWatch alarms. Configure the first CloudWatch alarm to enter the ALARM state when the average CPUUtilization metric is below 20%. Configure the second CloudWatch alarm to enter the ALARM state when the average CPUUtilization metric is above 50%. Configure the alarms to publish to an Amazon Simple Notification Service (Amazon SNS) topic to send an email message. After receiving the message, log in to decrease or increase the number of EC2 instances that are running.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create an EC2 Auto Scaling group. Select the existing ALB as the load balancer and the existing target group as the target group. Set a target tracking scaling policy that is based on the ASGAverageCPUUtilization metric. Set the minimum instances to 2, the desired capacity to 3, the maximum instances to 6, and the target value to 50%. Add the EC2 instances to the Auto Scaling group.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>EC2 Auto Scaling Group</span></strong><span>: Creating an Auto Scaling group ensures that the application can automatically scale in and out based on the demand. This helps in optimizing costs by running only the necessary number of instances.</span></p></li><li><p><strong><span>Target Tracking Scaling Policy</span></strong><span>: By setting a target tracking scaling policy based on the </span><code>ASGAverageCPUUtilization</code><span> metric, the Auto Scaling group can dynamically adjust the number of instances to maintain the desired CPU utilization. This ensures that there are enough CPU resources during surges and optimizes costs during periods of low usage.</span></p></li><li><p><strong><span>Configuration</span></strong><span>: Setting the minimum instances to 2, the desired capacity to 3, and the maximum instances to 6 provides a balance between ensuring availability and optimizing costs. The target value of 50% CPU utilization helps maintain a responsive application while avoiding over-provisioning.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Terminating Instances with Lambda</span></strong><span>: Terminating instances based on a CloudWatch alarm and Lambda function does not provide a dynamic scaling solution and can lead to insufficient resources during surges.</span></p><p><span>C. </span><strong><span>Auto Scaling Group without Target Tracking</span></strong><span>: While this option creates an Auto Scaling group, it lacks a target tracking scaling policy. Without this policy, the Auto Scaling group will not automatically adjust the number of instances based on CPU utilization.</span></p><p><span>D. </span><strong><span>Manual Scaling with CloudWatch Alarms and SNS</span></strong><span>: This option requires manual intervention to scale the number of instances, which is not automated and can lead to delays in responding to changes in demand.</span></p><p><span>By creating an EC2 Auto Scaling group with a target tracking scaling policy based on the </span><code>ASGAverageCPUUtilization</code><span> metric, the company can automate the scalability of the application, optimize costs, and ensure that the application has enough CPU resources when surges occur.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-298-making-an-application-highly-available-across-multiple-availability-zones'><span>Question #298 Making an application highly available across multiple Availability Zones</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is running a critical business application on Amazon EC2 instances behind an Application Load Balancer. The EC2 instances run in an Auto Scaling group and access an Amazon RDS DB instance. The design did not pass an operational review because the EC2 instances and the DB instance are all located in a single Availability Zone. A solutions architect must update the design to use a second Availability Zone.</span></p><p><strong><span>Which solution will make the application highly available?</span></strong></p><p><span>A. Provision a subnet in each Availability Zone. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance with connections to each network.</span></p><p><span>B. Provision two subnets that extend across both Availability Zones. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance with connections to each network.</span></p><p><span>C. Provision a subnet in each Availability Zone. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance for Multi-AZ deployment.</span></p><p><span>D. Provision a subnet that extends across both Availability Zones. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance for Multi-AZ deployment.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Provision a subnet in each Availability Zone. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance for Multi-AZ deployment.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Subnets in Multiple Availability Zones</span></strong><span>:</span></p><ul><li><p><strong><span>Subnets</span></strong><span>: To achieve high availability, you need to provision subnets in multiple Availability Zones (AZs). Each AZ should have its own subnet.</span></p></li><li><p><strong><span>Auto Scaling Group</span></strong><span>: The Auto Scaling group should be configured to distribute EC2 instances across both subnets in different AZs. This ensures that the application remains available even if one AZ fails.</span></p></li></ul></li><li><p><strong><span>Multi-AZ Deployment for RDS</span></strong><span>:</span></p><ul><li><p><strong><span>RDS Multi-AZ</span></strong><span>: Configuring the RDS DB instance for Multi-AZ deployment ensures that the database is replicated across multiple AZs. In the event of an AZ failure, the database will failover to a standby instance in another AZ, providing high availability for the database layer.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Option A</span></strong><span>: While provisioning subnets in each AZ and distributing EC2 instances across them is correct, configuring the DB instance with connections to each network is not sufficient. The DB instance itself needs to be configured for Multi-AZ deployment to ensure high availability.</span></p></li><li><p><strong><span>Option B</span></strong><span>: Subnets cannot extend across multiple AZs. Each subnet is confined to a single AZ. Additionally, configuring the DB instance with connections to each network is not the correct approach for high availability.</span></p></li><li><p><strong><span>Option D</span></strong><span>: As mentioned, subnets cannot extend across multiple AZs. Each subnet must be specific to a single AZ.</span></p></li></ul></li></ol><p><span>By provisioning a subnet in each Availability Zone, configuring the Auto Scaling group to distribute EC2 instances across both AZs, and configuring the RDS DB instance for Multi-AZ deployment, the solutions architect can ensure that the application is highly available and resilient to AZ failures.</span></p><p>&nbsp;</p><hr /><h3 id='question-299-high-performance-storage-solution-for-processing-8-tb-of-data'><span>Question #299 High-performance storage solution for processing 8 TB of data</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A research laboratory needs to process approximately 8 TB of data. The laboratory requires sub-millisecond latencies and a minimum throughput of 6 GBps for the storage subsystem. Hundreds of Amazon EC2 instances that run Amazon Linux will distribute and process the data. Which solution will meet the performance requirements?</span></p><p><span>A. Create an Amazon FSx for NetApp ONTAP file system. Set each volume&#39;s tiering policy to ALL. Import the raw data into the file system. Mount the file system on the EC2 instances.</span></p><p><span>B. Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent SSD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.</span></p><p><span>C. Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent HDD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.</span></p><p><span>D. Create an Amazon FSx for NetApp ONTAP file system. Set each volume&#39;s tiering policy to NONE. Import the raw data into the file system. Mount the file system on the EC2 instances.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent SSD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon FSx for Lustre</span></strong><span>: Amazon FSx for Lustre is designed for high-performance computing workloads and provides the required sub-millisecond latencies and high throughput. It can handle the large-scale data processing needs of the research laboratory.</span></p></li><li><p><strong><span>Persistent SSD Storage</span></strong><span>: Using persistent SSD storage ensures that the file system can meet the minimum throughput requirement of 6 GBps. SSD storage provides the necessary performance characteristics for high I/O operations and low latency.</span></p></li><li><p><strong><span>Integration with Amazon S3</span></strong><span>: By storing the raw data in an Amazon S3 bucket and using FSx for Lustre with the option to import data from and export data to S3, the laboratory can efficiently manage and process the data. This setup allows for seamless data movement between S3 and the Lustre file system.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>FSx for NetApp ONTAP with Tiering Policy to ALL</span></strong><span>: Setting the tiering policy to ALL would move data to lower-cost storage tiers, which may not meet the performance requirements for sub-millisecond latencies and high throughput.</span></p><p><span>C. </span><strong><span>FSx for Lustre with Persistent HDD Storage</span></strong><span>: Using HDD storage would not provide the necessary performance characteristics for sub-millisecond latencies and high throughput. HDDs are not suitable for workloads requiring high IOPS and low latency.</span></p><p><span>D. </span><strong><span>FSx for NetApp ONTAP with Tiering Policy to NONE</span></strong><span>: While FSx for NetApp ONTAP can provide good performance, FSx for Lustre is specifically optimized for high-performance computing workloads and is a better fit for the laboratory&#39;s requirements.</span></p><p><span>By creating an Amazon S3 bucket to store the raw data and using an Amazon FSx for Lustre file system with persistent SSD storage, the research laboratory can achieve the required performance with sub-millisecond latencies and a minimum throughput of 6 GBps, ensuring efficient data processing across hundreds of EC2 instances.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-300-migrating-a-legacy-application-to-the-aws-cloud-cost-effectively'><span>Question #300 Migrating a legacy application to the AWS Cloud cost-effectively</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs to migrate a legacy application from an on-premises data center to the AWS Cloud because of hardware capacity constraints. The application runs 24 hours a day, 7 days a week. The application&#39;s database storage continues to grow over time.</span></p><p><strong><span>What should a solutions architect do to meet these requirements MOST cost-effectively?</span></strong></p><p><span>A. Migrate the application layer to Amazon EC2 Spot Instances. Migrate the data storage layer to Amazon S3.</span></p><p><span>B. Migrate the application layer to Amazon EC2 Reserved Instances. Migrate the data storage layer to Amazon RDS On-Demand Instances.</span></p><p><span>C. Migrate the application layer to Amazon EC2 Reserved Instances. Migrate the data storage layer to Amazon Aurora Reserved Instances.</span></p><p><span>D. Migrate the application layer to Amazon EC2 On-Demand Instances. Migrate the data storage layer to Amazon RDS Reserved Instances.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Migrate the application layer to Amazon EC2 Reserved Instances. Migrate the data storage layer to Amazon Aurora Reserved Instances.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon EC2 Reserved Instances</span></strong><span>:</span></p><ul><li><p><strong><span>Cost Savings</span></strong><span>: Reserved Instances provide significant cost savings compared to On-Demand Instances, especially for applications that run 24/7. By committing to a 1-year or 3-year term, the company can reduce its compute costs.</span></p></li><li><p><strong><span>Predictable Workload</span></strong><span>: Since the application runs continuously, Reserved Instances are a cost-effective choice.</span></p></li></ul></li><li><p><strong><span>Amazon Aurora Reserved Instances</span></strong><span>:</span></p><ul><li><p><strong><span>Scalability and Performance</span></strong><span>: Amazon Aurora is a highly performant and scalable relational database service that is compatible with MySQL and PostgreSQL. It automatically grows storage as needed, which is ideal for applications with growing database storage requirements.</span></p></li><li><p><strong><span>Cost Savings</span></strong><span>: Similar to EC2 Reserved Instances, Aurora Reserved Instances offer significant cost savings over On-Demand Instances.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Spot Instances (Option A)</span></strong><span>: Spot Instances are not suitable for applications that require continuous availability, as they can be interrupted by AWS with little notice. Moving the data storage layer to Amazon S3 is also not appropriate for a database.</span></p></li><li><p><strong><span>On-Demand Instances (Option B and D)</span></strong><span>: While On-Demand Instances offer flexibility, they are more expensive than Reserved Instances for long-running applications. Using On-Demand Instances for both the application layer and the data storage layer would not be cost-effective.</span></p></li><li><p><strong><span>RDS On-Demand Instances (Option B)</span></strong><span>: Using RDS On-Demand Instances for the database layer would be more expensive than using Aurora Reserved Instances, especially for a growing database with continuous usage.</span></p></li></ul></li></ol><p><span>By migrating the application layer to Amazon EC2 Reserved Instances and the data storage layer to Amazon Aurora Reserved Instances, the solutions architect can ensure that the migration is cost-effective while meeting the continuous availability and growing storage requirements of the application.</span></p><hr /><p>&nbsp;</p><h2 id='questions-301-400'><span>Questions 301-400</span></h2><p>&nbsp;</p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-301-migrating-30-tb-of-data-to-amazon-fsx-for-windows-file-server'><span>Question #301 Migrating 30 TB of data to Amazon FSx for Windows File Server</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A university research laboratory needs to migrate 30 TB of data from an on-premises Windows file server to Amazon FSx for Windows File Server. The laboratory has a 1 Gbps network link that many other departments in the university share. The laboratory wants to implement a data migration service that will maximize the performance of the data transfer. However, the laboratory needs to be able to control the amount of bandwidth that the service uses to minimize the impact on other departments. The data migration must take place within the next 5 days. Which AWS solution will meet these requirements?</span></p><p><span>A. AWS Snowcone</span></p><p><span>B. Amazon FSx File Gateway</span></p><p><span>C. AWS DataSync</span></p><p><span>D. AWS Transfer Family</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. AWS DataSync</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS DataSync</span></strong><span>: AWS DataSync is a data transfer service that simplifies, automates, and accelerates moving large amounts of data between on-premises storage and AWS storage services. DataSync is designed for high-performance data transfers and can handle large datasets efficiently.</span></p></li><li><p><strong><span>Bandwidth Control</span></strong><span>: DataSync allows you to control the amount of bandwidth used for the data transfer. This feature is crucial for minimizing the impact on other departments sharing the same network link.</span></p></li><li><p><strong><span>Performance</span></strong><span>: DataSync is optimized for performance and can transfer data at high speeds, making it suitable for migrating 30 TB of data within the required timeframe of 5 days.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Snowcone</span></strong><span>: AWS Snowcone is a small, portable edge computing and data transfer device. While it is useful for small-scale data transfers and edge computing, it is not suitable for transferring 30 TB of data within a short timeframe.</span></p><p><span>B. </span><strong><span>Amazon FSx File Gateway</span></strong><span>: FSx File Gateway provides a way to access Amazon FSx for Windows File Server from on-premises environments, but it is not designed specifically for large-scale data migration. It does not offer the same performance optimization and bandwidth control features as DataSync.</span></p><p><span>D. </span><strong><span>AWS Transfer Family</span></strong><span>: AWS Transfer Family provides managed file transfer services for SFTP, FTPS, and FTP. While it supports secure file transfers, it is not optimized for large-scale data migration and does not offer the same level of performance and bandwidth control as DataSync.</span></p><p><span>By using AWS DataSync, the university research laboratory can efficiently migrate 30 TB of data to Amazon FSx for Windows File Server while controlling the bandwidth usage to minimize the impact on other departments, ensuring that the data migration is completed within the required timeframe.</span></p><p>&nbsp;</p><hr /><h3 id='question-302-improving-performance-and-scalability-for-a-mobile-app-streaming-slow-motion-video-clips'><span>Question #302 Improving performance and scalability for a mobile app streaming slow-motion video clips</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to create a mobile app that allows users to stream slow-motion video clips on their mobile devices. Currently, the app captures video clips and uploads the video clips in raw format into an Amazon S3 bucket. The app retrieves these video clips directly from the S3 bucket. However, the videos are large in their raw format. Users are experiencing issues with buffering and playback on mobile devices. The company wants to implement solutions to maximize the performance and scalability of the app while minimizing operational overhead.</span></p><p><strong><span>Which combination of solutions will meet these requirements? (Choose two.)</span></strong></p><p><span>A. Deploy Amazon CloudFront for content delivery and caching.</span></p><p><span>B. Use AWS DataSync to replicate the video files across AWS Regions in other S3 buckets.</span></p><p><span>C. Use Amazon Elastic Transcoder to convert the video files to more appropriate formats.</span></p><p><span>D. Deploy an Auto Scaling group of Amazon EC2 instances in Local Zones for content delivery and caching.</span></p><p><span>E. Deploy an Auto Scaling group of Amazon EC2 instances to convert the video files to more appropriate formats.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Deploy Amazon CloudFront for content delivery and caching.</span></p><p><span>C. Use Amazon Elastic Transcoder to convert the video files to more appropriate formats.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon CloudFront for Content Delivery and Caching</span></strong><span>:</span></p><ul><li><p><strong><span>Content Delivery Network (CDN)</span></strong><span>: Amazon CloudFront is a global content delivery network (CDN) that can cache video content at edge locations close to the users. This reduces latency and improves playback performance by delivering content from the nearest edge location.</span></p></li><li><p><strong><span>Caching</span></strong><span>: CloudFront caches the video files, which helps reduce the load on the origin S3 bucket and improves the scalability of the application.</span></p></li></ul></li><li><p><strong><span>Amazon Elastic Transcoder for Video Conversion</span></strong><span>:</span></p><ul><li><p><strong><span>Video Transcoding</span></strong><span>: Amazon Elastic Transcoder is a media transcoding service that can convert raw video files into formats that are more suitable for streaming on mobile devices. This reduces the file size and improves playback performance by optimizing the video format for mobile devices.</span></p></li><li><p><strong><span>Operational Overhead</span></strong><span>: Elastic Transcoder is a managed service, which minimizes operational overhead compared to managing a fleet of EC2 instances for video conversion.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS DataSync (Option B)</span></strong><span>: DataSync is used for data transfer between storage systems and is not relevant for improving video streaming performance or reducing video file sizes.</span></p></li><li><p><strong><span>EC2 Instances in Local Zones (Option D)</span></strong><span>: Using EC2 instances in Local Zones for content delivery and caching would increase operational overhead and complexity compared to using CloudFront.</span></p></li><li><p><strong><span>EC2 Instances for Video Conversion (Option E)</span></strong><span>: While EC2 instances can be used for video conversion, this approach would involve more operational overhead compared to using the managed Amazon Elastic Transcoder service.</span></p></li></ul></li></ol><p><span>By deploying Amazon CloudFront for content delivery and caching, and using Amazon Elastic Transcoder to convert the video files to more appropriate formats, the company can maximize the performance and scalability of the app while minimizing operational overhead. This combination ensures that the videos are optimized for streaming and delivered efficiently to users.</span></p><p>&nbsp;</p><hr /><h3 id='question-303-scaling-an-amazon-ecs-cluster-with-fargate-launch-type'><span>Question #303 Scaling an Amazon ECS Cluster with Fargate Launch Type</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is launching a new application deployed on an Amazon Elastic Container Service (Amazon ECS) cluster and is using the Fargate launch type for ECS tasks. The company is monitoring CPU and memory usage because it is expecting high traffic to the application upon its launch. However, the company wants to reduce costs when utilization decreases. What should a solutions architect recommend?</span></p><p><span>A. Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.</span></p><p><span>B. Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm.</span></p><p><span>C. Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.</span></p><p><span>D. Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Application Auto Scaling</span></strong><span>: AWS Application Auto Scaling is the service designed to automatically scale AWS resources, including ECS tasks, based on predefined metrics and policies. It is the appropriate service for scaling ECS tasks running on Fargate.</span></p></li><li><p><strong><span>Target Tracking Policies</span></strong><span>: Target tracking scaling policies are similar to the way that Amazon EC2 Auto Scaling target tracking works. They adjust the number of running ECS tasks to maintain the specified target utilization, such as CPU or memory usage. This provides a dynamic and responsive way to handle varying traffic patterns while optimizing costs.</span></p></li><li><p><strong><span>CloudWatch Alarms</span></strong><span>: By using Amazon CloudWatch alarms to monitor CPU and memory usage, the scaling actions can be triggered automatically based on metric breaches, ensuring that the application scales up during high traffic and scales down during low traffic, reducing costs.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon EC2 Auto Scaling</span></strong><span>: This option is not applicable to ECS tasks using the Fargate launch type. EC2 Auto Scaling is used for scaling EC2 instances, not ECS tasks.</span></p><p><span>B. </span><strong><span>AWS Lambda Function</span></strong><span>: While it is possible to use a Lambda function to scale ECS tasks, it adds unnecessary complexity. AWS Application Auto Scaling provides a more straightforward and integrated solution for this use case.</span></p><p><span>C. </span><strong><span>Amazon EC2 Auto Scaling with Simple Scaling Policies</span></strong><span>: Similar to option A, this approach is not applicable to ECS tasks using the Fargate launch type. EC2 Auto Scaling is used for scaling EC2 instances.</span></p><p><span>By using AWS Application Auto Scaling with target tracking policies and CloudWatch alarms, the company can ensure that the ECS tasks running on Fargate automatically scale in response to changes in traffic, optimizing resource usage and reducing costs when utilization decreases.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-304-transferring-large-amounts-of-data-between-nfs-file-systems-in-different-aws-regions'><span>Question #304 Transferring large amounts of data between NFS file systems in different AWS Regions</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company recently created a disaster recovery site in a different AWS Region. The company needs to transfer large amounts of data back and forth between NFS file systems in the two Regions on a periodic basis.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST operational overhead?</span></strong></p><p><span>A. Use AWS DataSync.</span></p><p><span>B. Use AWS Snowball devices.</span></p><p><span>C. Set up an SFTP server on Amazon EC2.</span></p><p><span>D. Use AWS Database Migration Service (AWS DMS).</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use AWS DataSync.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS DataSync</span></strong><span>:</span></p><ul><li><p><strong><span>Purpose-built for Data Transfer</span></strong><span>: AWS DataSync is a managed service specifically designed for transferring large amounts of data between on-premises storage and AWS, as well as between AWS storage services in different Regions.</span></p></li><li><p><strong><span>Ease of Use</span></strong><span>: DataSync simplifies data transfer by automating and accelerating the process, requiring minimal operational overhead.</span></p></li><li><p><strong><span>Periodic Transfers</span></strong><span>: DataSync supports scheduled transfers, making it suitable for periodic data synchronization between NFS file systems in different Regions.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Snowball Devices (Option B)</span></strong><span>: Snowball devices are designed for transferring large amounts of data to and from AWS physically. They are more suitable for one-time large data migrations rather than periodic transfers.</span></p></li><li><p><strong><span>SFTP Server on Amazon EC2 (Option C)</span></strong><span>: Setting up and managing an SFTP server on EC2 involves significant operational overhead, including server maintenance, security, and scalability.</span></p></li><li><p><strong><span>AWS Database Migration Service (AWS DMS) (Option D)</span></strong><span>: AWS DMS is designed for migrating databases and is not suitable for transferring data between NFS file systems.</span></p></li></ul></li></ol><p><span>By using AWS DataSync, the company can efficiently transfer large amounts of data between NFS file systems in different AWS Regions with the least operational overhead. DataSync&#39;s managed nature and ability to schedule transfers make it the optimal solution for this use case.</span></p><p>&nbsp;</p><hr /><h3 id='question-305-designing-a-shared-storage-solution-for-a-gaming-application'><span>Question #305 Designing a shared storage solution for a gaming application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is designing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed. Which AWS solution meets these requirements?</span></p><p><span>A. Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.</span></p><p><span>B. Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.</span></p><p><span>C. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.</span></p><p><span>D. Create an Amazon S3 bucket. Assign an IAM role to the application to grant access to the S3 bucket. Mount the S3 bucket to the application server.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon FSx for Windows File Server</span></strong><span>: Amazon FSx for Windows File Server is a fully managed file storage service that is built on Windows Server. It provides native support for the SMB protocol, which is required for SMB clients to access data.</span></p></li><li><p><strong><span>Fully Managed Solution</span></strong><span>: FSx for Windows File Server is a fully managed service, meaning that AWS handles the setup, maintenance, and scaling of the file system, reducing operational overhead for the company.</span></p></li><li><p><strong><span>SMB Protocol Support</span></strong><span>: Since the requirement specifies the need for SMB clients to access data, FSx for Windows File Server is the most suitable solution as it natively supports the SMB protocol.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS DataSync</span></strong><span>: AWS DataSync is a data transfer service and does not provide a mountable file system for continuous access. It is used for migrating data between on-premises storage and AWS storage services.</span></p><p><span>B. </span><strong><span>Amazon EC2 Windows Instance</span></strong><span>: Setting up a Windows file share on an EC2 instance involves managing the instance and the file share configuration, which adds operational complexity. This solution is not fully managed.</span></p><p><span>D. </span><strong><span>Amazon S3 Bucket</span></strong><span>: While Amazon S3 is a highly scalable object storage service, it does not natively support the SMB protocol. Mounting S3 as a file system requires additional tools and does not provide the same functionality as a native SMB file share.</span></p><p><span>By using Amazon FSx for Windows File Server, the company can meet the requirements for a fully managed shared storage solution that supports SMB clients, ensuring efficient and seamless access to data for the gaming application.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-306-running-an-in-memory-database-for-a-latency-sensitive-application-on-ec2-instances'><span>Question #306 Running an in-memory database for a latency-sensitive application on EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to run an in-memory database for a latency-sensitive application that runs on Amazon EC2 instances. The application processes more than 100,000 transactions each minute and requires high network throughput. A solutions architect needs to provide a cost-effective network design that minimizes data transfer charges.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><span>A. Launch all EC2 instances in the same Availability Zone within the same AWS Region. Specify a placement group with cluster strategy when launching EC2 instances.</span></p><p><span>B. Launch all EC2 instances in different Availability Zones within the same AWS Region. Specify a placement group with partition strategy when launching EC2 instances.</span></p><p><span>C. Deploy an Auto Scaling group to launch EC2 instances in different Availability Zones based on a network utilization target.</span></p><p><span>D. Deploy an Auto Scaling group with a step scaling policy to launch EC2 instances in different Availability Zones.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Launch all EC2 instances in the same Availability Zone within the same AWS Region. Specify a placement group with cluster strategy when launching EC2 instances.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Cluster Placement Group</span></strong><span>:</span></p><ul><li><p><strong><span>High Network Throughput and Low Latency</span></strong><span>: A cluster placement group is designed to provide low-latency networking and high network throughput for EC2 instances. Instances in a cluster placement group are physically located close to each other within a single Availability Zone, which minimizes network latency and maximizes throughput.</span></p></li><li><p><strong><span>Cost-Effective</span></strong><span>: By keeping all EC2 instances within the same Availability Zone, you avoid inter-AZ data transfer charges, which can be significant for high-throughput applications.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Partition Strategy (Option B)</span></strong><span>: While a partition placement group can help in distributing instances across partitions to reduce the impact of hardware failures, it does not provide the same level of low-latency and high-throughput networking as a cluster placement group.</span></p></li><li><p><strong><span>Auto Scaling Group Across AZs (Options C and D)</span></strong><span>: Deploying EC2 instances across multiple Availability Zones can provide high availability, but it incurs inter-AZ data transfer charges, which are not cost-effective for a high-throughput, latency-sensitive application.</span></p></li></ul></li></ol><p><span>By launching all EC2 instances in the same Availability Zone and specifying a cluster placement group, the solutions architect can ensure that the application benefits from high network throughput and low latency, while also minimizing data transfer charges. This approach is the most suitable for the given requirements.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-307-migrating-on-premises-application-servers-to-aws-with-minimized-local-iscsi-storage'><span>Question #307 Migrating on-premises application servers to AWS with minimized local iSCSI storage</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company that primarily runs its application servers on premises has decided to migrate to AWS. The company wants to minimize its need to scale its Internet Small Computer Systems Interface (iSCSI) storage on premises. The company wants only its recently accessed data to remain stored locally. Which AWS solution should the company use to meet these requirements?</span></p><p><span>A. Amazon S3 File Gateway</span></p><p><span>B. AWS Storage Gateway Tape Gateway</span></p><p><span>C. AWS Storage Gateway Volume Gateway stored volumes</span></p><p><span>D. AWS Storage Gateway Volume Gateway cached volumes</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. AWS Storage Gateway Volume Gateway cached volumes</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Storage Gateway Volume Gateway (Cached Volumes)</span></strong><span>: The cached volumes configuration of AWS Storage Gateway allows you to store your primary data in Amazon S3 while retaining frequently accessed data locally in a cache. This minimizes the need for on-premises storage capacity and ensures that only recently accessed data remains stored locally.</span></p></li><li><p><strong><span>Minimized Local Storage</span></strong><span>: With cached volumes, you can maintain a smaller local storage footprint because only the most frequently accessed data is cached locally, while the bulk of the data resides in Amazon S3. This aligns with the company&#39;s requirement to minimize the need to scale its iSCSI storage on premises.</span></p></li><li><p><strong><span>iSCSI Interface</span></strong><span>: AWS Storage Gateway provides an iSCSI interface, which allows on-premises application servers to access the storage as if it were local, ensuring seamless integration with existing infrastructure.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon S3 File Gateway</span></strong><span>: S3 File Gateway is designed for file-based storage, providing a file interface to Amazon S3. It does not provide an iSCSI interface and is not suitable for block storage needs.</span></p><p><span>B. </span><strong><span>AWS Storage Gateway Tape Gateway</span></strong><span>: Tape Gateway is designed for backup and archival use cases, emulating physical tape libraries. It is not intended for primary storage or for frequently accessed data.</span></p><p><span>C. </span><strong><span>AWS Storage Gateway Volume Gateway (Stored Volumes)</span></strong><span>: Stored volumes store the entire dataset locally and asynchronously back up point-in-time snapshots to Amazon S3. This does not minimize the need for on-premises storage as the entire dataset must be stored locally.</span></p><p><span>By using AWS Storage Gateway Volume Gateway cached volumes, the company can achieve its goal of minimizing on-premises iSCSI storage while ensuring that recently accessed data is stored locally, providing a cost-effective and efficient solution for migrating to AWS.</span></p><p>&nbsp;</p><hr /><h3 id='question-308-reviewing-trusted-advisor-recommendations-to-reduce-rds-costs'><span>Question #308 Reviewing Trusted Advisor recommendations to reduce RDS costs</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has multiple AWS accounts that use consolidated billing. The company runs several active high-performance Amazon RDS for Oracle On-Demand DB instances for 90 days. The company&#39;s finance team has access to AWS Trusted Advisor in the consolidated billing account and all other AWS accounts. The finance team needs to use the appropriate AWS account to access the Trusted Advisor check recommendations for RDS. The finance team must review the appropriate Trusted Advisor check to reduce RDS costs.</span></p><p><strong><span>Which combination of steps should the finance team take to meet these requirements? (Choose two.)</span></strong></p><p><strong><span>Options:</span></strong></p><p><span>A. Use the Trusted Advisor recommendations from the account where the RDS instances are running.</span></p><p><span>B. Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time.</span></p><p><span>C. Review the Trusted Advisor check for Amazon RDS Reserved Instance Optimization.</span></p><p><span>D. Review the Trusted Advisor check for Amazon RDS Idle DB Instances.</span></p><p><span>E. Review the Trusted Advisor check for Amazon Redshift Reserved Node Optimization.</span></p><p><strong><span>Correct answers:</span></strong></p><p><span>B. Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time.</span></p><p><span>D. Review the Trusted Advisor check for Amazon RDS Idle DB Instances.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Consolidated Billing Account for Recommendations (Option B)</span></strong><span>: Using the Trusted Advisor recommendations from the consolidated billing account allows the finance team to see all RDS instance checks across all accounts at the same time. This central view makes it easier to manage and optimize costs across multiple accounts.</span></p></li><li><p><strong><span>RDS Idle DB Instances Check (Option D)</span></strong><span>: Reviewing the Trusted Advisor check for Amazon RDS Idle DB Instances helps identify any RDS instances that are not being utilized efficiently. By identifying and possibly terminating or resizing idle instances, the company can reduce unnecessary costs.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Account-Specific Recommendations</span></strong><span>: While using the Trusted Advisor recommendations from the account where the RDS instances are running can provide insights, it is less efficient than using the consolidated billing account, which provides a centralized view.</span></p><p><span>C. </span><strong><span>RDS Reserved Instance Optimization Check</span></strong><span>: While this check can provide cost-saving opportunities, it is more relevant for long-term cost optimization rather than addressing immediate cost reductions for potentially idle instances.</span></p><p><span>E. </span><strong><span>Redshift Reserved Node Optimization</span></strong><span>: This check is specific to Amazon Redshift and is not relevant to Amazon RDS for Oracle DB instances.</span></p><p><span>By using the consolidated billing account to access Trusted Advisor recommendations and focusing on the RDS Idle DB Instances check, the finance team can effectively identify cost-saving opportunities for their RDS instances.</span></p><hr /><h3 id='question-309-identifying-rarely-accessed-amazon-s3-buckets-to-optimize-storage-costs'><span>Question #309 Identifying rarely accessed Amazon S3 buckets to optimize storage costs</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect needs to optimize storage costs. The solutions architect must identify any Amazon S3 buckets that are no longer being accessed or are rarely accessed. Which solution will accomplish this goal with the LEAST operational overhead?</span></p><p><span>A. Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics.</span></p><p><span>B. Analyze bucket access patterns by using the S3 dashboard in the AWS Management Console.</span></p><p><span>C. Turn on the Amazon CloudWatch BucketSizeBytes metric for buckets. Analyze bucket access patterns by using the metrics data with Amazon Athena.</span></p><p><span>D. Turn on AWS CloudTrail for S3 object monitoring. Analyze bucket access patterns by using CloudTrail logs that are integrated with Amazon CloudWatch Logs.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>S3 Storage Lens</span></strong><span>: Amazon S3 Storage Lens provides visibility into storage usage and activity trends across your S3 buckets. It offers advanced activity metrics and insights to help you understand and optimize your storage costs. S3 Storage Lens includes metrics such as bucket size, object count, and access patterns.</span></p></li><li><p><strong><span>Operational Overhead</span></strong><span>: S3 Storage Lens is a fully managed service that automatically collects and analyzes data, providing a comprehensive dashboard with minimal operational overhead. It eliminates the need for manual data collection and analysis.</span></p></li><li><p><strong><span>Advanced Activity Metrics</span></strong><span>: The advanced activity metrics provided by S3 Storage Lens allow you to easily identify buckets that are rarely accessed or no longer being accessed, helping you make informed decisions about cost optimization.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>S3 Dashboard in the AWS Management Console</span></strong><span>: The S3 dashboard provides basic information about your buckets but does not offer detailed access pattern analysis or advanced metrics.</span></p><p><span>C. </span><strong><span>CloudWatch BucketSizeBytes Metric with Athena</span></strong><span>: This approach involves turning on the BucketSizeBytes metric and using Amazon Athena to analyze the data. While feasible, it requires setting up and managing additional services, resulting in higher operational overhead compared to S3 Storage Lens.</span></p><p><span>D. </span><strong><span>CloudTrail for S3 Object Monitoring</span></strong><span>: Enabling CloudTrail for S3 object monitoring and analyzing logs with CloudWatch Logs is a more complex and manual process. It involves managing and analyzing large volumes of log data, leading to significant operational overhead.</span></p><p><span>By using the S3 Storage Lens dashboard, the solutions architect can efficiently identify rarely accessed or inactive S3 buckets with the least operational overhead, thereby optimizing storage costs effectively.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-310-reducing-data-transfer-costs-and-improving-performance-for-dataset-delivery'><span>Question #310 Reducing data transfer costs and improving performance for dataset delivery</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company sells datasets to customers who do research in artificial intelligence and machine learning (AI/ML). The datasets are large, formatted files that are stored in an Amazon S3 bucket in the us-east-1 Region. The company hosts a web application that the customers use to purchase access to a given dataset. The web application is deployed on multiple Amazon EC2 instances behind an Application Load Balancer. After a purchase is made, customers receive an S3 signed URL that allows access to the files.</span></p><p><span>The customers are distributed across North America and Europe. The company wants to reduce the cost that is associated with data transfers and wants to maintain or improve performance.</span></p><p><strong><span>What should a solutions architect do to meet these requirements?</span></strong></p><p><span>A. Configure S3 Transfer Acceleration on the existing S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint. Continue to use S3 signed URLs for access control.</span></p><p><span>B. Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin. Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control.</span></p><p><span>C. Set up a second S3 bucket in the eu-central-1 Region with S3 Cross-Region Replication between the buckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control.</span></p><p><span>D. Modify the web application to enable streaming of the datasets to end users. Configure the web application to read the data from the existing S3 bucket. Implement access control directly in the application.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin. Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon CloudFront Distribution</span></strong><span>:</span></p><ul><li><p><strong><span>Content Delivery Network (CDN)</span></strong><span>: CloudFront is a global CDN that caches content at edge locations close to the end users, reducing latency and improving download speeds.</span></p></li><li><p><strong><span>Cost Efficiency</span></strong><span>: Using CloudFront can reduce data transfer costs because data is served from edge locations, which can be more cost-effective than serving directly from the S3 bucket.</span></p></li><li><p><strong><span>Performance Improvement</span></strong><span>: Customers in North America and Europe will experience improved performance due to reduced latency when accessing cached content from nearby edge locations.</span></p></li></ul></li><li><p><strong><span>Access Control with CloudFront Signed URLs</span></strong><span>:</span></p><ul><li><p><strong><span>Security</span></strong><span>: CloudFront signed URLs provide a secure way to grant time-limited access to the content, similar to S3 signed URLs.</span></p></li><li><p><strong><span>Seamless Integration</span></strong><span>: Switching to CloudFront signed URLs ensures that access control remains robust and secure while leveraging the benefits of CloudFront.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>S3 Transfer Acceleration (Option A)</span></strong><span>: While S3 Transfer Acceleration can improve upload and download speeds by using optimized network paths, it does not provide the same level of global caching and cost reduction as CloudFront.</span></p></li><li><p><strong><span>Cross-Region Replication (Option C)</span></strong><span>: Setting up a second S3 bucket with cross-region replication can improve performance for European users, but it increases storage costs and does not address the global caching benefits provided by CloudFront.</span></p></li><li><p><strong><span>Streaming Data (Option D)</span></strong><span>: Modifying the web application to enable streaming adds complexity and may not be necessary for delivering large files. Additionally, this approach does not address the cost and performance benefits provided by a CDN like CloudFront.</span></p></li></ul></li></ol><p><span>By deploying an Amazon CloudFront distribution with the existing S3 bucket as the origin and switching to CloudFront signed URLs for access control, the company can reduce data transfer costs, improve performance for customers in North America and Europe, and maintain secure access to the datasets.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-311-designing-a-web-application-to-process-insurance-quotes'><span>Question #311 Designing a web application to process insurance quotes</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is using AWS to design a web application that will process insurance quotes. Users will request quotes from the application. Quotes must be separated by quote type, must be responded to within 24 hours, and must not get lost. The solution must maximize operational efficiency and must minimize maintenance. Which solution meets these requirements?</span></p><p><span>A. Create multiple Amazon Kinesis data streams based on the quote type. Configure the web application to send messages to the proper data stream. Configure each backend group of application servers to use the Kinesis Client Library (KCL) to pool messages from its own data stream.</span></p><p><span>B. Create an AWS Lambda function and an Amazon Simple Notification Service (Amazon SNS) topic for each quote type. Subscribe the Lambda function to its associated SNS topic. Configure the application to publish requests for quotes to the appropriate SNS topic.</span></p><p><span>C. Create a single Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon Simple Queue Service (Amazon SQS) queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to use its own SQS queue.</span></p><p><span>D. Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon OpenSearch Service cluster. Configure the application to send messages to the proper delivery stream. Configure each backend group of application servers to search for the messages from OpenSearch Service and process them accordingly.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create a single Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon Simple Queue Service (Amazon SQS) queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to use its own SQS queue.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SNS and SQS Integration</span></strong><span>: By using a single SNS topic and subscribing SQS queues to that topic, you can leverage the power of SNS for message distribution and SQS for reliable message queuing. This ensures that messages (quotes) are not lost and can be processed reliably.</span></p></li><li><p><strong><span>Message Filtering</span></strong><span>: SNS message filtering allows messages to be routed to the appropriate SQS queue based on the quote type. This ensures that each backend application server processes only the quotes relevant to its type, maximizing operational efficiency.</span></p></li><li><p><strong><span>Decoupling and Scalability</span></strong><span>: This solution decouples the web application from the backend processing servers, allowing each component to scale independently. It also minimizes maintenance by using fully managed services (SNS and SQS).</span></p></li><li><p><strong><span>Reliability and Durability</span></strong><span>: SQS provides at-least-once delivery, ensuring that messages are not lost. Additionally, SQS queues can be configured with a visibility timeout to ensure that messages are processed within the required 24-hour window.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Kinesis Data Streams</span></strong><span>: While Kinesis is suitable for real-time data streaming, it introduces additional complexity with the Kinesis Client Library (KCL) and is not necessary for the given use case. It also does not inherently provide the same level of message durability and reliability as SQS.</span></p><p><span>B. </span><strong><span>Lambda and SNS</span></strong><span>: This approach does not provide message durability and the separation of quote types as effectively as the SNS and SQS combination. Lambda functions are event-driven and may not be ideal for processing large volumes of messages with a 24-hour response requirement.</span></p><p><span>D. </span><strong><span>Kinesis Data Firehose and OpenSearch</span></strong><span>: This solution is more complex and involves additional components (OpenSearch) that are not necessary for the use case. It also does not provide the same level of message durability and reliability as SQS.</span></p><p><span>By using SNS and SQS with message filtering, the company can ensure that quotes are reliably processed, separated by type, and responded to within the required timeframe, while minimizing operational overhead and maintenance.</span></p><p>&nbsp;</p><hr /><h3 id='question-312-backing-up-and-recovering-an-application-with-multiple-ec2-instances-and-ebs-volumes'><span>Question #312 Backing up and recovering an application with multiple EC2 instances and EBS volumes</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an application that runs on several Amazon EC2 instances. Each EC2 instance has multiple Amazon Elastic Block Store (Amazon EBS) data volumes attached to it. The application&#39;s EC2 instance configuration and data need to be backed up nightly. The application also needs to be recoverable in a different AWS Region.</span></p><p><strong><span>Which solution will meet these requirements in the MOST operationally efficient way?</span></strong></p><p><span>A. Write an AWS Lambda function that schedules nightly snapshots of the application&#39;s EBS volumes and copies the snapshots to a different Region.</span></p><p><span>B. Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application&#39;s EC2 instances as resources.</span></p><p><span>C. Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application&#39;s EBS volumes as resources.</span></p><p><span>D. Write an AWS Lambda function that schedules nightly snapshots of the application&#39;s EBS volumes and copies the snapshots to a different Availability Zone.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application&#39;s EC2 instances as resources.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Backup</span></strong><span>:</span></p><ul><li><p><strong><span>Operational Efficiency</span></strong><span>: AWS Backup is a fully managed service that centralizes and automates data protection across AWS services. It simplifies the creation, management, and monitoring of backups.</span></p></li><li><p><strong><span>Cross-Region Backup</span></strong><span>: AWS Backup supports cross-region backup, allowing you to copy backups to another AWS Region for disaster recovery purposes.</span></p></li></ul></li><li><p><strong><span>Resource Addition</span></strong><span>:</span></p><ul><li><p><strong><span>EC2 Instances as Resources</span></strong><span>: Adding the EC2 instances as resources in the backup plan ensures that both the instance configuration and attached EBS volumes are backed up. This approach is more comprehensive than backing up only the EBS volumes.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Lambda Function for Snapshots (Option A and D)</span></strong><span>: Writing a Lambda function to manage snapshots involves more operational overhead compared to using AWS Backup. Additionally, copying snapshots to a different Availability Zone (Option D) does not meet the requirement for cross-region recoverability.</span></p></li><li><p><strong><span>EBS Volumes as Resources (Option C)</span></strong><span>: While this option ensures that the EBS volumes are backed up, it does not include the EC2 instance configurations. Adding EC2 instances as resources ensures a more complete backup solution.</span></p></li></ul></li></ol><p><span>By creating a backup plan using AWS Backup to perform nightly backups, copying the backups to another Region, and adding the application&#39;s EC2 instances as resources, the company can achieve a comprehensive and operationally efficient backup and disaster recovery solution.</span></p><p>&nbsp;</p><hr /><h3 id='question-313-building-a-mobile-app-to-stream-content-to-millions-of-users'><span>Question #313 Building a mobile app to stream content to millions of users</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is building a mobile app on AWS. The company wants to expand its reach to millions of users. The company needs to build a platform so that authorized users can watch the company&#39;s content on their mobile devices. What should a solutions architect recommend to meet these requirements?</span></p><p><span>A. Publish content to a public Amazon S3 bucket. Use AWS Key Management Service (AWS KMS) keys to stream content.</span></p><p><span>B. Set up IPsec VPN between the mobile app and the AWS environment to stream content.</span></p><p><span>C. Use Amazon CloudFront. Provide signed URLs to stream content.</span></p><p><span>D. Set up AWS Client VPN between the mobile app and the AWS environment to stream content.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use Amazon CloudFront. Provide signed URLs to stream content.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon CloudFront</span></strong><span>: CloudFront is a global content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to users with low latency and high transfer speeds. It is designed to handle high traffic and can scale to millions of users.</span></p></li><li><p><strong><span>Signed URLs</span></strong><span>: By using signed URLs, the company can restrict access to the content to only authorized users. Signed URLs allow the company to control who can access the content and for how long, ensuring that only authenticated users can stream the content.</span></p></li><li><p><strong><span>Security and Performance</span></strong><span>: CloudFront integrates with AWS services like AWS Shield for DDoS protection and AWS WAF for web application firewall capabilities, providing enhanced security. It also caches content at edge locations around the world, reducing latency and improving the streaming experience for users.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Public Amazon S3 Bucket with AWS KMS</span></strong><span>: Publishing content to a public S3 bucket is not secure as it makes the content accessible to anyone with the URL. AWS KMS keys do not provide a mechanism for securely streaming content to authorized users.</span></p><p><span>B. </span><strong><span>IPsec VPN</span></strong><span>: Setting up an IPsec VPN between the mobile app and the AWS environment is not practical for streaming content to millions of users. VPNs are typically used for secure connections between networks and are not designed for high-volume content delivery.</span></p><p><span>D. </span><strong><span>AWS Client VPN</span></strong><span>: Similar to IPsec VPN, AWS Client VPN is not designed for streaming content to a large number of users. It is used for providing secure access to AWS resources for individual clients and does not scale well for content delivery.</span></p><p><span>By using Amazon CloudFront with signed URLs, the company can securely and efficiently deliver content to millions of authorized users on their mobile devices, ensuring a high-quality streaming experience while maintaining control over access to the content.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-314-migrating-an-on-premises-mysql-database-to-aws-with-minimal-downtime-and-future-scalability'><span>Question #314 Migrating an on-premises MySQL database to AWS with minimal downtime and future scalability</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an on-premises MySQL database used by the global sales team with infrequent access patterns. The sales team requires the database to have minimal downtime. A database administrator wants to migrate this database to AWS without selecting a particular instance type in anticipation of more users in the future.</span></p><p><strong><span>Which service should a solutions architect recommend?</span></strong></p><p><span>A. Amazon Aurora MySQL</span></p><p><span>B. Amazon Aurora Serverless for MySQL</span></p><p><span>C. Amazon Redshift Spectrum</span></p><p><span>D. Amazon RDS for MySQL</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Amazon Aurora Serverless for MySQL</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Aurora Serverless for MySQL</span></strong><span>:</span></p><ul><li><p><strong><span>Scalability</span></strong><span>: Aurora Serverless automatically scales the database capacity up or down based on the application&#39;s needs. This is ideal for infrequent access patterns and future growth without the need to select a specific instance type.</span></p></li><li><p><strong><span>Cost Efficiency</span></strong><span>: With Aurora Serverless, you only pay for the database capacity you use, which can be more cost-effective for databases with infrequent access patterns.</span></p></li><li><p><strong><span>Minimal Downtime</span></strong><span>: Aurora Serverless can provide minimal downtime during the migration process by allowing for automated scaling and handling of database connections seamlessly.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon Aurora MySQL (Option A)</span></strong><span>: While Aurora MySQL offers high performance and scalability, it requires selecting an instance type, which does not align with the requirement of avoiding instance selection.</span></p></li><li><p><strong><span>Amazon Redshift Spectrum (Option C)</span></strong><span>: Redshift Spectrum is designed for querying data directly from Amazon S3 using SQL and is not suitable for running a transactional MySQL database.</span></p></li><li><p><strong><span>Amazon RDS for MySQL (Option D)</span></strong><span>: RDS for MySQL requires selecting an instance type and managing instance scaling, which does not meet the requirement of avoiding instance selection and anticipating future growth.</span></p></li></ul></li></ol><p><span>By recommending Amazon Aurora Serverless for MySQL, the solutions architect provides a scalable, cost-effective, and low-maintenance solution that meets the company&#39;s requirements for minimal downtime and future scalability without the need to select a specific instance type.</span></p><p>&nbsp;</p><hr /><h3 id='question-315-implementing-vulnerability-scanning-on-amazon-ec2-instances'><span>Question #315 Implementing vulnerability scanning on Amazon EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company experienced a breach that affected several applications in its on-premises data center. The attacker took advantage of vulnerabilities in the custom applications that were running on the servers. The company is now migrating its applications to run on Amazon EC2 instances. The company wants to implement a solution that actively scans for vulnerabilities on the EC2 instances and sends a report that details the findings. Which solution will meet these requirements?</span></p><p><span>A. Deploy AWS Shield to scan the EC2 instances for vulnerabilities. Create an AWS Lambda function to log any findings to AWS CloudTrail.</span></p><p><span>B. Deploy Amazon Macie and AWS Lambda functions to scan the EC2 instances for vulnerabilities. Log any findings to AWS CloudTrail.</span></p><p><span>C. Turn on Amazon GuardDuty. Deploy the GuardDuty agents to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings.</span></p><p><span>D. Turn on Amazon Inspector. Deploy the Amazon Inspector agent to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Turn on Amazon Inspector. Deploy the Amazon Inspector agent to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Inspector</span></strong><span>: Amazon Inspector is a security assessment service that helps improve the security and compliance of applications deployed on AWS. It automatically assesses applications for vulnerabilities or deviations from best practices and generates detailed reports.</span></p></li><li><p><strong><span>Amazon Inspector Agent</span></strong><span>: Deploying the Amazon Inspector agent to the EC2 instances allows the service to perform assessments by collecting information about the operating system, installed packages, network configurations, and more.</span></p></li><li><p><strong><span>Automated Reporting</span></strong><span>: By configuring an AWS Lambda function, you can automate the generation and distribution of reports detailing the findings from Amazon Inspector. This ensures that the company receives timely and actionable information about any vulnerabilities.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Shield</span></strong><span>: AWS Shield is a managed DDoS protection service that safeguards applications running on AWS. It is not designed for vulnerability scanning of EC2 instances.</span></p><p><span>B. </span><strong><span>Amazon Macie</span></strong><span>: Amazon Macie is a data security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. It is not designed for vulnerability scanning of EC2 instances.</span></p><p><span>C. </span><strong><span>Amazon GuardDuty</span></strong><span>: GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior to protect AWS accounts and workloads. While it provides threat detection, it does not actively scan for vulnerabilities in the same way that Amazon Inspector does.</span></p><p><span>By turning on Amazon Inspector and deploying the Amazon Inspector agent to the EC2 instances, the company can actively scan for vulnerabilities and generate detailed reports, ensuring that any security issues are identified and addressed promptly.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-316-reducing-operational-costs-while-processing-messages-in-an-sqs-queue'><span>Question #316 Reducing operational costs while processing messages in an SQS queue</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company uses an Amazon EC2 instance to run a script to poll for and process messages in an Amazon Simple Queue Service (Amazon SQS) queue. The company wants to reduce operational costs while maintaining its ability to process a growing number of messages that are added to the queue.</span></p><p><strong><span>What should a solutions architect recommend to meet these requirements?</span></strong></p><p><span>A. Increase the size of the EC2 instance to process messages faster.</span></p><p><span>B. Use Amazon EventBridge to turn off the EC2 instance when the instance is underutilized.</span></p><p><span>C. Migrate the script on the EC2 instance to an AWS Lambda function with the appropriate runtime.</span></p><p><span>D. Use AWS Systems Manager Run Command to run the script on demand.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Migrate the script on the EC2 instance to an AWS Lambda function with the appropriate runtime.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Lambda</span></strong><span>:</span></p><ul><li><p><strong><span>Cost Efficiency</span></strong><span>: AWS Lambda is a serverless compute service that automatically scales to handle the number of incoming messages. You only pay for the compute time you consume, which can significantly reduce costs compared to running an EC2 instance continuously.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: Lambda can automatically scale to handle a growing number of messages in the SQS queue without the need for manual intervention or resizing of instances.</span></p></li><li><p><strong><span>Operational Overhead</span></strong><span>: By migrating the script to Lambda, the company can eliminate the need to manage and maintain an EC2 instance, further reducing operational overhead.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Increasing the Size of the EC2 Instance (Option A)</span></strong><span>: This option may improve processing speed but does not address the cost efficiency and scalability requirements. It could also lead to higher operational costs.</span></p></li><li><p><strong><span>Using Amazon EventBridge to Turn Off the EC2 Instance (Option B)</span></strong><span>: While this can help reduce costs when the instance is underutilized, it does not provide the same level of automatic scaling and cost efficiency as Lambda.</span></p></li><li><p><strong><span>Using AWS Systems Manager Run Command (Option D)</span></strong><span>: This option allows for on-demand execution of scripts but does not provide the automatic scaling and cost efficiency benefits of Lambda.</span></p></li></ul></li></ol><p><span>By migrating the script to an AWS Lambda function with the appropriate runtime, the company can achieve cost savings, automatic scaling, and reduced operational overhead, all while maintaining the ability to process a growing number of messages in the SQS queue.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-317-processing-legacy-application-data-for-a-new-cots-application'><span>Question #317 Processing legacy application data for a new COTS application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company uses a legacy application to produce data in CSV format. The legacy application stores the output data in Amazon S3. The company is deploying a new commercial off-the-shelf (COTS) application that can perform complex SQL queries to analyze data that is stored in Amazon Redshift and Amazon S3 only. However, the COTS application cannot process the .csv files that the legacy application produces. The company cannot update the legacy application to produce data in another format. The company needs to implement a solution so that the COTS application can use the data that the legacy application produces. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Create an AWS Glue extract, transform, and load (ETL) job that runs on a schedule. Configure the ETL job to process the .csv files and store the processed data in Amazon Redshift.</span></p><p><span>B. Develop a Python script that runs on Amazon EC2 instances to convert the .csv files to .sql files. Invoke the Python script on a cron schedule to store the output files in Amazon S3.</span></p><p><span>C. Create an AWS Lambda function and an Amazon DynamoDB table. Use an S3 event to invoke the Lambda function. Configure the Lambda function to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in the DynamoDB table.</span></p><p><span>D. Use Amazon EventBridge to launch an Amazon EMR cluster on a weekly schedule. Configure the EMR cluster to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in an Amazon Redshift table.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create an AWS Glue extract, transform, and load (ETL) job that runs on a schedule. Configure the ETL job to process the .csv files and store the processed data in Amazon Redshift.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Glue</span></strong><span>: AWS Glue is a fully managed extract, transform, and load (ETL) service that makes it easy to prepare and load data for analytics. It is designed to handle ETL tasks with minimal operational overhead.</span></p></li><li><p><strong><span>Scheduled ETL Jobs</span></strong><span>: AWS Glue allows you to create ETL jobs that can be scheduled to run at regular intervals, ensuring that the data is processed and loaded into Amazon Redshift as needed.</span></p></li><li><p><strong><span>Integration with Amazon Redshift</span></strong><span>: AWS Glue natively integrates with Amazon Redshift, making it straightforward to load processed data into Redshift tables for analysis by the COTS application.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Python Script on EC2 Instances</span></strong><span>: Developing and running a custom Python script on EC2 instances introduces additional operational overhead, including managing the EC2 instances, scheduling the script, and handling failures.</span></p><p><span>C. </span><strong><span>Lambda Function and DynamoDB</span></strong><span>: While using a Lambda function for ETL tasks is possible, storing the processed data in DynamoDB does not meet the requirement of loading the data into Amazon Redshift or S3 for the COTS application.</span></p><p><span>D. </span><strong><span>Amazon EMR Cluster</span></strong><span>: Using Amazon EMR for ETL tasks is more complex and involves managing a cluster, which adds operational overhead. EMR is more suitable for large-scale data processing rather than simple ETL tasks that can be handled by AWS Glue.</span></p><p><span>By using AWS Glue to create a scheduled ETL job, the company can efficiently process the .csv files produced by the legacy application and load the processed data into Amazon Redshift, meeting the requirements with the least operational overhead.</span></p><p>&nbsp;</p><hr /><h3 id='question-318-tracking-and-auditing-inventory-and-configuration-changes-in-aws'><span>Question #318 Tracking and auditing inventory and configuration changes in AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company recently migrated its entire IT environment to the AWS Cloud. The company discovers that users are provisioning oversized Amazon EC2 instances and modifying security group rules without using the appropriate change control process. A solutions architect must devise a strategy to track and audit these inventory and configuration changes.</span></p><p><strong><span>Which actions should the solutions architect take to meet these requirements? (Choose two.)</span></strong></p><p><span>A. Enable AWS CloudTrail and use it for auditing.</span></p><p><span>B. Use data lifecycle policies for the Amazon EC2 instances.</span></p><p><span>C. Enable AWS Trusted Advisor and reference the security dashboard.</span></p><p><span>D. Enable AWS Config and create rules for auditing and compliance purposes.</span></p><p><span>E. Restore previous resource configurations with an AWS CloudFormation template.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Enable AWS CloudTrail and use it for auditing.</span></p><p><span>D. Enable AWS Config and create rules for auditing and compliance purposes.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS CloudTrail</span></strong><span>:</span></p><ul><li><p><strong><span>Auditing</span></strong><span>: AWS CloudTrail enables governance, compliance, and operational and risk auditing of your AWS account. It records all API calls made in your account, including actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services.</span></p></li><li><p><strong><span>Tracking Changes</span></strong><span>: By enabling CloudTrail, the company can track changes to EC2 instances and security group rules, providing a detailed audit trail of who did what and when.</span></p></li></ul></li><li><p><strong><span>AWS Config</span></strong><span>:</span></p><ul><li><p><strong><span>Configuration Management</span></strong><span>: AWS Config provides a detailed view of the configuration of AWS resources in your account. It continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations.</span></p></li><li><p><strong><span>Compliance</span></strong><span>: By creating AWS Config rules, the company can enforce compliance policies and ensure that any changes to resources, such as oversized EC2 instances or modified security group rules, are tracked and audited.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Data Lifecycle Policies (Option B)</span></strong><span>: Data lifecycle policies are used for managing the lifecycle of data stored in AWS services like S3 and do not address tracking and auditing configuration changes.</span></p></li><li><p><strong><span>AWS Trusted Advisor (Option C)</span></strong><span>: Trusted Advisor provides recommendations for optimizing AWS resources, including security and cost optimization, but it is not specifically designed for tracking and auditing changes.</span></p></li><li><p><strong><span>AWS CloudFormation Templates (Option E)</span></strong><span>: Restoring previous configurations with CloudFormation templates can help revert changes, but it does not provide continuous tracking and auditing capabilities.</span></p></li></ul></li></ol><p><span>By enabling AWS CloudTrail and AWS Config, the solutions architect can effectively track and audit inventory and configuration changes, ensuring that any modifications to EC2 instances and security group rules are properly monitored and compliant with the company&#39;s change control process.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-319-secure-access-to-ec2-instances-without-shared-ssh-keys'><span>Question #319 Secure access to EC2 instances without shared SSH keys</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has hundreds of Amazon EC2 Linux-based instances in the AWS Cloud. Systems administrators have used shared SSH keys to manage the instances. After a recent audit, the company&#39;s security team is mandating the removal of all shared keys. A solutions architect must design a solution that provides secure access to the EC2 instances. Which solution will meet this requirement with the LEAST amount of administrative overhead?</span></p><p><span>A. Use AWS Systems Manager Session Manager to connect to the EC2 instances.</span></p><p><span>B. Use AWS Security Token Service (AWS STS) to generate one-time SSH keys on demand.</span></p><p><span>C. Allow shared SSH access to a set of bastion instances. Configure all other instances to allow only SSH access from the bastion instances.</span></p><p><span>D. Use an Amazon Cognito custom authorizer to authenticate users. Invoke an AWS Lambda function to generate a temporary SSH key.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use AWS Systems Manager Session Manager to connect to the EC2 instances.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Systems Manager Session Manager</span></strong><span>: Session Manager is a fully managed service that provides secure and auditable instance management without the need for SSH keys. It allows administrators to connect to EC2 instances using the AWS Management Console, AWS CLI, or AWS SDKs.</span></p></li><li><p><strong><span>No SSH Keys Required</span></strong><span>: With Session Manager, there is no need to manage SSH keys, reducing the administrative overhead and improving security by eliminating the risk associated with shared keys.</span></p></li><li><p><strong><span>Secure and Auditable</span></strong><span>: Session Manager provides secure access to instances and logs all session activity in AWS CloudTrail, ensuring compliance with security and audit requirements.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>AWS Security Token Service (AWS STS)</span></strong><span>: Generating one-time SSH keys on demand using AWS STS adds complexity and administrative overhead. It requires custom implementation and does not eliminate the need to manage SSH keys.</span></p><p><span>C. </span><strong><span>Bastion Instances</span></strong><span>: Using bastion instances for SSH access still involves managing SSH keys and does not fully eliminate the risk associated with shared keys. It also adds complexity to the network architecture.</span></p><p><span>D. </span><strong><span>Amazon Cognito and Lambda</span></strong><span>: Using Amazon Cognito with a custom authorizer and Lambda function to generate temporary SSH keys introduces significant complexity and administrative overhead. It requires custom development and management of multiple services.</span></p><p><span>By using AWS Systems Manager Session Manager, the company can provide secure access to EC2 instances without the need for shared SSH keys, meeting the security requirements with the least amount of administrative overhead.</span></p><p>&nbsp;</p><hr /><h3 id='question-320-scalable-near-real-time-data-querying-with-minimal-data-loss'><span>Question #320 Scalable, near-real-time data querying with minimal data loss</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is using a fleet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-flight is lost. The company&#39;s data science team wants to query ingested data in near-real time.</span></p><p><strong><span>Which solution provides near-real-time data querying that is scalable with minimal data loss?</span></strong></p><p><span>A. Publish data to Amazon Kinesis Data Streams. Use Kinesis Data Analytics to query the data.</span></p><p><span>B. Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.</span></p><p><span>C. Store ingested data in an EC2 instance store. Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data.</span></p><p><span>D. Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Publish data to Amazon Kinesis Data Streams. Use Kinesis Data Analytics to query the data.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Kinesis Data Streams</span></strong><span>:</span></p><ul><li><p><strong><span>Scalability</span></strong><span>: Kinesis Data Streams is designed to handle high-throughput data streams, making it suitable for the ingestion rate of 1 MB/s.</span></p></li><li><p><strong><span>Durability</span></strong><span>: Kinesis Data Streams ensures that data is durably stored across multiple availability zones, minimizing data loss even if an EC2 instance is rebooted.</span></p></li><li><p><strong><span>Real-Time Processing</span></strong><span>: Data can be processed in real-time as it is ingested into the stream.</span></p></li></ul></li><li><p><strong><span>Kinesis Data Analytics</span></strong><span>:</span></p><ul><li><p><strong><span>Real-Time Querying</span></strong><span>: Kinesis Data Analytics allows for real-time querying and processing of data streams using standard SQL. This meets the requirement for near-real-time data querying.</span></p></li><li><p><strong><span>Integration</span></strong><span>: It seamlessly integrates with Kinesis Data Streams, allowing for efficient querying of ingested data.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Kinesis Data Firehose with Redshift (Option B)</span></strong><span>: While this option allows for querying data in Redshift, it introduces latency due to the batch loading process, which may not meet the near-real-time requirement.</span></p></li><li><p><strong><span>EC2 Instance Store and Kinesis Data Firehose with S3 and Athena (Option C)</span></strong><span>: Storing data in an EC2 instance store is not durable and data can be lost if the instance is rebooted. Athena querying introduces latency as it queries data stored in S3.</span></p></li><li><p><strong><span>EBS Volume and ElastiCache for Redis (Option D)</span></strong><span>: Storing data in an EBS volume does not provide the same real-time querying capabilities. ElastiCache for Redis is more suited for caching and not for durable storage and querying of streaming data.</span></p></li></ul></li></ol><p><span>By using Amazon Kinesis Data Streams for data ingestion and Kinesis Data Analytics for real-time querying, the company can achieve a scalable solution with minimal data loss and near-real-time data querying capabilities.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-321-ensuring-encryption-for-all-objects-uploaded-to-an-amazon-s3-bucket'><span>Question #321 Ensuring encryption for all objects uploaded to an Amazon S3 bucket</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>What should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?</span></p><p><span>A. Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set.</span></p><p><span>B. Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set to private.</span></p><p><span>C. Update the bucket policy to deny if the PutObject does not have an aws:SecureTransport header set to true.</span></p><p><span>D. Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><p><span>To ensure that all objects uploaded to an Amazon S3 bucket are encrypted, you need to enforce server-side encryption by updating the bucket policy to deny any </span><code>PutObject</code><span> request that does not include the </span><code>x-amz-server-side-encryption</code><span> header. This header specifies the server-side encryption algorithm to use when Amazon S3 creates an object.</span></p><p><span>Here is a sample bucket policy that enforces this requirement:</span></p><pre class="md-fences md-end-block ty-contain-cm modeLoaded" spellcheck="false" lang="json" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="json"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 32.5px; left: 26.5px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">{</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-string cm-property">"Version"</span>: <span class="cm-string">"2012-10-17"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-string cm-property">"Statement"</span>: [</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  {</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Sid"</span>: <span class="cm-string">"DenyUnencryptedObjectUploads"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Effect"</span>: <span class="cm-string">"Deny"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Principal"</span>: <span class="cm-string">"*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Action"</span>: <span class="cm-string">"s3:PutObject"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Resource"</span>: <span class="cm-string">"arn:aws:s3:::your-bucket-name/*"</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"Condition"</span>: {</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"StringNotEquals"</span>: {</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-string cm-property">"s3:x-amz-server-side-encryption"</span>: <span class="cm-string">"AES256"</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp;  }</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;  }</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;  }</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">  ]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">}</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 453px;"></div><div class="CodeMirror-gutters" style="display: none; height: 453px;"></div></div></div></pre><p><span>This policy ensures that any </span><code>PutObject</code><span> request without the </span><code>x-amz-server-side-encryption</code><span> header set to </span><code>AES256</code><span> will be denied. You can also use </span><code>&quot;aws:kms&quot;</code><span> if you are using AWS Key Management Service (KMS) for server-side encryption.</span></p><p><span>Other options:</span></p><p><span>A. </span><strong><span>s3:x-amz-acl header</span></strong><span>: The </span><code>s3:x-amz-acl</code><span> header is used for setting access control lists (ACLs) on objects, not for enforcing encryption.</span></p><p><span>B. </span><strong><span>s3:x-amz-acl header set to private</span></strong><span>: Similarly, setting the ACL to private does not ensure that the object is encrypted.</span></p><p><span>C. </span><strong><span>aws:SecureTransport header</span></strong><span>: The </span><code>aws:SecureTransport</code><span> header ensures that the request is made over HTTPS, which secures data in transit but does not enforce encryption of the objects stored in the bucket.</span></p><p><span>By updating the bucket policy to deny any </span><code>PutObject</code><span> request that does not include the </span><code>x-amz-server-side-encryption</code><span> header, the solutions architect ensures that all objects uploaded to the S3 bucket are encrypted.</span></p><p>&nbsp;</p><hr /><h3 id='question-322-designing-a-multi-tier-application-for-asynchronous-image-processing'><span>Question #322 Designing a multi-tier application for asynchronous image processing</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect is designing a multi-tier application for a company. The application&#39;s users upload images from a mobile device. The application generates a thumbnail of each image and returns a message to the user to confirm that the image was uploaded successfully. </span></p><p><span>The thumbnail generation can take up to 60 seconds, but the company wants to provide a faster response time to its users to notify them that the original image was received. The solutions architect must design the application to asynchronously dispatch requests to the different application tiers.</span></p><p><strong><span>What should the solutions architect do to meet these requirements?</span></strong></p><p><span>A. Write a custom AWS Lambda function to generate the thumbnail and alert the user. Use the image upload process as an event source to invoke the Lambda function.</span></p><p><span>B. Create an AWS Step Functions workflow. Configure Step Functions to handle the orchestration between the application tiers and alert the user when thumbnail generation is complete.</span></p><p><span>C. Create an Amazon Simple Queue Service (Amazon SQS) message queue. As images are uploaded, place a message on the SQS queue for thumbnail generation. Alert the user through an application message that the image was received.</span></p><p><span>D. Create Amazon Simple Notification Service (Amazon SNS) notification topics and subscriptions. Use one subscription with the application to generate the thumbnail after the image upload is complete. Use a second subscription to message the user&#39;s mobile app by way of a push notification after thumbnail generation is complete.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create an Amazon Simple Queue Service (Amazon SQS) message queue. As images are uploaded, place a message on the SQS queue for thumbnail generation. Alert the user through an application message that the image was received.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Simple Queue Service (Amazon SQS)</span></strong><span>:</span></p><ul><li><p><strong><span>Asynchronous Processing</span></strong><span>: SQS is designed to handle asynchronous message processing. By placing a message in the SQS queue, the image upload process can quickly notify the user that the image was received without waiting for the thumbnail generation to complete.</span></p></li><li><p><strong><span>Decoupling</span></strong><span>: Using SQS decouples the image upload and thumbnail generation processes, allowing the application to scale independently and handle varying loads efficiently.</span></p></li></ul></li><li><p><strong><span>User Notification</span></strong><span>:</span></p><ul><li><p><strong><span>Immediate Feedback</span></strong><span>: The application can immediately alert the user that the image was received, providing a faster response time.</span></p></li><li><p><strong><span>Queue Processing</span></strong><span>: The thumbnail generation process can asynchronously poll the SQS queue, generate the thumbnail, and store the result without impacting the user experience.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Lambda (Option A)</span></strong><span>: While Lambda can be used for thumbnail generation, using it directly as an event source for image upload does not provide the necessary decoupling for asynchronous processing.</span></p></li><li><p><strong><span>AWS Step Functions (Option B)</span></strong><span>: Step Functions can handle orchestration but may add unnecessary complexity for this use case. The primary requirement is to decouple the upload and processing, which SQS handles efficiently.</span></p></li><li><p><strong><span>Amazon SNS (Option D)</span></strong><span>: SNS is suitable for notifications but not for queue-based processing. Using SNS for thumbnail generation and user notification adds complexity without providing the decoupling benefits of SQS.</span></p></li></ul></li></ol><p><span>By using Amazon SQS to queue thumbnail generation requests and immediately notifying the user that the image was received, the solutions architect can meet the requirements for faster response times and scalable, asynchronous processing.</span></p><p>&nbsp;</p><hr /><h3 id='question-323-designing-a-system-to-process-badge-reader-messages'><span>Question #323 Designing a system to process badge reader messages</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company&#39;s facility has badge readers at every entrance throughout the building. When badges are scanned, the readers send a message over HTTPS to indicate who attempted to access that particular entrance. A solutions architect must design a system to process these messages from the sensors. The solution must be highly available, and the results must be made available for the company&#39;s security team to analyze. Which system architecture should the solutions architect recommend?</span></p><p><span>A. Launch an Amazon EC2 instance to serve as the HTTPS endpoint and to process the messages. Configure the EC2 instance to save the results to an Amazon S3 bucket.</span></p><p><span>B. Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.</span></p><p><span>C. Use Amazon Route 53 to direct incoming sensor messages to an AWS Lambda function. Configure the Lambda function to process the messages and save the results to an Amazon DynamoDB table.</span></p><p><span>D. Create a gateway VPC endpoint for Amazon S3. Configure a Site-to-Site VPN connection from the facility network to the VPC so that sensor data can be written directly to an S3 bucket by way of the VPC endpoint.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon API Gateway</span></strong><span>: API Gateway can easily create and manage an HTTPS endpoint to receive messages from the badge readers. It provides a highly available and scalable solution for handling incoming HTTPS requests.</span></p></li><li><p><strong><span>AWS Lambda</span></strong><span>: Using a Lambda function to process the messages ensures that the solution is serverless, reducing operational overhead. Lambda automatically scales to handle the volume of incoming requests and processes each message.</span></p></li><li><p><strong><span>Amazon DynamoDB</span></strong><span>: Storing the results in DynamoDB provides a highly available and durable storage solution that can be easily queried by the security team for analysis. DynamoDB is designed to handle high request rates and offers low latency performance.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon EC2 Instance</span></strong><span>: Using an EC2 instance introduces additional operational overhead for managing the instance and ensuring high availability. This solution is not as scalable or cost-effective as a serverless approach.</span></p><p><span>C. </span><strong><span>Amazon Route 53</span></strong><span>: Route 53 is a DNS service and is not designed to handle HTTPS requests directly. It cannot be used to directly invoke a Lambda function based on incoming HTTPS messages.</span></p><p><span>D. </span><strong><span>Gateway VPC Endpoint and Site-to-Site VPN</span></strong><span>: This approach is overly complex and not suitable for handling HTTPS messages from badge readers. It involves setting up and maintaining a VPN connection and does not provide a straightforward way to process and store the messages.</span></p><p><span>By using Amazon API Gateway to create the HTTPS endpoint and invoking an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table, the solutions architect can design a highly available, scalable, and low-maintenance system that meets the company&#39;s requirements.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-324-implementing-a-disaster-recovery-plan-for-on-premises-file-storage'><span>Question #324 Implementing a disaster recovery plan for on-premises file storage</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to implement a disaster recovery plan for its primary on-premises file storage volume. The file storage volume is mounted from an Internet Small Computer Systems Interface (iSCSI) device on a local storage server. The file storage volume holds hundreds of terabytes (TB) of data.</span></p><p><span>The company wants to ensure that end users retain immediate access to all file types from the on-premises systems without experiencing latency.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST amount of change to the company&#39;s existing infrastructure?</span></strong></p><p><span>A. Provision an Amazon S3 File Gateway as a virtual machine (VM) that is hosted on premises. Set the local cache to 10 TB. Modify existing applications to access the files through the NFS protocol. To recover from a disaster, provision an Amazon EC2 instance and mount the S3 bucket that contains the files.</span></p><p><span>B. Provision an AWS Storage Gateway tape gateway. Use a data backup solution to back up all existing data to a virtual tape library. Configure the data backup solution to run nightly after the initial backup is complete. To recover from a disaster, provision an Amazon EC2 instance and restore the data to an Amazon Elastic Block Store (Amazon EBS) volume from the volumes in the virtual tape library.</span></p><p><span>C. Provision an AWS Storage Gateway Volume Gateway cached volume. Set the local cache to 10 TB. Mount the Volume Gateway cached volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.</span></p><p><span>D. Provision an AWS Storage Gateway Volume Gateway stored volume with the same amount of disk space as the existing file storage volume. Mount the Volume Gateway stored volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Provision an AWS Storage Gateway Volume Gateway stored volume with the same amount of disk space as the existing file storage volume. Mount the Volume Gateway stored volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Storage Gateway Volume Gateway (Stored Volume)</span></strong><span>:</span></p><ul><li><p><strong><span>Least Change to Infrastructure</span></strong><span>: The Volume Gateway stored volume allows the company to continue using its existing iSCSI interface, minimizing changes to the current setup.</span></p></li><li><p><strong><span>Immediate Access</span></strong><span>: The stored volume configuration keeps the entire dataset on-premises, ensuring that users have immediate access to all file types without experiencing latency.</span></p></li><li><p><strong><span>Disaster Recovery</span></strong><span>: Scheduled snapshots provide a reliable backup mechanism. In the event of a disaster, these snapshots can be restored to Amazon EBS volumes and attached to EC2 instances for quick recovery.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon S3 File Gateway (Option A)</span></strong><span>: This option requires modifying existing applications to use the NFS protocol, which introduces changes to the current infrastructure and may not meet the latency requirements.</span></p></li><li><p><strong><span>AWS Storage Gateway Tape Gateway (Option B)</span></strong><span>: Tape Gateway is designed for backup and archival rather than immediate access to data, making it unsuitable for this use case.</span></p></li><li><p><strong><span>AWS Storage Gateway Volume Gateway Cached Volume (Option C)</span></strong><span>: While this option reduces on-premises storage requirements, it relies on frequently accessed data being cached locally. This may not ensure immediate access to all file types without latency.</span></p></li></ul></li></ol><p><span>By provisioning an AWS Storage Gateway Volume Gateway stored volume and configuring scheduled snapshots, the company can meet its disaster recovery requirements while ensuring immediate access to all file types and minimizing changes to its existing infrastructure.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-325-resolving-access-issues-for-protected-content-in-amazon-s3'><span>Question #325 Resolving access issues for protected content in Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is hosting a web application from an Amazon S3 bucket. The application uses Amazon Cognito as an identity provider to authenticate users and return a JSON Web Token (JWT) that provides access to protected resources that are stored in another S3 bucket. Upon deployment of the application, users report errors and are unable to access the protected content. A solutions architect must resolve this issue by providing proper permissions so that users can access the protected content. Which solution meets these requirements?</span></p><p><span>A. Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content.</span></p><p><span>B. Update the S3 ACL to allow the application to access the protected content.</span></p><p><span>C. Redeploy the application to Amazon S3 to prevent eventually consistent reads in the S3 bucket from affecting the ability of users to access the protected content.</span></p><p><span>D. Update the Amazon Cognito pool to use custom attribute mappings within the identity pool and grant users the proper permissions to access the protected content.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Cognito Identity Pool</span></strong><span>: Amazon Cognito identity pools enable you to create unique identities for your users and authenticate them with identity providers. Identity pools can be configured to assume IAM roles that grant users the necessary permissions to access AWS resources.</span></p></li><li><p><strong><span>IAM Role Permissions</span></strong><span>: To allow authenticated users to access protected content in another S3 bucket, the IAM role assumed by the Cognito identity pool must have the appropriate permissions. This typically involves granting </span><code>s3:GetObject</code><span> permission for the protected S3 bucket.</span></p></li><li><p><strong><span>JWT and Access Control</span></strong><span>: When users authenticate via Cognito, they receive a JWT that includes the necessary credentials to assume the IAM role and access the protected resources. Ensuring that the IAM role has the correct permissions will resolve the access issues.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Update the S3 ACL</span></strong><span>: While updating the S3 ACL can grant access to objects, it is not the recommended approach for fine-grained access control based on user authentication. IAM roles and policies provide a more secure and manageable way to control access.</span></p><p><span>C. </span><strong><span>Redeploy the Application</span></strong><span>: Redeploying the application to address eventual consistency issues in S3 is not relevant to the problem of users not having the correct permissions to access protected content.</span></p><p><span>D. </span><strong><span>Custom Attribute Mappings</span></strong><span>: While custom attribute mappings in Cognito can be used to include additional user attributes, the core issue is ensuring that the IAM role assumed by the Cognito identity pool has the correct permissions to access the protected content.</span></p><p><span>By updating the Amazon Cognito identity pool to assume the proper IAM role with the necessary permissions, the solutions architect can ensure that authenticated users have access to the protected content stored in the S3 bucket.</span></p><p>&nbsp;</p><hr /><h3 id='question-326-optimizing-s3-storage-costs-while-maintaining-high-availability-and-resiliency'><span>Question #326 Optimizing S3 storage costs while maintaining high availability and resiliency</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An image hosting company uploads its large assets to Amazon S3 Standard buckets. The company uses multipart upload in parallel by using S3 APIs and overwrites if the same object is uploaded again. For the first 30 days after upload, the objects will be accessed frequently. The objects will be used less frequently after 30 days, but the access patterns for each object will be inconsistent. The company must optimize its S3 storage costs while maintaining high availability and resiliency of stored assets.</span></p><p><strong><span>Which combination of actions should a solutions architect recommend to meet these requirements? (Choose two.)</span></strong></p><p><span>A. Move assets to S3 Intelligent-Tiering after 30 days.</span></p><p><span>B. Configure an S3 Lifecycle policy to clean up incomplete multipart uploads.</span></p><p><span>C. Configure an S3 Lifecycle policy to clean up expired object delete markers.</span></p><p><span>D. Move assets to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.</span></p><p><span>E. Move assets to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Move assets to S3 Intelligent-Tiering after 30 days.</span></p><p><span>B. Configure an S3 Lifecycle policy to clean up incomplete multipart uploads.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>S3 Intelligent-Tiering</span></strong><span>:</span></p><ul><li><p><strong><span>Cost Optimization</span></strong><span>: S3 Intelligent-Tiering is designed to optimize storage costs by automatically moving data between two access tiers (frequent and infrequent) when access patterns change. This is ideal for objects with unpredictable access patterns after 30 days.</span></p></li><li><p><strong><span>High Availability and Resiliency</span></strong><span>: S3 Intelligent-Tiering provides the same high availability and resiliency as S3 Standard.</span></p></li></ul></li><li><p><strong><span>Incomplete Multipart Uploads</span></strong><span>:</span></p><ul><li><p><strong><span>Cost Management</span></strong><span>: Configuring an S3 Lifecycle policy to clean up incomplete multipart uploads helps manage storage costs by removing parts of objects that were not successfully uploaded. This prevents unnecessary storage usage and potential costs.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>S3 Standard-Infrequent Access (S3 Standard-IA) (Option D)</span></strong><span>: While S3 Standard-IA provides cost savings for infrequently accessed data, it may not be as cost-effective as S3 Intelligent-Tiering for objects with unpredictable access patterns.</span></p></li><li><p><strong><span>S3 One Zone-Infrequent Access (S3 One Zone-IA) (Option E)</span></strong><span>: S3 One Zone-IA stores data in a single availability zone, which does not meet the high availability and resiliency requirements.</span></p></li><li><p><strong><span>Expired Object Delete Markers (Option C)</span></strong><span>: Cleaning up expired object delete markers is useful for managing versioned objects but does not directly address the optimization of storage costs for frequently accessed objects.</span></p></li></ul></li></ol><p><span>By moving assets to S3 Intelligent-Tiering after 30 days and configuring an S3 Lifecycle policy to clean up incomplete multipart uploads, the company can optimize its S3 storage costs while maintaining high availability and resiliency for its stored assets.</span></p><p>&nbsp;</p><hr /><h3 id='question-327-securing-a-vpc-network-with-access-to-approved-third-party-software-repositories'><span>Question #327 Securing a VPC network with access to approved third-party software repositories</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect must secure a VPC network that hosts Amazon EC2 instances. The EC2 instances contain highly sensitive data and run in a private subnet. According to company policy, the EC2 instances that run in the VPC can access only approved third-party software repositories on the internet for software product updates that use the third party&#39;s URL. Other internet traffic must be blocked. Which solution meets these requirements?</span></p><p><span>A. Update the route table for the private subnet to route the outbound traffic to an AWS Network Firewall firewall. Configure domain list rule groups.</span></p><p><span>B. Set up an AWS WAF web ACL. Create a custom set of rules that filter traffic requests based on source and destination IP address range sets.</span></p><p><span>C. Implement strict inbound security group rules. Configure an outbound rule that allows traffic only to the authorized software repositories on the internet by specifying the URLs.</span></p><p><span>D. Configure an Application Load Balancer (ALB) in front of the EC2 instances. Direct all outbound traffic to the ALB. Use a URL-based rule listener in the ALB&#39;s target group for outbound access to the internet.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Update the route table for the private subnet to route the outbound traffic to an AWS Network Firewall firewall. Configure domain list rule groups.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Network Firewall</span></strong><span>: AWS Network Firewall is a managed service that provides network traffic filtering and protection for your VPC. It allows you to define rules to control both inbound and outbound traffic based on domain names, IP addresses, and other criteria.</span></p></li><li><p><strong><span>Domain List Rule Groups</span></strong><span>: By configuring domain list rule groups in AWS Network Firewall, you can specify the approved third-party software repositories&#39; URLs. This ensures that only traffic to these URLs is allowed, and all other internet traffic is blocked.</span></p></li><li><p><strong><span>Private Subnet Route Table Update</span></strong><span>: Updating the route table for the private subnet to route outbound traffic through the AWS Network Firewall ensures that all outgoing traffic from the EC2 instances is inspected and filtered according to the defined rules.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>AWS WAF Web ACL</span></strong><span>: AWS WAF is designed primarily for web application protection and operates at the application layer. It is not suitable for controlling outbound traffic from EC2 instances based on URLs.</span></p><p><span>C. </span><strong><span>Security Group Rules</span></strong><span>: Security groups do not support URL-based rules. They can only filter traffic based on IP addresses and port numbers, making them unsuitable for this requirement.</span></p><p><span>D. </span><strong><span>Application Load Balancer (ALB)</span></strong><span>: An ALB is typically used for distributing incoming traffic to targets and does not provide a mechanism for URL-based outbound traffic filtering.</span></p><p><span>By using AWS Network Firewall with domain list rule groups and updating the route table for the private subnet, the solutions architect can ensure that the EC2 instances can access only the approved third-party software repositories while blocking all other internet traffic. This approach meets the security requirements with the necessary granularity and control.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-328-ensuring-successful-processing-of-sales-requests-during-traffic-spikes'><span>Question #328 Ensuring successful processing of sales requests during traffic spikes</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is hosting a three-tier ecommerce application in the AWS Cloud. The company hosts the website on Amazon S3 and integrates the website with an API that handles sales requests. The company hosts the API on three Amazon EC2 instances behind an Application Load Balancer (ALB). The API consists of static and dynamic front-end content along with backend workers that process sales requests asynchronously.</span></p><p><span>The company is expecting a significant and sudden increase in the number of sales requests during events for the launch of new products.</span></p><p><strong><span>What should a solutions architect recommend to ensure that all the requests are processed successfully?</span></strong></p><p><span>A. Add an Amazon CloudFront distribution for the dynamic content. Increase the number of EC2 instances to handle the increase in traffic.</span></p><p><span>B. Add an Amazon CloudFront distribution for the static content. Place the EC2 instances in an Auto Scaling group to launch new instances based on network traffic.</span></p><p><span>C. Add an Amazon CloudFront distribution for the dynamic content. Add an Amazon ElastiCache instance in front of the ALB to reduce traffic for the API to handle.</span></p><p><span>D. Add an Amazon CloudFront distribution for the static content. Add an Amazon Simple Queue Service (Amazon SQS) queue to receive requests from the website for later processing by the EC2 instances.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Add an Amazon CloudFront distribution for the static content. Add an Amazon Simple Queue Service (Amazon SQS) queue to receive requests from the website for later processing by the EC2 instances.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon CloudFront for Static Content</span></strong><span>:</span></p><ul><li><p><strong><span>Performance Improvement</span></strong><span>: CloudFront can cache and distribute static content globally, reducing latency and improving the performance of the website during high traffic events.</span></p></li><li><p><strong><span>Offloading Traffic</span></strong><span>: By caching static content, CloudFront reduces the load on the origin server (S3), ensuring that more resources are available for handling dynamic content and API requests.</span></p></li></ul></li><li><p><strong><span>Amazon Simple Queue Service (Amazon SQS)</span></strong><span>:</span></p><ul><li><p><strong><span>Asynchronous Processing</span></strong><span>: SQS allows you to decouple and distribute the processing of sales requests. By queuing the requests, you can ensure that they are processed asynchronously by the backend workers, preventing overload on the EC2 instances.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: SQS can handle a virtually unlimited number of messages, ensuring that all sales requests are queued and processed, even during traffic spikes.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Increasing EC2 Instances (Option A)</span></strong><span>: Simply increasing the number of EC2 instances might not be sufficient to handle sudden spikes in traffic and does not address the need for asynchronous processing.</span></p></li><li><p><strong><span>Auto Scaling Group (Option B)</span></strong><span>: While Auto Scaling can help manage the number of EC2 instances, it does not provide the same level of decoupling and asynchronous processing as SQS.</span></p></li><li><p><strong><span>ElastiCache (Option C)</span></strong><span>: Adding ElastiCache can help reduce database load by caching frequently accessed data, but it does not address the need for handling asynchronous sales request processing.</span></p></li></ul></li></ol><p><span>By adding an Amazon CloudFront distribution for the static content and an Amazon SQS queue to receive requests from the website for later processing by the EC2 instances, the company can ensure that all requests are processed successfully. This approach improves performance, scalability, and reliability during significant traffic spikes.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-329-ensuring-regular-security-scans-and-patching-for-amazon-ec2-instances'><span>Question #329 Ensuring regular security scans and patching for Amazon EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A security audit reveals that Amazon EC2 instances are not being patched regularly. A solutions architect needs to provide a solution that will run regular security scans across a large fleet of EC2 instances. The solution should also patch the EC2 instances on a regular schedule and provide a report of each instance&#39;s patch status. Which solution will meet these requirements?</span></p><p><span>A. Set up Amazon Macie to scan the EC2 instances for software vulnerabilities. Set up a cron job on each EC2 instance to patch the instance on a regular schedule.</span></p><p><span>B. Turn on Amazon GuardDuty in the account. Configure GuardDuty to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Session Manager to patch the EC2 instances on a regular schedule.</span></p><p><span>C. Set up Amazon Detective to scan the EC2 instances for software vulnerabilities. Set up an Amazon EventBridge scheduled rule to patch the EC2 instances on a regular schedule.</span></p><p><span>D. Turn on Amazon Inspector in the account. Configure Amazon Inspector to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Patch Manager to patch the EC2 instances on a regular schedule.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Turn on Amazon Inspector in the account. Configure Amazon Inspector to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Patch Manager to patch the EC2 instances on a regular schedule.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Inspector</span></strong><span>: Amazon Inspector is a security assessment service that helps improve the security and compliance of applications deployed on AWS. It automatically assesses applications for vulnerabilities or deviations from best practices and generates detailed reports.</span></p></li><li><p><strong><span>AWS Systems Manager Patch Manager</span></strong><span>: Patch Manager automates the process of patching managed instances with both security-related and other types of updates. It allows you to define patch baselines, set patching schedules, and generate reports on the patch status of your instances.</span></p></li><li><p><strong><span>Integration and Automation</span></strong><span>: By turning on Amazon Inspector to scan for vulnerabilities and using AWS Systems Manager Patch Manager to automate the patching process, you can ensure that your EC2 instances are regularly scanned and patched. This solution also provides detailed reporting on the patch status of each instance.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon Macie and Cron Job</span></strong><span>: Amazon Macie is designed for data security and privacy, not for scanning EC2 instances for software vulnerabilities. Using cron jobs on each instance adds complexity and does not provide centralized management or reporting.</span></p><p><span>B. </span><strong><span>Amazon GuardDuty and Session Manager</span></strong><span>: GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior. It does not perform software vulnerability scanning. Session Manager is used for secure and auditable instance management, not for patch management.</span></p><p><span>C. </span><strong><span>Amazon Detective and EventBridge</span></strong><span>: Amazon Detective is used for investigating and analyzing potential security issues and threats. It does not perform software vulnerability scanning. EventBridge can schedule tasks but does not provide the patch management capabilities of AWS Systems Manager Patch Manager.</span></p><p><span>By using Amazon Inspector for vulnerability scanning and AWS Systems Manager Patch Manager for automated patching, the solutions architect can ensure that the EC2 instances are regularly scanned and patched, meeting the security requirements with comprehensive reporting.</span></p><p>&nbsp;</p><hr /><h3 id='question-330-encrypting-data-at-rest-on-amazon-rds-db-instances'><span>Question #330 Encrypting data at rest on Amazon RDS DB instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is planning to store data on Amazon RDS DB instances. The company must encrypt the data at rest.</span></p><p><strong><span>What should a solutions architect do to meet this requirement?</span></strong></p><p><span>A. Create a key in AWS Key Management Service (AWS KMS). Enable encryption for the DB instances.</span></p><p><span>B. Create an encryption key. Store the key in AWS Secrets Manager. Use the key to encrypt the DB instances.</span></p><p><span>C. Generate a certificate in AWS Certificate Manager (ACM). Enable SSL/TLS on the DB instances by using the certificate.</span></p><p><span>D. Generate a certificate in AWS Identity and Access Management (IAM). Enable SSL/TLS on the DB instances by using the certificate.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create a key in AWS Key Management Service (AWS KMS). Enable encryption for the DB instances.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Key Management Service (AWS KMS)</span></strong><span>:</span></p><ul><li><p><strong><span>Encryption at Rest</span></strong><span>: AWS KMS allows you to create and manage cryptographic keys. When you enable encryption for an RDS DB instance, AWS automatically uses KMS to encrypt the data at rest.</span></p></li><li><p><strong><span>Integration with RDS</span></strong><span>: AWS RDS integrates with AWS KMS to provide seamless encryption of data at rest. When you create an encrypted RDS instance, AWS manages the encryption and decryption of data transparently.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Secrets Manager (Option B)</span></strong><span>: Secrets Manager is designed for storing and managing sensitive information such as database credentials, but it is not used for encrypting data at rest.</span></p></li><li><p><strong><span>AWS Certificate Manager (ACM) (Option C)</span></strong><span>: ACM is used for managing SSL/TLS certificates for securing data in transit, not for encrypting data at rest.</span></p></li><li><p><strong><span>IAM Certificates (Option D)</span></strong><span>: IAM can manage SSL/TLS certificates for securing data in transit, but it is not used for encrypting data at rest.</span></p></li></ul></li></ol><p><span>By creating a key in AWS KMS and enabling encryption for the RDS DB instances, the company can ensure that the data is encrypted at rest, meeting the security requirements.</span></p><p>&nbsp;</p><hr /><h3 id='question-331-migrating-20-tb-of-data-to-aws-within-30-days-with-limited-network-bandwidth'><span>Question #331 Migrating 20 TB of data to AWS within 30 days with limited network bandwidth</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company&#39;s network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Use AWS Snowball.</span></p><p><span>B. Use AWS DataSync.</span></p><p><span>C. Use a secure VPN connection.</span></p><p><span>D. Use Amazon S3 Transfer Acceleration.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use AWS Snowball.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Snowball</span></strong><span>: AWS Snowball is a petabyte-scale data transport solution that uses secure appliances to transfer large amounts of data into and out of AWS. It is designed for situations where network bandwidth is limited or where transferring large amounts of data over the internet is impractical.</span></p></li><li><p><strong><span>Network Bandwidth Limitation</span></strong><span>: Given the company&#39;s network bandwidth limitation of 15 Mbps and the requirement to not exceed 70% utilization, transferring 20 TB of data over the network within 30 days would not be feasible. AWS Snowball provides a physical device that can be shipped to the data center, loaded with data, and then shipped back to AWS for data transfer.</span></p></li><li><p><strong><span>Time Constraints</span></strong><span>: Using AWS Snowball ensures that the data transfer can be completed within the required 30-day timeframe without relying on the limited network bandwidth.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>AWS DataSync</span></strong><span>: AWS DataSync is a service for automating data transfer between on-premises storage and AWS. However, it relies on the available network bandwidth. Given the constraints, it would not be feasible to transfer 20 TB of data within 30 days using DataSync.</span></p><p><span>C. </span><strong><span>Secure VPN Connection</span></strong><span>: A secure VPN connection would also rely on the available network bandwidth. With the bandwidth limitation and the requirement not to exceed 70% utilization, it would not be possible to transfer 20 TB of data within the required timeframe.</span></p><p><span>D. </span><strong><span>Amazon S3 Transfer Acceleration</span></strong><span>: S3 Transfer Acceleration speeds up data transfer to S3 by using AWS edge locations. However, it still relies on the available network bandwidth. Given the constraints, it would not be feasible to transfer 20 TB of data within 30 days using this method.</span></p><p><span>By using AWS Snowball, the company can efficiently and securely transfer 20 TB of data to AWS within the required 30-day timeframe without being constrained by the limited network bandwidth.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-332-providing-secure-access-to-confidential-files-with-increased-remote-usage'><span>Question #332 Providing secure access to confidential files with increased remote usage</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees&#39; devices.</span></p><p><span>The files are stored in an on-premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity.</span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees&#39; IP addresses.</span></p><p><span>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on-premises Active Directory. Configure AWS Client VPN.</span></p><p><span>C. Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.</span></p><p><span>D. Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS IAM Identity Center (AWS Single Sign-On).</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on-premises Active Directory. Configure AWS Client VPN.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon FSx for Windows File Server</span></strong><span>:</span></p><ul><li><p><strong><span>Compatibility</span></strong><span>: Amazon FSx for Windows File Server is fully compatible with Windows file systems, making it a seamless solution for migrating from an on-premises Windows file server.</span></p></li><li><p><strong><span>Integration with Active Directory</span></strong><span>: Integrating FSx with the on-premises Active Directory ensures that only authorized users can access the files, maintaining security and access control.</span></p></li></ul></li><li><p><strong><span>AWS Client VPN</span></strong><span>:</span></p><ul><li><p><strong><span>Secure Access</span></strong><span>: AWS Client VPN allows employees to securely connect to AWS resources from remote locations. By configuring a VPN, employees can securely download files from the FSx file system.</span></p></li><li><p><strong><span>Access Control</span></strong><span>: The VPN ensures that only authenticated and authorized users can access the files, providing an additional layer of security.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>EC2 Instance in Public Subnet (Option A)</span></strong><span>: Running a file server on an EC2 instance in a public subnet poses security risks and does not provide the same level of integration and scalability as FSx.</span></p></li><li><p><strong><span>Amazon S3 with Private VPC Endpoint (Option C)</span></strong><span>: While S3 with a private VPC endpoint and signed URLs can provide secure access, it does not offer the same seamless integration with Active Directory and file system features as FSx.</span></p></li><li><p><strong><span>Amazon S3 with Public VPC Endpoint (Option D)</span></strong><span>: Using a public VPC endpoint and IAM Identity Center (Single Sign-On) may expose the files to the public internet, which is not suitable for confidential and sensitive files.</span></p></li></ul></li></ol><p><span>By migrating the files to Amazon FSx for Windows File Server and integrating it with the on-premises Active Directory, along with configuring AWS Client VPN, the company can ensure secure access for authorized users, maintain compatibility with existing systems, and provide a scalable solution for increased remote usage.</span></p><p>&nbsp;</p><hr /><h3 id='question-333-handling-peak-cpu-utilization-during-monthly-batch-runs'><span>Question #333 Handling peak CPU utilization during monthly batch runs</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company&#39;s application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month-end financial calculation batch runs. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application. What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?</span></p><p><span>A. Configure an Amazon CloudFront distribution in front of the ALB.</span></p><p><span>B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.</span></p><p><span>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</span></p><p><span>D. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Scheduled Scaling Policy</span></strong><span>: Scheduled scaling allows you to scale your Amazon EC2 Auto Scaling group based on a specified schedule. Since the high CPU utilization occurs predictably at midnight on the first day of every month, a scheduled scaling policy is the most appropriate solution.</span></p></li><li><p><strong><span>Proactive Scaling</span></strong><span>: By configuring a scheduled scaling policy, you can ensure that additional EC2 instances are launched ahead of the anticipated peak load. This proactive approach helps handle the increased workload without causing disruptions or downtime.</span></p></li><li><p><strong><span>Avoiding Downtime</span></strong><span>: Scheduled scaling ensures that the application can handle the increased workload during the month-end financial calculation batch runs, preventing the CPU utilization from peaking to 100% and disrupting the application.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon CloudFront</span></strong><span>: CloudFront is a content delivery network (CDN) that helps improve the performance of delivering static and dynamic web content. It does not address the issue of high CPU utilization on EC2 instances caused by batch processing.</span></p><p><span>B. </span><strong><span>Simple Scaling Policy</span></strong><span>: A simple scaling policy based on CPU utilization reacts to changes in CPU usage. However, in this case, the CPU utilization spikes immediately, and a reactive approach may not scale up the instances quickly enough to prevent disruption.</span></p><p><span>D. </span><strong><span>Amazon ElastiCache</span></strong><span>: ElastiCache can help offload some of the workload from EC2 instances by caching frequently accessed data. However, it does not directly address the issue of high CPU utilization caused by the batch processing workload.</span></p><p><span>By configuring an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule, the solutions architect can ensure that the application has the necessary resources to handle the increased workload during the month-end financial calculation batch runs, avoiding downtime and maintaining performance.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-334-using-on-premises-microsoft-active-directory-for-sftp-access-to-amazon-s3'><span>Question #334 Using on-premises Microsoft Active Directory for SFTP access to Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to give a customer the ability to use on-premises Microsoft Active Directory to download files that are stored in Amazon S3. The customer&#39;s application uses an SFTP client to download the files.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST operational overhead and no changes to the customer&#39;s application?</span></strong></p><p><span>A. Set up AWS Transfer Family with SFTP for Amazon S3. Configure integrated Active Directory authentication.</span></p><p><span>B. Set up AWS Database Migration Service (AWS DMS) to synchronize the on-premises client with Amazon S3. Configure integrated Active Directory authentication.</span></p><p><span>C. Set up AWS DataSync to synchronize between the on-premises location and the S3 location by using AWS IAM Identity Center (AWS Single Sign-On).</span></p><p><span>D. Set up a Windows Amazon EC2 instance with SFTP to connect the on-premises client with Amazon S3. Integrate AWS Identity and Access Management (IAM).</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Set up AWS Transfer Family with SFTP for Amazon S3. Configure integrated Active Directory authentication.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Transfer Family with SFTP for Amazon S3</span></strong><span>:</span></p><ul><li><p><strong><span>SFTP Support</span></strong><span>: AWS Transfer Family supports SFTP, which allows the customer&#39;s application to continue using the SFTP client without any changes.</span></p></li><li><p><strong><span>Integration with Active Directory</span></strong><span>: AWS Transfer Family can be configured to authenticate users against an on-premises Microsoft Active Directory, meeting the requirement for integrated AD authentication.</span></p></li><li><p><strong><span>Operational Overhead</span></strong><span>: This solution requires minimal operational overhead as AWS Transfer Family is a fully managed service, eliminating the need to manage and maintain an SFTP server.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Database Migration Service (AWS DMS) (Option B)</span></strong><span>: AWS DMS is designed for database migration and synchronization, not for SFTP access to files stored in Amazon S3.</span></p></li><li><p><strong><span>AWS DataSync (Option C)</span></strong><span>: AWS DataSync is used for data transfer between on-premises storage and AWS, but it does not provide SFTP access and does not integrate directly with Active Directory for authentication.</span></p></li><li><p><strong><span>Windows Amazon EC2 Instance with SFTP (Option D)</span></strong><span>: Setting up an EC2 instance with SFTP requires managing the instance, maintaining the SFTP server, and integrating with IAM, which increases operational overhead compared to using a fully managed service like AWS Transfer Family.</span></p></li></ul></li></ol><p><span>By setting up AWS Transfer Family with SFTP for Amazon S3 and configuring integrated Active Directory authentication, the company can provide secure SFTP access to files stored in Amazon S3 with minimal operational overhead and no changes to the customer&#39;s application.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-335-minimizing-initialization-latency-for-ec2-instances-in-an-auto-scaling-group'><span>Question #335 Minimizing initialization latency for EC2 instances in an Auto Scaling group</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is experiencing sudden increases in demand. The company needs to provision large Amazon EC2 instances from an Amazon Machine Image (AMI). The instances will run in an Auto Scaling group. The company needs a solution that provides minimum initialization latency to meet the demand. Which solution meets these requirements?</span></p><p><span>A. Use the aws ec2 register-image command to create an AMI from a snapshot. Use AWS Step Functions to replace the AMI in the Auto Scaling group.</span></p><p><span>B. Enable Amazon Elastic Block Store (Amazon EBS) fast snapshot restore on a snapshot. Provision an AMI by using the snapshot. Replace the AMI in the Auto Scaling group with the new AMI.</span></p><p><span>C. Enable AMI creation and define lifecycle rules in Amazon Data Lifecycle Manager (Amazon DLM). Create an AWS Lambda function that modifies the AMI in the Auto Scaling group.</span></p><p><span>D. Use Amazon EventBridge to invoke AWS Backup lifecycle policies that provision AMIs. Configure Auto Scaling group capacity limits as an event source in EventBridge.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Enable Amazon Elastic Block Store (Amazon EBS) fast snapshot restore on a snapshot. Provision an AMI by using the snapshot. Replace the AMI in the Auto Scaling group with the new AMI.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon EBS Fast Snapshot Restore</span></strong><span>: Enabling fast snapshot restore on an Amazon EBS snapshot significantly reduces the time it takes to create EBS volumes from snapshots. This feature ensures that volumes restored from snapshots are fully initialized and immediately available, which minimizes the initialization latency for EC2 instances.</span></p></li><li><p><strong><span>Provisioning an AMI</span></strong><span>: By provisioning an AMI using a snapshot with fast snapshot restore enabled, the instances launched from this AMI will have minimal initialization latency. This ensures that the instances can be quickly provisioned to meet sudden increases in demand.</span></p></li><li><p><strong><span>Replacing the AMI in the Auto Scaling Group</span></strong><span>: Once the AMI is created from the fast snapshot restore-enabled snapshot, it can be replaced in the Auto Scaling group to ensure that all new instances launched by the Auto Scaling group benefit from the reduced initialization latency.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>aws ec2 register-image Command and AWS Step Functions</span></strong><span>: Using the </span><code>aws ec2 register-image</code><span> command to create an AMI from a snapshot and using AWS Step Functions to replace the AMI in the Auto Scaling group does not specifically address the initialization latency issue.</span></p><p><span>C. </span><strong><span>Amazon Data Lifecycle Manager (DLM) and AWS Lambda</span></strong><span>: While DLM can automate the creation of AMIs and manage their lifecycle, it does not directly address the need for minimizing initialization latency. Additionally, using a Lambda function to modify the AMI in the Auto Scaling group adds complexity.</span></p><p><span>D. </span><strong><span>Amazon EventBridge and AWS Backup Lifecycle Policies</span></strong><span>: Using EventBridge to invoke AWS Backup lifecycle policies to provision AMIs and configuring Auto Scaling group capacity limits as an event source is not directly related to minimizing initialization latency. This approach is more complex and does not specifically address the requirement.</span></p><p><span>By enabling Amazon EBS fast snapshot restore on a snapshot and provisioning an AMI using that snapshot, the company can ensure that EC2 instances launched from the AMI have minimal initialization latency, meeting the demand with the least delay.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-336-managing-encrypted-and-rotated-database-credentials-for-an-aurora-mysql-db-cluster'><span>Question #336 Managing encrypted and rotated database credentials for an Aurora MySQL DB cluster</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a multi-tier web application that uses an Amazon Aurora MySQL DB cluster for storage. The application tier is hosted on Amazon EC2 instances. The company&#39;s IT security guidelines mandate that the database credentials be encrypted and rotated every 14 days.</span></p><p><strong><span>What should a solutions architect do to meet this requirement with the LEAST operational effort?</span></strong></p><p><span>A. Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.</span></p><p><span>B. Create two parameters in AWS Systems Manager Parameter Store: one for the user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days.</span></p><p><span>C. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all EC2 instances of the application tier. Restrict the access to the file on the file system so that the application can read the file and that only super users can modify the file. Implement an AWS Lambda function that rotates the key in Aurora every 14 days and writes new credentials into the file.</span></p><p><span>D. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon S3 bucket that the application uses to load the credentials. Download the file to the application regularly to ensure that the correct credentials are used. Implement an AWS Lambda function that rotates the Aurora credentials every 14 days and uploads these credentials to the file in the S3 bucket.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Secrets Manager</span></strong><span>:</span></p><ul><li><p><strong><span>Automated Rotation</span></strong><span>: AWS Secrets Manager natively supports automatic rotation of database credentials, which can be configured to rotate every 14 days. This reduces operational effort as it handles the rotation process automatically.</span></p></li><li><p><strong><span>Encryption</span></strong><span>: Secrets Manager integrates with AWS KMS to encrypt the credentials, ensuring they are stored securely.</span></p></li><li><p><strong><span>Integration with Aurora</span></strong><span>: Secrets Manager can be directly associated with the Aurora DB cluster, allowing seamless retrieval of credentials by the application.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Systems Manager Parameter Store (Option B)</span></strong><span>: While Parameter Store can store encrypted parameters, it requires a custom Lambda function for rotation, adding operational complexity.</span></p></li><li><p><strong><span>Amazon EFS (Option C)</span></strong><span>: Storing credentials in an EFS file system and managing access adds unnecessary complexity and operational overhead compared to using Secrets Manager.</span></p></li><li><p><strong><span>Amazon S3 (Option D)</span></strong><span>: Storing credentials in an S3 bucket and managing rotation with a Lambda function introduces additional steps and complexity, making it less efficient than using Secrets Manager.</span></p></li></ul></li></ol><p><span>By using AWS Secrets Manager with a KMS key and configuring a custom rotation period of 14 days, the company can meet its security requirements with the least operational effort, ensuring that database credentials are securely encrypted and automatically rotated.</span></p><hr /><h3 id='question-337-reducing-replication-lag-for-mysql-read-replicas'><span>Question #337 Reducing replication lag for MySQL read replicas</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has deployed a web application on AWS. The company hosts the backend database on Amazon RDS for MySQL with a primary DB instance and five read replicas to support scaling needs. The read replicas must lag no more than 1 second behind the primary DB instance. The database routinely runs scheduled stored procedures. As traffic on the website increases, the replicas experience additional lag during periods of peak load. A solutions architect must reduce the replication lag as much as possible. The solutions architect must minimize changes to the application code and must minimize ongoing operational overhead. Which solution will meet these requirements?</span></p><p><span>A. Migrate the database to Amazon Aurora MySQL. Replace the read replicas with Aurora Replicas, and configure Aurora Auto Scaling. Replace the stored procedures with Aurora MySQL native functions.</span></p><p><span>B. Deploy an Amazon ElastiCache for Redis cluster in front of the database. Modify the application to check the cache before the application queries the database. Replace the stored procedures with AWS Lambda functions.</span></p><p><span>C. Migrate the database to a MySQL database that runs on Amazon EC2 instances. Choose large, compute optimized EC2 instances for all replica nodes. Maintain the stored procedures on the EC2 instances.</span></p><p><span>D. Migrate the database to Amazon DynamoDB. Provision a large number of read capacity units (RCUs) to support the required throughput, and configure on-demand capacity scaling. Replace the stored procedures with DynamoDB streams.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Migrate the database to Amazon Aurora MySQL. Replace the read replicas with Aurora Replicas, and configure Aurora Auto Scaling. Replace the stored procedures with Aurora MySQL native functions.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Aurora MySQL</span></strong><span>: Amazon Aurora is a MySQL-compatible, managed database that provides enhanced performance and availability. Aurora is designed to be highly scalable and can handle high throughput with minimal replication lag.</span></p></li><li><p><strong><span>Aurora Replicas</span></strong><span>: Aurora Replicas share the same underlying storage as the primary instance, which allows for very low-latency replication. This helps to ensure that the replicas lag no more than 1 second behind the primary DB instance.</span></p></li><li><p><strong><span>Aurora Auto Scaling</span></strong><span>: Aurora Auto Scaling automatically adjusts the number of Aurora Replicas based on the application’s needs. This helps to manage the load during peak traffic periods without manual intervention, minimizing ongoing operational overhead.</span></p></li><li><p><strong><span>Minimizing Changes to Application Code</span></strong><span>: Migrating to Aurora MySQL requires minimal changes to the application code since Aurora is MySQL-compatible. The stored procedures can be replaced with Aurora MySQL native functions, which are similar in functionality.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>ElastiCache for Redis</span></strong><span>: While deploying ElastiCache for Redis can improve read performance by caching frequently accessed data, it does not address the replication lag issue directly. Additionally, modifying the application to check the cache before querying the database requires significant changes to the application code.</span></p><p><span>C. </span><strong><span>MySQL on EC2 Instances</span></strong><span>: Running MySQL on EC2 instances requires managing the database infrastructure, which increases operational overhead. This option does not inherently reduce replication lag and involves significant changes to the database management process.</span></p><p><span>D. </span><strong><span>Amazon DynamoDB</span></strong><span>: Migrating to DynamoDB requires significant changes to the application code and database schema. DynamoDB is a NoSQL database and does not support MySQL features such as stored procedures directly. This option involves a complete re-architecture of the database solution.</span></p><p><span>By migrating to Amazon Aurora MySQL and using Aurora Replicas with Aurora Auto Scaling, the solutions architect can reduce replication lag, minimize changes to the application code, and reduce ongoing operational overhead, meeting the company&#39;s requirements effectively.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-338-creating-a-disaster-recovery-dr-plan-for-an-aurora-mysql-db-cluster'><span>Question #338 Creating a disaster recovery (DR) plan for an Aurora MySQL DB cluster</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect must create a disaster recovery (DR) plan for a high-volume software as a service (SaaS) platform. All data for the platform is stored in an Amazon Aurora MySQL DB cluster.</span></p><p><span>The DR plan must replicate data to a secondary AWS Region.</span></p><p><strong><span>Which solution will meet these requirements MOST cost-effectively?</span></strong></p><p><strong><span>Options:</span></strong></p><p><span>A. Use MySQL binary log replication to an Aurora cluster in the secondary Region. Provision one DB instance for the Aurora cluster in the secondary Region.</span></p><p><span>B. Set up an Aurora global database for the DB cluster. When setup is complete, remove the DB instance from the secondary Region.</span></p><p><span>C. Use AWS Database Migration Service (AWS DMS) to continuously replicate data to an Aurora cluster in the secondary Region. Remove the DB instance from the secondary Region.</span></p><p><span>D. Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>B. Set up an Aurora global database for the DB cluster. When setup is complete, remove the DB instance from the secondary Region.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Aurora Global Database (Option B)</span></strong><span>: Setting up an Aurora global database for the DB cluster ensures that data is replicated to a secondary AWS Region. After the setup is complete, removing the DB instance from the secondary Region can be a cost-effective solution. Aurora global databases allow for replication without maintaining a continuously running DB instance in the secondary Region. This configuration ensures that data is replicated and available for recovery while minimizing costs by not running an active DB instance in the secondary Region until it is needed.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>MySQL Binary Log Replication</span></strong><span>: While MySQL binary log replication can replicate data to a secondary Region, it requires manual setup and ongoing management. It is not as seamless or integrated as using Aurora&#39;s global database capabilities and may not be the most cost-effective solution.</span></p><p><span>C. </span><strong><span>AWS Database Migration Service (AWS DMS)</span></strong><span>: Using AWS DMS for continuous replication involves additional complexity and potential costs. Removing the DB instance from the secondary Region would similarly reduce costs but does not leverage Aurora&#39;s global database feature, which is specifically designed for cross-region replication.</span></p><p><span>D. </span><strong><span>Aurora Global Database with Minimum One DB Instance</span></strong><span>: While this setup ensures immediate failover capability, it incurs higher costs by maintaining a running DB instance in the secondary Region at all times. This may not be the most cost-effective solution if the primary goal is to minimize costs while still having a DR plan in place.</span></p><p><span>By setting up an Aurora global database and removing the DB instance from the secondary Region after setup, the solutions architect can ensure data replication for disaster recovery while keeping costs to a minimum. This approach leverages Aurora&#39;s built-in capabilities for cross-region replication without the ongoing expense of maintaining an active DB instance in the secondary Region.</span></p><hr /><p>&nbsp;</p><h3 id='question-339-enhancing-security-of-an-application-with-embedded-credentials'><span>Question #339 Enhancing security of an application with embedded credentials</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Use AWS Key Management Service (AWS KMS) to create keys. Configure the application to load the database credentials from AWS KMS. Enable automatic key rotation.</span></p><p><span>B. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secrets Manager.</span></p><p><span>C. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.</span></p><p><span>D. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Secrets Manager</span></strong><span>: AWS Secrets Manager is a service designed to manage and retrieve secrets, such as database credentials. It provides built-in functionality for secret rotation, which can be easily integrated with Amazon RDS.</span></p></li><li><p><strong><span>Minimal Programming Effort</span></strong><span>: By storing the database credentials in AWS Secrets Manager and configuring the application to load the credentials from Secrets Manager, the application can securely retrieve the credentials without significant changes to the codebase.</span></p></li><li><p><strong><span>Automatic Rotation</span></strong><span>: AWS Secrets Manager supports automatic rotation of secrets with minimal configuration. Setting up a credentials rotation schedule ensures that the database credentials are regularly rotated without manual intervention, enhancing security.</span></p></li><li><p><strong><span>Integration with RDS</span></strong><span>: AWS Secrets Manager integrates seamlessly with Amazon RDS, allowing for easy setup of credentials rotation schedules for the application user in the RDS for MySQL database.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS KMS</span></strong><span>: AWS Key Management Service (KMS) is primarily used for managing encryption keys, not for storing and rotating database credentials. Using KMS would require more programming effort to implement a secure credentials management system.</span></p><p><span>B. </span><strong><span>Lambda Function for Rotation</span></strong><span>: While using a Lambda function for rotating credentials in Secrets Manager is possible, it adds unnecessary complexity compared to the built-in rotation functionality provided by Secrets Manager.</span></p><p><span>D. </span><strong><span>AWS Systems Manager Parameter Store</span></strong><span>: Parameter Store can store and retrieve parameters, including database credentials, but it does not provide built-in support for automatic credentials rotation like Secrets Manager. Implementing rotation would require additional custom logic.</span></p><p><span>By using AWS Secrets Manager to store and automatically rotate the database credentials, the solutions architect can enhance the security of the application with minimal programming effort, meeting the company&#39;s requirements effectively.</span></p><p>&nbsp;</p><hr /><h3 id='question-340-protecting-a-website-from-sql-injection-attacks'><span>Question #340 Protecting a website from SQL injection attacks</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A media company hosts its website on AWS. The website application&#39;s architecture includes a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB) and a database that is hosted on Amazon Aurora. The company&#39;s cybersecurity team reports that the application is vulnerable to SQL injection.</span></p><p><strong><span>How should the company resolve this issue?</span></strong></p><p><span>A. Use AWS WAF in front of the ALB. Associate the appropriate web ACLs with AWS WAF.</span></p><p><span>B. Create an ALB listener rule to reply to SQL injections with a fixed response.</span></p><p><span>C. Subscribe to AWS Shield Advanced to block all SQL injection attempts automatically.</span></p><p><span>D. Set up Amazon Inspector to block all SQL injection attempts automatically.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use AWS WAF in front of the ALB. Associate the appropriate web ACLs with AWS WAF.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS WAF (Web Application Firewall)</span></strong><span>:</span></p><ul><li><p><strong><span>Protection Against SQL Injection</span></strong><span>: AWS WAF can be configured to protect web applications from common web exploits, including SQL injection attacks. By creating and associating Web ACLs (Access Control Lists) with AWS WAF, you can define rules that specifically block SQL injection attempts.</span></p></li><li><p><strong><span>Integration with ALB</span></strong><span>: AWS WAF can be placed in front of the ALB to inspect incoming traffic and block malicious requests before they reach the EC2 instances and the database.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>ALB Listener Rule (Option B)</span></strong><span>: Creating an ALB listener rule to reply to SQL injections with a fixed response is not a practical solution, as it does not prevent the attack but merely responds to it. It also lacks the granularity and flexibility provided by AWS WAF.</span></p></li><li><p><strong><span>AWS Shield Advanced (Option C)</span></strong><span>: AWS Shield Advanced is designed to protect against DDoS attacks, not specifically SQL injection attacks. It does not provide the necessary protection against SQL injection.</span></p></li><li><p><strong><span>Amazon Inspector (Option D)</span></strong><span>: Amazon Inspector is a security assessment service that helps identify vulnerabilities in AWS resources, but it does not block SQL injection attempts. It is more suited for identifying and reporting security issues rather than actively blocking them.</span></p></li></ul></li></ol><p><span>By using AWS WAF in front of the ALB and associating the appropriate web ACLs, the company can effectively protect its website from SQL injection attacks, ensuring that malicious requests are blocked before they reach the application and database.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-341-creating-visualizations-in-amazon-quicksight-with-column-level-authorization'><span>Question #341 Creating visualizations in Amazon QuickSight with column-level authorization</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an Amazon S3 data lake that is governed by AWS Lake Formation. The company wants to create a visualization in Amazon QuickSight by joining the data in the data lake with operational data that is stored in an Amazon Aurora MySQL database. The company wants to enforce column-level authorization so that the company&#39;s marketing team can access only a subset of columns in the database.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST operational overhead?</span></strong></p><p><span>A. Use Amazon EMR to ingest the data directly from the database to the QuickSight SPICE engine. Include only the required columns.</span></p><p><span>B. Use AWS Glue Studio to ingest the data from the database to the S3 data lake. Attach an IAM policy to the QuickSight users to enforce column-level access control. Use Amazon S3 as the data source in QuickSight.</span></p><p><span>C. Use AWS Glue Elastic Views to create a materialized view for the database in Amazon S3. Create an S3 bucket policy to enforce column-level access control for the QuickSight users. Use Amazon S3 as the data source in QuickSight.</span></p><p><span>D. Use a Lake Formation blueprint to ingest the data from the database to the S3 data lake. Use Lake Formation to enforce column-level access control for the QuickSight users. Use Amazon Athena as the data source in QuickSight.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use a Lake Formation blueprint to ingest the data from the database to the S3 data lake. Use Lake Formation to enforce column-level access control for the QuickSight users. Use Amazon Athena as the data source in QuickSight.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Lake Formation Blueprints</span></strong><span>:</span></p><ul><li><p><strong><span>Data Ingestion</span></strong><span>: Lake Formation blueprints can be used to ingest data from various sources, including databases, into the S3 data lake. This ensures that the data is managed and governed within the Lake Formation framework.</span></p></li><li><p><strong><span>Column-Level Authorization</span></strong><span>: Lake Formation provides fine-grained access control, including column-level permissions. This allows the company to enforce access control policies that restrict the marketing team to only the required columns.</span></p></li></ul></li><li><p><strong><span>Amazon Athena</span></strong><span>:</span></p><ul><li><p><strong><span>Querying Data</span></strong><span>: Amazon Athena can query data stored in the S3 data lake. Using Athena as the data source in QuickSight allows for seamless integration and querying of the data.</span></p></li><li><p><strong><span>Integration with Lake Formation</span></strong><span>: Athena integrates with Lake Formation to enforce the defined access control policies, ensuring that column-level authorization is maintained.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon EMR (Option A)</span></strong><span>: Using EMR to ingest data directly to the QuickSight SPICE engine does not leverage Lake Formation&#39;s governance and access control capabilities, and it involves more operational overhead.</span></p></li><li><p><strong><span>AWS Glue Studio (Option B)</span></strong><span>: While Glue Studio can ingest data and IAM policies can enforce access control, it does not provide the same level of integration and column-level authorization as Lake Formation.</span></p></li><li><p><strong><span>AWS Glue Elastic Views (Option C)</span></strong><span>: Creating materialized views and enforcing access control with S3 bucket policies involves more operational complexity and does not utilize Lake Formation&#39;s built-in governance features.</span></p></li></ul></li></ol><p><span>By using a Lake Formation blueprint to ingest the data from the database to the S3 data lake and leveraging Lake Formation to enforce column-level access control, the company can meet its requirements with the least operational overhead. Using Amazon Athena as the data source in QuickSight ensures seamless integration and querying of the governed data.</span></p><p>&nbsp;</p><hr /><h3 id='question-342-automating-capacity-provisioning-for-ec2-instances-running-batch-jobs'><span>Question #342 Automating capacity provisioning for EC2 instances running batch jobs</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A transaction processing company has weekly scripted batch jobs that run on Amazon EC2 instances. The EC2 instances are in an Auto Scaling group. The number of transactions can vary, but the baseline CPU utilization that is noted on each run is at least 60%. The company needs to provision the capacity 30 minutes before the jobs run. Currently, engineers complete this task by manually modifying the Auto Scaling group parameters. The company does not have the resources to analyze the required capacity trends for the Auto Scaling group counts. The company needs an automated way to modify the Auto Scaling group&#39;s desired capacity. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Create a dynamic scaling policy for the Auto Scaling group. Configure the policy to scale based on the CPU utilization metric. Set the target value for the metric to 60%.</span></p><p><span>B. Create a scheduled scaling policy for the Auto Scaling group. Set the appropriate desired capacity, minimum capacity, and maximum capacity. Set the recurrence to weekly. Set the start time to 30 minutes before the batch jobs run.</span></p><p><span>C. Create a predictive scaling policy for the Auto Scaling group. Configure the policy to scale based on forecast. Set the scaling metric to CPU utilization. Set the target value for the metric to 60%. In the policy, set the instances to pre-launch 30 minutes before the jobs run.</span></p><p><span>D. Create an Amazon EventBridge event to invoke an AWS Lambda function when the CPU utilization metric value for the Auto Scaling group reaches 60%. Configure the Lambda function to increase the Auto Scaling group&#39;s desired capacity and maximum capacity by 20%.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>C. Create a predictive scaling policy for the Auto Scaling group. Configure the policy to scale based on forecast. Set the scaling metric to CPU utilization. Set the target value for the metric to 60%. In the policy, set the instances to pre-launch 30 minutes before the jobs run.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Predictive Scaling Policy (Option C)</span></strong><span>: Predictive scaling in AWS Auto Scaling uses machine learning to predict future traffic and automatically provision the necessary capacity ahead of time. By configuring the policy to scale based on forecasted CPU utilization and setting the target value to 60%, the Auto Scaling group can pre-launch instances 30 minutes before the batch jobs run. This ensures that the required capacity is available when needed without manual intervention, meeting the requirement with minimal operational overhead.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Dynamic Scaling Policy</span></strong><span>: While a dynamic scaling policy based on CPU utilization can adjust capacity automatically, it does so in reaction to current metrics rather than predicting future needs. This might not provision capacity in advance of the batch jobs, potentially leading to performance issues at the start of the batch jobs.</span></p><p><span>B. </span><strong><span>Scheduled Scaling Policy</span></strong><span>: Scheduled scaling can provision capacity in advance, but it requires manual configuration and adjustments if the job timings or load patterns change. It does not dynamically adjust based on actual usage trends, which can lead to inefficiencies.</span></p><p><span>D. </span><strong><span>EventBridge and Lambda</span></strong><span>: Using EventBridge to trigger a Lambda function based on CPU utilization adds complexity and operational overhead. It involves setting up additional components and does not inherently provision capacity in advance of the batch jobs, leading to potential delays.</span></p><p><span>By implementing a predictive scaling policy, the company can ensure that the necessary capacity is provisioned 30 minutes before the batch jobs run, leveraging machine learning to forecast and automate scaling with minimal operational overhead.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-343-designing-a-disaster-recovery-dr-architecture-for-a-mysql-database'><span>Question #343 Designing a disaster recovery (DR) architecture for a MySQL database</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect is designing a company&#39;s disaster recovery (DR) architecture. The company has a MySQL database that runs on an Amazon EC2 instance in a private subnet with scheduled backup. The DR design needs to include multiple AWS Regions. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Migrate the MySQL database to multiple EC2 instances. Configure a standby EC2 instance in the DR Region. Turn on replication.</span></p><p><span>B. Migrate the MySQL database to Amazon RDS. Use a Multi-AZ deployment. Turn on read replication for the primary DB instance in the different Availability Zones.</span></p><p><span>C. Migrate the MySQL database to an Amazon Aurora global database. Host the primary DB cluster in the primary Region. Host the secondary DB cluster in the DR Region.</span></p><p><span>D. Store the scheduled backup of the MySQL database in an Amazon S3 bucket that is configured for S3 Cross-Region Replication (CRR). Use the data backup to restore the database in the DR Region.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Migrate the MySQL database to an Amazon Aurora global database. Host the primary DB cluster in the primary Region. Host the secondary DB cluster in the DR Region.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Aurora Global Database</span></strong><span>: Amazon Aurora global databases are designed for applications with a global footprint. They allow a single Aurora database to span multiple AWS Regions, providing fast local reads and disaster recovery from outages in a single Region. This setup significantly reduces operational overhead as it manages replication and failover automatically.</span></p></li><li><p><strong><span>Primary and Secondary Clusters</span></strong><span>: By hosting the primary DB cluster in the primary Region and the secondary DB cluster in the DR Region, the solution ensures minimal data loss and rapid recovery in the event of a disaster. The secondary cluster can be promoted to be the primary cluster if the primary Region fails.</span></p></li><li><p><strong><span>Operational Overhead</span></strong><span>: Aurora global databases automate much of the replication and failover processes, reducing the need for manual intervention and ongoing management. This makes it the solution with the least operational overhead compared to other options.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>EC2 Instances with Replication</span></strong><span>: Managing MySQL on EC2 instances with replication requires significant manual setup and ongoing maintenance. This approach also involves more operational overhead to ensure replication consistency and failover processes.</span></p><p><span>B. </span><strong><span>Amazon RDS Multi-AZ with Read Replication</span></strong><span>: While this setup provides high availability within a single Region, it does not natively support cross-Region disaster recovery. Additional configuration and management are required to set up cross-Region replication.</span></p><p><span>D. </span><strong><span>S3 Cross-Region Replication</span></strong><span>: Storing backups in S3 with Cross-Region Replication provides a cost-effective backup solution, but it involves higher recovery time objectives (RTO) and recovery point objectives (RPO). Restoring the database from backups in the DR Region requires more time and manual effort, resulting in higher operational overhead.</span></p><p><span>By migrating to an Amazon Aurora global database and hosting the primary and secondary clusters in different Regions, the company can achieve a robust DR architecture with minimal operational overhead, meeting the requirements effectively.</span></p><hr /><h3 id='question-344-handling-large-messages-in-a-java-application-using-amazon-sqs'><span>Question #344 Handling large messages in a Java application using Amazon SQS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a Java application that uses Amazon Simple Queue Service (Amazon SQS) to parse messages. The application cannot parse messages that are larger than 256 KB in size. The company wants to implement a solution to give the application the ability to parse messages as large as 50 MB.</span></p><p><strong><span>Which solution will meet these requirements with the FEWEST changes to the code?</span></strong></p><p><span>A. Use the Amazon SQS Extended Client Library for Java to host messages that are larger than 256 KB in Amazon S3.</span></p><p><span>B. Use Amazon EventBridge to post large messages from the application instead of Amazon SQS.</span></p><p><span>C. Change the limit in Amazon SQS to handle messages that are larger than 256 KB.</span></p><p><span>D. Store messages that are larger than 256 KB in Amazon Elastic File System (Amazon EFS). Configure Amazon SQS to reference this location in the messages.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use the Amazon SQS Extended Client Library for Java to host messages that are larger than 256 KB in Amazon S3.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SQS Extended Client Library for Java</span></strong><span>:</span></p><ul><li><p><strong><span>Handling Large Messages</span></strong><span>: The Amazon SQS Extended Client Library for Java is specifically designed to handle messages larger than 256 KB by storing the payload in Amazon S3 and sending a reference to the S3 object in the SQS message.</span></p></li><li><p><strong><span>Minimal Code Changes</span></strong><span>: Using this library requires minimal changes to the existing codebase since it extends the functionality of the existing SQS client in a way that is transparent to the application. This solution allows the application to handle messages up to 50 MB.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon EventBridge (Option B)</span></strong><span>: Switching to Amazon EventBridge would require significant changes to the application code and the overall architecture, making it less suitable for this requirement.</span></p></li><li><p><strong><span>Changing SQS Limit (Option C)</span></strong><span>: The maximum message size for Amazon SQS is 256 KB. This limit cannot be changed, so this option is not feasible.</span></p></li><li><p><strong><span>Amazon EFS (Option D)</span></strong><span>: Storing messages in Amazon EFS and referencing them in SQS messages would require more substantial changes to the application code and the management of EFS, making it less efficient and more complex compared to using the SQS Extended Client Library.</span></p></li></ul></li></ol><p><span>By using the Amazon SQS Extended Client Library for Java to host messages larger than 256 KB in Amazon S3, the company can meet its requirements with the fewest changes to the existing code, allowing the application to handle messages up to 50 MB efficiently.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-345-implementing-a-serverless-authentication-and-authorization-solution-for-a-web-application'><span>Question #345 Implementing a serverless authentication and authorization solution for a web application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to restrict access to the content of one of its main web applications and to protect the content by using authorization techniques available on AWS. The company wants to implement a serverless architecture and an authentication solution for fewer than 100 users. The solution needs to integrate with the main web application and serve web content globally. The solution must also scale as the company&#39;s user base grows while providing the lowest login latency possible. Which solution will meet these requirements MOST cost-effectively?</span></p><p><span>A. Use Amazon Cognito for authentication. Use Lambda@Edge for authorization. Use Amazon CloudFront to serve the web application globally.</span></p><p><span>B. Use AWS Directory Service for Microsoft Active Directory for authentication. Use AWS Lambda for authorization. Use an Application Load Balancer to serve the web application globally.</span></p><p><span>C. Use Amazon Cognito for authentication. Use AWS Lambda for authorization. Use Amazon S3 Transfer Acceleration to serve the web application globally.</span></p><p><span>D. Use AWS Directory Service for Microsoft Active Directory for authentication. Use Lambda@Edge for authorization. Use AWS Elastic Beanstalk to serve the web application globally.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use Amazon Cognito for authentication. Use Lambda@Edge for authorization. Use Amazon CloudFront to serve the web application globally.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Cognito for Authentication</span></strong><span>: Amazon Cognito is a fully managed service that provides authentication, authorization, and user management for web and mobile apps. It scales seamlessly as the user base grows and is cost-effective for fewer than 100 users.</span></p></li><li><p><strong><span>Lambda@Edge for Authorization</span></strong><span>: Lambda@Edge allows you to run Lambda functions at AWS edge locations in response to CloudFront events. This provides low-latency authorization checks close to the user&#39;s location, improving performance.</span></p></li><li><p><strong><span>Amazon CloudFront for Global Content Delivery</span></strong><span>: Amazon CloudFront is a global content delivery network (CDN) that integrates with other AWS services to deliver web content with low latency and high transfer speeds. It is well-suited for serving web applications globally.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>AWS Directory Service and ALB</span></strong><span>: Using AWS Directory Service for Microsoft Active Directory is more complex and expensive compared to Amazon Cognito for a small user base. Additionally, using an Application Load Balancer does not provide global content delivery as efficiently as CloudFront.</span></p><p><span>C. </span><strong><span>AWS Lambda and S3 Transfer Acceleration</span></strong><span>: While Amazon S3 Transfer Acceleration can speed up uploads to S3, it is not designed for serving web applications globally. CloudFront is more appropriate for this use case.</span></p><p><span>D. </span><strong><span>AWS Directory Service and Elastic Beanstalk</span></strong><span>: Similar to option B, using AWS Directory Service for authentication is more complex and costly. AWS Elastic Beanstalk is a platform as a service (PaaS) that simplifies application deployment but does not provide the same global content delivery capabilities as CloudFront.</span></p><p><span>By using Amazon Cognito for authentication, Lambda@Edge for authorization, and Amazon CloudFront for global content delivery, the company can implement a cost-effective, serverless solution that scales with the user base and provides low login latency, meeting all the requirements effectively.</span></p><p>&nbsp;</p><hr /><h3 id='question-346-migrating-nas-data-to-amazon-s3-while-maintaining-the-same-look-and-feel-for-client-workstations'><span>Question #346 Migrating NAS data to Amazon S3 while maintaining the same look and feel for client workstations</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an aging network-attached storage (NAS) array in its data center. The NAS array presents SMB shares and NFS shares to client workstations. The company does not want to purchase a new NAS array. The company also does not want to incur the cost of renewing the NAS array&#39;s support contract. Some of the data is accessed frequently, but much of the data is inactive.</span></p><p><span>A solutions architect needs to implement a solution that migrates the data to Amazon S3, uses S3 Lifecycle policies, and maintains the same look and feel for the client workstations. The solutions architect has identified AWS Storage Gateway as part of the solution.</span></p><p><strong><span>Which type of storage gateway should the solutions architect provision to meet these requirements?</span></strong></p><p><span>A. Volume Gateway</span></p><p><span>B. Tape Gateway</span></p><p><span>C. Amazon FSx File Gateway</span></p><p><span>D. Amazon S3 File Gateway</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Amazon S3 File Gateway</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3 File Gateway</span></strong><span>:</span></p><ul><li><p><strong><span>SMB and NFS Shares</span></strong><span>: The Amazon S3 File Gateway can present SMB and NFS shares to client workstations, maintaining the same look and feel as the existing NAS array.</span></p></li><li><p><strong><span>Integration with S3</span></strong><span>: It allows data to be stored in Amazon S3 while providing local caching for frequently accessed data. This solution also supports S3 Lifecycle policies, which can be used to manage data storage costs by transitioning inactive data to lower-cost storage classes.</span></p></li><li><p><strong><span>Seamless Migration</span></strong><span>: This type of gateway is designed to integrate seamlessly with existing workflows and applications that use SMB and NFS protocols.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Volume Gateway (Option A)</span></strong><span>: Volume Gateway is designed for block storage and does not provide SMB or NFS shares directly to client workstations.</span></p></li><li><p><strong><span>Tape Gateway (Option B)</span></strong><span>: Tape Gateway is used for backup and archival purposes, emulating physical tape libraries. It is not suitable for providing SMB or NFS shares.</span></p></li><li><p><strong><span>Amazon FSx File Gateway (Option C)</span></strong><span>: This option does not exist. The correct option is Amazon S3 File Gateway, which is designed for the described use case.</span></p></li></ul></li></ol><p><span>By provisioning an Amazon S3 File Gateway, the solutions architect can migrate the data to Amazon S3, use S3 Lifecycle policies to manage storage costs, and maintain the same look and feel for the client workstations, meeting all the stated requirements effectively.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-347-maximizing-cost-savings-for-ec2-instances-with-flexibility-to-change-instance-family-and-sizes'><span>Question #347 Maximizing cost savings for EC2 instances with flexibility to change instance family and sizes</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an application that is running on Amazon EC2 instances. A solutions architect has standardized the company on a particular instance family and various instance sizes based on the current needs of the company. The company wants to maximize cost savings for the application over the next 3 years. The company needs to be able to change the instance family and sizes in the next 6 months based on application popularity and usage. Which solution will meet these requirements MOST cost-effectively?</span></p><p><span>A. Compute Savings Plan</span></p><p><span>B. EC2 Instance Savings Plan</span></p><p><span>C. Zonal Reserved Instances</span></p><p><span>D. Standard Reserved Instances</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Compute Savings Plan</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Compute Savings Plan</span></strong><span>: Compute Savings Plans offer the most flexibility and the highest potential cost savings. They provide savings across a wide range of EC2 instance families, sizes, and regions, and even apply to AWS Fargate and AWS Lambda usage. This flexibility allows the company to change instance families and sizes as needed without losing the benefits of the savings plan.</span></p></li><li><p><strong><span>Flexibility</span></strong><span>: The company needs to be able to change the instance family and sizes within the next 6 months. Compute Savings Plans allow this flexibility, making them the most suitable option for the company&#39;s requirements.</span></p></li><li><p><strong><span>Cost Savings</span></strong><span>: Compute Savings Plans provide significant cost savings (up to 66%) compared to On-Demand pricing, making them a cost-effective solution for long-term usage.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>EC2 Instance Savings Plan</span></strong><span>: EC2 Instance Savings Plans are more restrictive than Compute Savings Plans as they apply to a specific instance family within a region. While they offer savings, they do not provide the same level of flexibility to change instance families.</span></p><p><span>C. </span><strong><span>Zonal Reserved Instances</span></strong><span>: Zonal Reserved Instances are tied to a specific Availability Zone and instance type, offering less flexibility. They are suitable for workloads with predictable usage patterns in a specific zone but do not allow changes to instance families or sizes.</span></p><p><span>D. </span><strong><span>Standard Reserved Instances</span></strong><span>: Standard Reserved Instances offer significant cost savings but are less flexible compared to Savings Plans. They are tied to a specific instance family and size, which does not meet the company&#39;s requirement to change instance families and sizes within the next 6 months.</span></p><p><span>By choosing Compute Savings Plans, the company can maximize cost savings while retaining the flexibility to change instance families and sizes as needed, making it the most cost-effective solution to meet their requirements.</span></p><p>&nbsp;</p><hr /><h3 id='question-348-managing-dynamodb-costs-with-predictable-workloads'><span>Question #348 Managing DynamoDB costs with predictable workloads</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company collects data from a large number of participants who use wearable devices. The company stores the data in an Amazon DynamoDB table and uses applications to analyze the data. The data workload is constant and predictable. The company wants to stay at or below its forecasted budget for DynamoDB.</span></p><p><strong><span>Which solution will meet these requirements MOST cost-effectively?</span></strong></p><p><strong><span>Options:</span></strong></p><p><span>A. Use provisioned mode and DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA). Reserve capacity for the forecasted workload.</span></p><p><span>B. Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs).</span></p><p><span>C. Use on-demand mode. Set the read capacity units (RCUs) and write capacity units (WCUs) high enough to accommodate changes in the workload.</span></p><p><span>D. Use on-demand mode. Specify the read capacity units (RCUs) and write capacity units (WCUs) with reserved capacity.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>B. Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs).</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Provisioned Mode (Option B)</span></strong><span>: Using provisioned mode allows the company to specify the exact number of read capacity units (RCUs) and write capacity units (WCUs) required for the workload. Since the workload is constant and predictable, this approach enables the company to allocate just enough capacity to handle the workload efficiently, keeping costs predictable and controlled. Provisioned mode is generally more cost-effective for workloads with predictable usage patterns compared to on-demand mode, which can be more expensive for steady-state applications.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Provisioned Mode with DynamoDB Standard-IA</span></strong><span>: While using provisioned mode with DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA) can reduce costs for infrequently accessed data, it is not suitable for constant and predictable workloads where data is accessed regularly. Standard-IA is designed for data that is accessed less frequently, which does not align with the company&#39;s requirements.</span></p><p><span>C. </span><strong><span>On-Demand Mode</span></strong><span>: On-demand mode is suitable for workloads with unpredictable traffic patterns as it automatically adjusts capacity based on usage. However, it is typically more expensive than provisioned mode for constant and predictable workloads. Setting RCUs and WCUs high enough to accommodate changes in the workload would lead to unnecessary costs.</span></p><p><span>D. </span><strong><span>On-Demand Mode with Reserved Capacity</span></strong><span>: On-demand mode does not support reserved capacity. Reserved capacity is a feature of provisioned mode, allowing companies to commit to a specific amount of capacity over a period (e.g., one or three years) for a discount. Therefore, this option is not valid.</span></p><p><span>By using provisioned mode and specifying the necessary RCUs and WCUs, the company can effectively manage DynamoDB costs while ensuring that the capacity meets the predictable workload requirements. This approach provides cost predictability and control, aligning with the company&#39;s goal of staying within the forecasted budget.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-349-securely-sharing-an-encrypted-aurora-postgresql-database-snapshot-with-another-aws-account'><span>Question #349 Securely sharing an encrypted Aurora PostgreSQL database snapshot with another AWS account</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company stores confidential data in an Amazon Aurora PostgreSQL database in the ap-southeast-3 Region. The database is encrypted with an AWS Key Management Service (AWS KMS) customer managed key. The company was recently acquired and must securely share a backup of the database with the acquiring company&#39;s AWS account in ap-southeast-3. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Create a database snapshot. Copy the snapshot to a new unencrypted snapshot. Share the new snapshot with the acquiring company&#39;s AWS account.</span></p><p><span>B. Create a database snapshot. Add the acquiring company&#39;s AWS account to the KMS key policy. Share the snapshot with the acquiring company&#39;s AWS account.</span></p><p><span>C. Create a database snapshot that uses a different AWS managed KMS key. Add the acquiring company&#39;s AWS account to the KMS key alias. Share the snapshot with the acquiring company&#39;s AWS account.</span></p><p><span>D. Create a database snapshot. Download the database snapshot. Upload the database snapshot to an Amazon S3 bucket. Update the S3 bucket policy to allow access from the acquiring company&#39;s AWS account.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create a database snapshot. Add the acquiring company&#39;s AWS account to the KMS key policy. Share the snapshot with the acquiring company&#39;s AWS account.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Database Snapshot</span></strong><span>: Creating a database snapshot is the first step in securely sharing the database backup. This snapshot will contain all the data from the Aurora PostgreSQL database.</span></p></li><li><p><strong><span>KMS Key Policy</span></strong><span>: Since the database is encrypted with a KMS customer managed key, the acquiring company&#39;s AWS account must have access to this key to decrypt the snapshot. Adding the acquiring company&#39;s AWS account to the KMS key policy ensures that they have the necessary permissions to use the key for decryption.</span></p></li><li><p><strong><span>Sharing the Snapshot</span></strong><span>: Once the acquiring company&#39;s AWS account has the required permissions on the KMS key, the snapshot can be shared with their account. This allows the acquiring company to access and restore the snapshot in their own AWS environment.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Unencrypted Snapshot</span></strong><span>: Creating an unencrypted snapshot compromises the security of the confidential data. This approach is not secure and does not meet the requirement to securely share the data.</span></p><p><span>C. </span><strong><span>Different KMS Key</span></strong><span>: Using a different AWS managed KMS key and adding the acquiring company&#39;s AWS account to the KMS key alias does not address the need to securely share the existing encrypted snapshot. The snapshot must remain encrypted with the original KMS key.</span></p><p><span>D. </span><strong><span>S3 Bucket</span></strong><span>: Downloading the database snapshot and uploading it to an S3 bucket adds unnecessary complexity and does not leverage the secure sharing capabilities provided by AWS. Additionally, managing the S3 bucket policy introduces potential security risks.</span></p><p><span>By creating a database snapshot, adding the acquiring company&#39;s AWS account to the KMS key policy, and sharing the snapshot, the solutions architect can securely share the encrypted database backup with the acquiring company&#39;s AWS account, meeting the requirements effectively.</span></p><hr /><p>&nbsp;</p><h3 id='question-350-improving-high-availability-and-report-performance-for-an-rds-for-microsoft-sql-server-instance'><span>Question #350 Improving high availability and report performance for an RDS for Microsoft SQL Server instance</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company uses a 100 GB Amazon RDS for Microsoft SQL Server Single-AZ DB instance in the us-east-1 Region to store customer transactions. The company needs high availability and automatic recovery for the DB instance. The company must also run reports on the RDS database several times a year. The report process causes transactions to take longer than usual to post to the customers&#39; accounts. The company needs a solution that will improve the performance of the report process.</span></p><p><strong><span>Which combination of steps will meet these requirements? (Choose two.)</span></strong></p><p><span>A. Modify the DB instance from a Single-AZ DB instance to a Multi-AZ deployment.</span></p><p><span>B. Take a snapshot of the current DB instance. Restore the snapshot to a new RDS deployment in another Availability Zone.</span></p><p><span>C. Create a read replica of the DB instance in a different Availability Zone. Point all requests for reports to the read replica.</span></p><p><span>D. Migrate the database to RDS Custom.</span></p><p><span>E. Use RDS Proxy to limit reporting requests to the maintenance window.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>A. Modify the DB instance from a Single-AZ DB instance to a Multi-AZ deployment.</span></p><p><span>C. Create a read replica of the DB instance in a different Availability Zone. Point all requests for reports to the read replica.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>High Availability and Automatic Recovery</span></strong><span>:</span></p><ul><li><p><strong><span>Multi-AZ Deployment (Option A)</span></strong><span>: Modifying the DB instance to a Multi-AZ deployment provides high availability and automatic recovery. In a Multi-AZ configuration, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. This setup ensures that the database remains available during maintenance, backups, and instance failures.</span></p></li></ul></li><li><p><strong><span>Improving Report Performance</span></strong><span>:</span></p><ul><li><p><strong><span>Read Replica (Option C)</span></strong><span>: Creating a read replica of the DB instance in a different Availability Zone allows the company to offload read-heavy operations, such as running reports, to the read replica. This approach improves the performance of the primary DB instance by reducing the load caused by reporting.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Snapshot and Restore (Option B)</span></strong><span>: Taking a snapshot and restoring it to a new RDS deployment does not provide high availability or automatic recovery and involves manual steps, which are not ideal for continuous operations.</span></p></li><li><p><strong><span>RDS Custom (Option D)</span></strong><span>: RDS Custom is designed for applications that require customization of the underlying database environment. It does not directly address the high availability or reporting performance requirements.</span></p></li><li><p><strong><span>RDS Proxy (Option E)</span></strong><span>: RDS Proxy helps with connection management and can improve application scalability and availability, but it does not specifically address the need to offload reporting or provide high availability through a Multi-AZ setup.</span></p></li></ul></li></ol><p><span>By modifying the DB instance to a Multi-AZ deployment and creating a read replica in a different Availability Zone, the company can achieve high availability, automatic recovery, and improved performance for the report process, meeting all the stated requirements effectively.</span></p><p>&nbsp;</p><hr /><h3 id='question-351-transitioning-to-an-event-driven-serverless-architecture-with-minimal-operational-overhead'><span>Question #351 Transitioning to an event-driven, serverless architecture with minimal operational overhead</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture. The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workflow. The company also wants to minimize operational overhead. Which solution will meet these requirements?</span></p><p><span>A. Build out the workflow in AWS Glue. Use AWS Glue to invoke AWS Lambda functions to process the workflow steps.</span></p><p><span>B. Build out the workflow in AWS Step Functions. Deploy the application on Amazon EC2 instances. Use Step Functions to invoke the workflow steps on the EC2 instances.</span></p><p><span>C. Build out the workflow in Amazon EventBridge. Use EventBridge to invoke AWS Lambda functions on a schedule to process the workflow steps.</span></p><p><span>D. Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Step Functions</span></strong><span>: AWS Step Functions is a serverless orchestration service that allows you to build and run workflows that coordinate multiple AWS services. It is ideal for creating event-driven architectures with minimal operational overhead.</span></p></li><li><p><strong><span>State Machine</span></strong><span>: A state machine in Step Functions defines the workflow as a series of steps, each of which can invoke different AWS services, including AWS Lambda functions. This allows for a highly distributed and scalable architecture.</span></p></li><li><p><strong><span>AWS Lambda</span></strong><span>: Using AWS Lambda functions to process the workflow steps ensures a serverless, event-driven execution model. Lambda functions automatically scale with the workload and eliminate the need for managing servers.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: By leveraging Step Functions and Lambda, the company can build a fully managed, serverless workflow with minimal operational overhead. AWS handles the infrastructure, scaling, and fault tolerance.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Glue</span></strong><span>: AWS Glue is a fully managed ETL service designed for data integration tasks. While it can invoke Lambda functions, it is primarily focused on data processing and may not be the best fit for general workflow orchestration.</span></p><p><span>B. </span><strong><span>Step Functions and EC2 Instances</span></strong><span>: Deploying the application on EC2 instances introduces additional operational overhead for managing and scaling the instances. This approach is not fully serverless and does not minimize operational overhead.</span></p><p><span>C. </span><strong><span>EventBridge and Scheduled Lambda</span></strong><span>: While Amazon EventBridge can be used to build event-driven architectures, using it to invoke Lambda functions on a schedule may not provide the same level of workflow orchestration and state management as Step Functions.</span></p><p><span>By building out the workflow in AWS Step Functions and using a state machine to invoke AWS Lambda functions, the company can achieve a distributed, serverless, event-driven architecture with minimal operational overhead, meeting all the requirements effectively.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-352-designing-a-low-latency-high-quality-network-for-an-online-multi-player-game'><span>Question #352 Designing a low-latency, high-quality network for an online multi-player game</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is designing the network for an online multi-player game. The game uses the UDP networking protocol and will be deployed in eight AWS Regions. The network architecture needs to minimize latency and packet loss to give end users a high-quality gaming experience.</span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Set up a transit gateway in each Region. Create inter-Region peering attachments between each transit gateway.</span></p><p><span>B. Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.</span></p><p><span>C. Set up Amazon CloudFront with UDP turned on. Configure an origin in each Region.</span></p><p><span>D. Set up a VPC peering mesh between each Region. Turn on UDP for each VPC.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Global Accelerator</span></strong><span>:</span></p><ul><li><p><strong><span>Low Latency and High Availability</span></strong><span>: AWS Global Accelerator is designed to improve the availability and performance of applications with global users. It provides a static IP address that acts as a fixed entry point to your application endpoints in multiple AWS Regions.</span></p></li><li><p><strong><span>UDP Support</span></strong><span>: Global Accelerator supports UDP listeners, which is essential for the online multi-player game that uses the UDP networking protocol.</span></p></li><li><p><strong><span>Optimized Routing</span></strong><span>: Global Accelerator routes user traffic to the nearest available endpoint based on health, geographic location, and policies, minimizing latency and packet loss. This ensures a high-quality gaming experience for end users.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Transit Gateway (Option A)</span></strong><span>: While transit gateways can be used for inter-region connectivity, they are more suited for VPC-to-VPC communication and do not provide the same level of global traffic optimization and latency reduction as Global Accelerator.</span></p></li><li><p><strong><span>Amazon CloudFront (Option C)</span></strong><span>: CloudFront is a content delivery network (CDN) primarily used for HTTP/HTTPS traffic and does not natively support UDP traffic, making it unsuitable for this use case.</span></p></li><li><p><strong><span>VPC Peering Mesh (Option D)</span></strong><span>: Setting up a VPC peering mesh between regions can provide inter-region connectivity, but it does not optimize for low latency and packet loss in the same way Global Accelerator does. Additionally, managing a full mesh of VPC peering connections can be complex and operationally intensive.</span></p></li></ul></li></ol><p><span>By setting up AWS Global Accelerator with UDP listeners and endpoint groups in each region, the company can ensure that the online multi-player game has minimized latency and packet loss, providing a high-quality gaming experience for end users.</span></p><p>&nbsp;</p><hr /><h3 id='question-353-moving-to-a-managed-highly-available-and-cost-effective-database-solution'><span>Question #353 Moving to a managed, highly available, and cost-effective database solution</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a three-tier web application on Amazon EC2 instances in a single Availability Zone. The web application uses a self-managed MySQL database that is hosted on an EC2 instance to store data in an Amazon Elastic Block Store (Amazon EBS) volume. The MySQL database currently uses a 1 TB Provisioned IOPS SSD (i02) EBS volume. The company expects traffic of 1,000 IOPS for both reads and writes at peak traffic. The company wants to minimize any disruptions, stabilize performance, and reduce costs while retaining the capacity for double the IOPS. The company wants to move the database tier to a fully managed solution that is highly available and fault tolerant. Which solution will meet these requirements MOST cost-effectively?</span></p><p><span>A. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with an i02 Block Express EBS volume.</span></p><p><span>B. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.</span></p><p><span>C. Use Amazon S3 Intelligent-Tiering access tiers.</span></p><p><span>D. Use two large EC2 instances to host the database in active-passive mode.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Multi-AZ Deployment</span></strong><span>: Amazon RDS for MySQL with Multi-AZ deployment provides high availability and fault tolerance. It automatically creates a standby replica in a different Availability Zone and performs synchronous replication to ensure data redundancy and failover capability.</span></p></li><li><p><strong><span>General Purpose SSD (gp2)</span></strong><span>: General Purpose SSD (gp2) EBS volumes provide a balance of price and performance for a wide variety of workloads. They can burst up to 3,000 IOPS per volume, which is sufficient for the company&#39;s requirement of 1,000 IOPS for both reads and writes at peak traffic, with the capacity to handle double the IOPS.</span></p></li><li><p><strong><span>Cost-Effectiveness</span></strong><span>: Using gp2 volumes is more cost-effective compared to Provisioned IOPS SSD (i02) volumes. The gp2 volumes provide a good balance of performance and cost, making them suitable for the company&#39;s needs while reducing costs.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>i02 Block Express EBS Volume</span></strong><span>: While using an i02 Block Express EBS volume would provide high performance, it is more expensive than gp2 volumes. This option may not be the most cost-effective solution for the company&#39;s requirements.</span></p><p><span>C. </span><strong><span>Amazon S3 Intelligent-Tiering</span></strong><span>: S3 Intelligent-Tiering is a storage class for optimizing storage costs for data with unpredictable access patterns. It is not relevant to the use case of hosting a MySQL database.</span></p><p><span>D. </span><strong><span>Two Large EC2 Instances in Active-Passive Mode</span></strong><span>: Managing two EC2 instances in an active-passive configuration for high availability involves more operational overhead and does not provide the same level of automated management and failover capabilities as Amazon RDS. Additionally, it may not be as cost-effective as using a managed RDS solution.</span></p><p><span>By using a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume, the company can achieve a highly available, fault-tolerant, and cost-effective managed database solution that meets their performance requirements.</span></p><p>&nbsp;</p><hr /><h3 id='question-354-mitigating-database-connection-timeouts-in-a-serverless-application'><span>Question #354 Mitigating database connection timeouts in a serverless application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a serverless application on AWS. The application uses Amazon API Gateway, AWS Lambda, and an Amazon RDS for PostgreSQL database. The company notices an increase in application errors that result from database connection timeouts during times of peak traffic or unpredictable traffic. The company needs a solution that reduces the application failures with the least amount of change to the code.</span></p><p><strong><span>What should a solutions architect do to meet these requirements?</span></strong></p><p><span>A. Reduce the Lambda concurrency rate.</span></p><p><span>B. Enable RDS Proxy on the RDS DB instance.</span></p><p><span>C. Resize the RDS DB instance class to accept more connections.</span></p><p><span>D. Migrate the database to Amazon DynamoDB with on-demand scaling.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Enable RDS Proxy on the RDS DB instance.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>RDS Proxy</span></strong><span>:</span></p><ul><li><p><strong><span>Connection Management</span></strong><span>: RDS Proxy helps manage database connections efficiently. It pools and shares connections among multiple Lambda functions, reducing the overhead of opening and closing connections frequently, which is a common cause of connection timeouts during peak traffic.</span></p></li><li><p><strong><span>Minimal Code Changes</span></strong><span>: Enabling RDS Proxy requires minimal changes to the existing code. The application can continue to use the same database connection logic, but it will benefit from improved connection management and reduced latency.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Reduce Lambda Concurrency Rate (Option A)</span></strong><span>: Reducing the concurrency rate might mitigate the issue temporarily but will likely degrade the application’s performance and responsiveness during peak traffic.</span></p></li><li><p><strong><span>Resize the RDS DB Instance Class (Option C)</span></strong><span>: While resizing the instance can increase the number of available connections, it might not fully address the issue of connection management during unpredictable traffic spikes. Additionally, this approach can be more costly.</span></p></li><li><p><strong><span>Migrate to Amazon DynamoDB (Option D)</span></strong><span>: Migrating to DynamoDB would require significant changes to the application code and database schema. While DynamoDB can handle unpredictable traffic well, this option involves a major architectural change, which is not aligned with the requirement to minimize code changes.</span></p></li></ul></li></ol><p><span>By enabling RDS Proxy on the RDS DB instance, the company can efficiently manage database connections, reducing the likelihood of connection timeouts during peak traffic, with minimal changes to the existing application code. This solution meets the requirement of reducing application failures with the least amount of change to the code.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-355-migrating-a-cpu-intensive-batch-job-to-aws-with-minimal-operational-overhead'><span>Question #355 Migrating a CPU-intensive batch job to AWS with minimal operational overhead</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory. Which solution will run the batch job within 15 minutes with the LEAST operational overhead?</span></p><p><span>A. Use AWS Lambda with functional scaling.</span></p><p><span>B. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.</span></p><p><span>C. Use Amazon Lightsail with AWS Auto Scaling.</span></p><p><span>D. Use AWS Batch on Amazon EC2.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use AWS Batch on Amazon EC2.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Batch</span></strong><span>: AWS Batch is a fully managed service that enables you to run batch computing workloads on the AWS Cloud. It efficiently provisions the optimal quantity and type of compute resources (e.g., CPU or memory-optimized instances) based on the volume and specific resource requirements of the batch jobs submitted.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: AWS Batch abstracts the underlying infrastructure and manages the provisioning, scheduling, and scaling of compute resources, reducing the operational overhead.</span></p></li><li><p><strong><span>Customizable EC2 Instances</span></strong><span>: AWS Batch allows you to specify the instance types and configurations that best match the requirements of your batch job. You can choose EC2 instances with 64 vCPUs and 512 GiB of memory to match the on-premises server specifications.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>AWS Lambda with Functional Scaling</span></strong><span>: AWS Lambda is not suitable for this use case because it is designed for short-lived, event-driven functions with a maximum execution time of 15 minutes. Additionally, it does not support the high memory and CPU requirements of the batch job.</span></p><p><span>B. </span><strong><span>Amazon ECS with AWS Fargate</span></strong><span>: While Amazon ECS with AWS Fargate provides a serverless way to run containers, it may not be the most efficient solution for a CPU-intensive batch job that requires specific instance types and configurations. AWS Batch is better suited for batch processing workloads.</span></p><p><span>C. </span><strong><span>Amazon Lightsail with AWS Auto Scaling</span></strong><span>: Amazon Lightsail is designed for simple web applications and does not provide the same level of flexibility and scalability as AWS Batch. It may not meet the performance requirements for a CPU-intensive batch job.</span></p><p><span>By using AWS Batch on Amazon EC2, the company can run the CPU-intensive batch job within 15 minutes with minimal operational overhead, leveraging the flexibility and scalability of AWS Batch to provision the appropriate compute resources.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-356-optimizing-s3-storage-costs-for-rarely-accessed-data'><span>Question #356 Optimizing S3 storage costs for rarely accessed data</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company stores its data objects in Amazon S3 Standard storage. A solutions architect has found that 75% of the data is rarely accessed after 30 days. The company needs all the data to remain immediately accessible with the same high availability and resiliency, but the company wants to minimize storage costs.</span></p><p><strong><span>Which storage solution will meet these requirements?</span></strong></p><p><span>A. Move the data objects to S3 Glacier Deep Archive after 30 days.</span></p><p><span>B. Move the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.</span></p><p><span>C. Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.</span></p><p><span>D. Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) immediately.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Move the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>S3 Standard-Infrequent Access (S3 Standard-IA)</span></strong><span>:</span></p><ul><li><p><strong><span>Cost Optimization</span></strong><span>: S3 Standard-IA is designed for data that is accessed less frequently but requires rapid access when needed. It offers lower storage costs compared to S3 Standard, making it a cost-effective solution for data that is rarely accessed after 30 days.</span></p></li><li><p><strong><span>High Availability and Resiliency</span></strong><span>: S3 Standard-IA provides the same high availability and resiliency as S3 Standard, ensuring that the data remains immediately accessible and protected.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>S3 Glacier Deep Archive (Option A)</span></strong><span>: While S3 Glacier Deep Archive is the lowest-cost storage class for data that is rarely accessed, it is designed for long-term archival storage and does not provide immediate access to data. Retrieval times can range from minutes to hours, which does not meet the requirement for immediate accessibility.</span></p></li><li><p><strong><span>S3 One Zone-Infrequent Access (S3 One Zone-IA) (Options C and D)</span></strong><span>: S3 One Zone-IA stores data in a single Availability Zone, which does not provide the same level of resiliency and availability as S3 Standard or S3 Standard-IA. This makes it less suitable for data that needs to remain highly available and resilient.</span></p></li></ul></li></ol><p><span>By moving the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, the company can minimize storage costs while maintaining the same high availability and resiliency for their data. This solution meets the requirement of keeping the data immediately accessible with reduced storage costs.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-357-moving-a-public-scoreboard-application-to-aws-with-highly-available-storage'><span>Question #357 Moving a public scoreboard application to AWS with highly available storage</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A gaming company is moving its public scoreboard from a data center to the AWS Cloud. The company uses Amazon EC2 Windows Server instances behind an Application Load Balancer to host its dynamic application. The company needs a highly available storage solution for the application. The application consists of static files and dynamic server-side code. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)</span></p><p><span>A. Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.</span></p><p><span>B. Store the static files on Amazon S3. Use Amazon ElastiCache to cache objects at the edge.</span></p><p><span>C. Store the server-side code on Amazon Elastic File System (Amazon EFS). Mount the EFS volume on each EC2 instance to share the files.</span></p><p><span>D. Store the server-side code on Amazon FSx for Windows File Server. Mount the FSx for Windows File Server volume on each EC2 instance to share the files.</span></p><p><span>E. Store the server-side code on a General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on each EC2 instance to share the files.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.</span></p><p><span>D. Store the server-side code on Amazon FSx for Windows File Server. Mount the FSx for Windows File Server volume on each EC2 instance to share the files.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3 and CloudFront for Static Files</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon S3</span></strong><span>: Amazon S3 is a highly available and durable object storage service that is ideal for storing static files such as images, videos, and other media.</span></p></li><li><p><strong><span>Amazon CloudFront</span></strong><span>: CloudFront is a content delivery network (CDN) that caches objects at edge locations around the world, providing low-latency access to static files stored in S3. This combination ensures that static files are served quickly and reliably to users globally.</span></p></li></ul></li><li><p><strong><span>Amazon FSx for Windows File Server for Server-Side Code</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon FSx for Windows File Server</span></strong><span>: FSx for Windows File Server provides fully managed, highly available, and durable file storage for Windows applications. It is designed to work seamlessly with Windows-based EC2 instances.</span></p></li><li><p><strong><span>Mounting FSx on EC2 Instances</span></strong><span>: By mounting the FSx for Windows File Server volume on each EC2 instance, the server-side code can be shared and accessed by all instances. This ensures high availability and fault tolerance for the dynamic application components.</span></p></li></ul></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Amazon ElastiCache</span></strong><span>: ElastiCache is a caching service that improves the performance of applications by caching frequently accessed data. However, it is not designed for caching static files at the edge like CloudFront.</span></p><p><span>C. </span><strong><span>Amazon EFS</span></strong><span>: While Amazon EFS is a highly available and scalable file system for Linux-based applications, it is not the best fit for Windows-based applications. FSx for Windows File Server is more suitable for this use case.</span></p><p><span>E. </span><strong><span>Amazon EBS</span></strong><span>: EBS volumes are block storage devices that can be attached to EC2 instances. However, they are not designed for sharing files across multiple instances. EFS or FSx are better options for shared file storage.</span></p><p><span>By storing static files on Amazon S3 and using CloudFront to cache them at the edge, and by using Amazon FSx for Windows File Server to store and share server-side code, the company can achieve a highly available and cost-effective storage solution for its application.</span></p><hr /><p>&nbsp;</p><h3 id='question-358-dynamic-image-resizing-with-minimal-operational-overhead'><span>Question #358 Dynamic image resizing with minimal operational overhead</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A social media company runs its application on Amazon EC2 instances behind an Application Load Balancer (ALB). The ALB is the origin for an Amazon CloudFront distribution. The application has more than a billion images stored in an Amazon S3 bucket and processes thousands of images each second. The company wants to resize the images dynamically and serve appropriate formats to clients.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST operational overhead?</span></strong></p><p><span>A. Install an external image management library on an EC2 instance. Use the image management library to process the images.</span></p><p><span>B. Create a CloudFront origin request policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.</span></p><p><span>C. Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviors that serve the images.</span></p><p><span>D. Create a CloudFront response headers policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviors that serve the images.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Lambda@Edge with Image Management Library</span></strong><span>:</span></p><ul><li><p><strong><span>Dynamic Image Processing</span></strong><span>: Using a Lambda@Edge function allows for dynamic image resizing and format conversion at the edge, based on the incoming request. This ensures that the images are processed close to the user, reducing latency.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: Lambda@Edge is a serverless solution that scales automatically with the number of requests, eliminating the need to manage and scale EC2 instances manually. It also integrates seamlessly with CloudFront, providing a low-maintenance solution.</span></p></li><li><p><strong><span>User-Agent Header</span></strong><span>: The Lambda@Edge function can inspect the User-Agent HTTP header to determine the appropriate image format (e.g., WebP for browsers that support it) and resize images accordingly.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>External Image Management Library on EC2 (Option A)</span></strong><span>: This option requires managing and scaling EC2 instances, which increases operational overhead. It also introduces additional latency as images must be processed on the server before being served to the client.</span></p></li><li><p><strong><span>CloudFront Origin Request Policy (Option B)</span></strong><span>: CloudFront origin request policies do not support dynamic image processing or format conversion based on the User-Agent header. They are used to control the headers, query strings, and cookies that CloudFront includes in requests to your origin.</span></p></li><li><p><strong><span>CloudFront Response Headers Policy (Option D)</span></strong><span>: CloudFront response headers policies are used to add or modify HTTP headers in responses from CloudFront. They do not provide functionality for dynamic image resizing or format conversion.</span></p></li></ul></li></ol><p><span>By using a Lambda@Edge function with an external image management library, the company can dynamically resize images and serve appropriate formats with minimal operational overhead, leveraging the scalability and low latency of AWS edge services.</span></p><p>&nbsp;</p><hr /><h3 id='question-359-ensuring-encryption-of-patient-records-in-amazon-s3'><span>Question #359 Ensuring encryption of patient records in Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A hospital needs to store patient records in an Amazon S3 bucket. The hospital&#39;s compliance team must ensure that all protected health information (PHI) is encrypted in transit and at rest. The compliance team must administer the encryption key for data at rest. Which solution will meet these requirements?</span></p><p><span>A. Create a public SSL/TLS certificate in AWS Certificate Manager (ACM). Associate the certificate with Amazon S3. Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.</span></p><p><span>B. Use the </span><code>aws:SecureTransport</code><span> condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with S3 managed encryption keys (SSE-S3). Assign the compliance team to manage the SSE-S3 keys.</span></p><p><span>C. Use the </span><code>aws:SecureTransport</code><span> condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.</span></p><p><span>D. Use the </span><code>aws:SecureTransport</code><span> condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Use Amazon Macie to protect the sensitive data that is stored in Amazon S3. Assign the compliance team to manage Macie.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use the </span><code>aws:SecureTransport</code><span> condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Encryption in Transit</span></strong><span>: Using the </span><code>aws:SecureTransport</code><span> condition in S3 bucket policies ensures that all connections to the S3 bucket are encrypted using HTTPS (TLS). This meets the requirement for encryption in transit.</span></p></li><li><p><strong><span>Encryption at Rest</span></strong><span>: Configuring default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS) ensures that all data stored in the bucket is encrypted at rest. AWS KMS allows for centralized key management and control, which is suitable for compliance requirements.</span></p></li><li><p><strong><span>Key Management</span></strong><span>: Assigning the compliance team to manage the KMS keys provides the necessary control over the encryption keys. This ensures that the team can administer and audit the keys as required by compliance regulations.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Public SSL/TLS Certificate in ACM</span></strong><span>: While ACM can provide SSL/TLS certificates, associating a certificate with S3 is not necessary for enforcing HTTPS connections. The </span><code>aws:SecureTransport</code><span> condition in the bucket policy is sufficient.</span></p><p><span>B. </span><strong><span>SSE-S3 Keys</span></strong><span>: Using SSE-S3 keys means that the keys are managed by AWS, not the compliance team. This does not meet the requirement for the compliance team to administer the encryption keys.</span></p><p><span>D. </span><strong><span>Amazon Macie</span></strong><span>: Amazon Macie is a data security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS. While it helps protect sensitive data, it does not provide the necessary encryption key management capabilities required by the compliance team.</span></p><p><span>By using the </span><code>aws:SecureTransport</code><span> condition to enforce HTTPS connections and configuring default encryption with AWS KMS keys, the hospital can ensure that all PHI is encrypted in transit and at rest, while allowing the compliance team to manage the encryption keys.</span></p><p>&nbsp;</p><hr /><h3 id='question-360-ensuring-private-communication-between-rest-apis-in-the-same-vpc'><span>Question #360 Ensuring private communication between REST APIs in the same VPC</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company uses Amazon API Gateway to run a private gateway with two REST APIs in the same VPC. The BuyStock RESTful web service calls the CheckFunds RESTful web service to ensure that enough funds are available before a stock can be purchased. The company has noticed in the VPC flow logs that the BuyStock RESTful web service calls the CheckFunds RESTful web service over the internet instead of through the VPC. A solutions architect must implement a solution so that the APIs communicate through the VPC.</span></p><p><strong><span>Which solution will meet these requirements with the FEWEST changes to the code?</span></strong></p><p><span>A. Add an X-API-Key header in the HTTP header for authorization.</span></p><p><span>B. Use an interface endpoint.</span></p><p><span>C. Use a gateway endpoint.</span></p><p><span>D. Add an Amazon Simple Queue Service (Amazon SQS) queue between the two REST APIs.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Use an interface endpoint.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Interface Endpoint</span></strong><span>:</span></p><ul><li><p><strong><span>Private Communication</span></strong><span>: An interface endpoint enables private communication between your VPC and supported AWS services, without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.</span></p></li><li><p><strong><span>Minimal Code Changes</span></strong><span>: Using an interface endpoint allows the REST APIs to communicate within the VPC, ensuring that the traffic does not go over the internet. This approach requires minimal changes to the existing code and configuration.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>X-API-Key Header (Option A)</span></strong><span>: Adding an X-API-Key header is used for API authorization and does not address the issue of routing traffic through the VPC.</span></p></li><li><p><strong><span>Gateway Endpoint (Option C)</span></strong><span>: Gateway endpoints are used for Amazon S3 and DynamoDB services and are not applicable for API Gateway.</span></p></li><li><p><strong><span>Amazon SQS (Option D)</span></strong><span>: Adding an SQS queue would introduce additional complexity and latency, as it involves asynchronous communication and does not directly address the issue of ensuring private communication within the VPC.</span></p></li></ul></li></ol><p><span>By using an interface endpoint, the company can ensure that the BuyStock RESTful web service communicates with the CheckFunds RESTful web service through the VPC, without requiring significant changes to the existing code. This solution meets the requirement with the fewest changes to the code and ensures secure, private communication between the APIs.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-361-meeting-the-requirements-for-sub-millisecond-latency-and-one-time-queries-on-historical-data'><span>Question #361 Meeting the requirements for sub-millisecond latency and one-time queries on historical data</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a multiplayer gaming application on AWS. The company wants the application to read data with sub-millisecond latency and run one-time queries on historical data. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to export the data to an Amazon S3 bucket.</span></p><p><span>B. Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move older data to S3 Glacier Deep Archive for long-term storage. Run one-time queries on the data in Amazon S3 by using Amazon Athena.</span></p><p><span>C. Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.</span></p><p><span>D. Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from Kinesis Data Streams. Store the records in an Amazon S3 bucket.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon DynamoDB with DynamoDB Accelerator (DAX)</span></strong><span>: DynamoDB is a fully managed NoSQL database service that provides single-digit millisecond response times. Adding DynamoDB Accelerator (DAX) can further reduce the latency to microseconds for read operations, which meets the requirement for sub-millisecond latency.</span></p></li><li><p><strong><span>Exporting Data to Amazon S3</span></strong><span>: DynamoDB provides a feature to export table data directly to Amazon S3. This allows for efficient and automated transfer of data from DynamoDB to S3 without the need for custom scripts or additional operational overhead.</span></p></li><li><p><strong><span>Amazon Athena for One-Time Queries</span></strong><span>: Amazon Athena is an interactive query service that allows you to run SQL queries on data stored in Amazon S3. It is serverless and requires no infrastructure management, making it ideal for running one-time queries on historical data with minimal operational overhead.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon RDS and Custom Script</span></strong><span>: Using Amazon RDS for frequently accessed data and running custom scripts to export data to S3 introduces additional operational overhead. RDS may not provide the sub-millisecond latency required for the application.</span></p><p><span>B. </span><strong><span>Amazon S3 and Athena</span></strong><span>: Storing data directly in S3 and using Athena for queries is suitable for historical data analysis but does not meet the requirement for sub-millisecond latency for frequently accessed data.</span></p><p><span>D. </span><strong><span>DynamoDB, Kinesis Data Streams, and Firehose</span></strong><span>: This solution introduces additional complexity and operational overhead by involving multiple services (DynamoDB, Kinesis Data Streams, and Firehose) to achieve the data export and query functionality.</span></p><p><span>By using Amazon DynamoDB with DAX for frequently accessed data and exporting the data to Amazon S3 for running one-time queries with Amazon Athena, the company can achieve the required sub-millisecond latency and efficient querying of historical data with the least operational overhead.</span></p><p>&nbsp;</p><hr /><h3 id='question-362-ensuring-message-order-for-a-payment-processing-system'><span>Question #362 Ensuring message order for a payment processing system</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent. Otherwise, the payments might be processed incorrectly.</span></p><p><strong><span>Which actions should a solutions architect take to meet this requirement? (Choose two.)</span></strong></p><p><span>A. Write the messages to an Amazon DynamoDB table with the payment ID as the partition key.</span></p><p><span>B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.</span></p><p><span>C. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key.</span></p><p><span>D. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue. Set the message attribute to use the payment ID.</span></p><p><span>E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.</span></p><p><span>E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Kinesis Data Streams</span></strong><span>:</span></p><ul><li><p><strong><span>Partition Key</span></strong><span>: By using the payment ID as the partition key, Kinesis ensures that all messages with the same payment ID are routed to the same shard, preserving the order of messages. This is crucial for applications that require strict ordering of events, such as payment processing.</span></p></li></ul></li><li><p><strong><span>Amazon SQS FIFO Queue</span></strong><span>:</span></p><ul><li><p><strong><span>FIFO Queue</span></strong><span>: SQS FIFO (First-In-First-Out) queues are designed to ensure that messages are processed in the exact order they are sent. By setting the message group ID to the payment ID, SQS FIFO queues ensure that messages with the same payment ID are processed in order.</span></p></li><li><p><strong><span>Message Group ID</span></strong><span>: The message group ID is used to group messages that should be processed in a strict order. This ensures that messages within the same group are delivered and processed in the order they were sent.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>DynamoDB (Option A)</span></strong><span>: While DynamoDB can store messages with a partition key, it does not guarantee the order of message processing, which is critical for this use case.</span></p></li><li><p><strong><span>ElastiCache for Memcached (Option C)</span></strong><span>: ElastiCache for Memcached is a caching solution and does not provide message ordering capabilities.</span></p></li><li><p><strong><span>SQS Standard Queue (Option D)</span></strong><span>: Standard SQS queues do not guarantee the order of message delivery. Therefore, they are not suitable for use cases that require strict message ordering.</span></p></li></ul></li></ol><p><span>By using Amazon Kinesis Data Streams with the payment ID as the partition key and Amazon SQS FIFO queues with the message group ID set to the payment ID, the solutions architect can ensure that messages for a particular payment ID are received and processed in the same order they were sent, meeting the requirement for the payment processing system.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-363-building-an-event-driven-system-with-guaranteed-order-of-events'><span>Question #363 Building an event-driven system with guaranteed order of events</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is building a game system that needs to send unique events to separate leaderboard, matchmaking, and authentication services concurrently. The company needs an AWS event-driven system that guarantees the order of the events. Which solution will meet these requirements?</span></p><p><span>A. Amazon EventBridge event bus</span></p><p><span>B. Amazon Simple Notification Service (Amazon SNS) FIFO topics</span></p><p><span>C. Amazon Simple Notification Service (Amazon SNS) standard topics</span></p><p><span>D. Amazon Simple Queue Service (Amazon SQS) FIFO queues</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Amazon Simple Notification Service (Amazon SNS) FIFO topics</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon SNS FIFO Topics</span></strong><span>: Amazon SNS FIFO (First-In-First-Out) topics provide the capability to publish messages to multiple subscribers while preserving the order of the messages. This ensures that the events are delivered in the exact order they were sent, which is crucial for the game system&#39;s requirement to guarantee the order of the events.</span></p></li><li><p><strong><span>Concurrent Delivery</span></strong><span>: SNS FIFO topics can deliver messages to multiple subscribers (leaderboard, matchmaking, and authentication services) concurrently, ensuring that all services receive the events in the correct order.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon EventBridge</span></strong><span>: While Amazon EventBridge is a powerful event bus that can route events to multiple targets, it does not guarantee the order of events. This solution does not meet the requirement for guaranteed order.</span></p><p><span>C. </span><strong><span>Amazon SNS Standard Topics</span></strong><span>: Standard SNS topics provide high throughput and best-effort ordering, but they do not guarantee the order of messages. This solution is not suitable for use cases where message order is critical.</span></p><p><span>D. </span><strong><span>Amazon SQS FIFO Queues</span></strong><span>: SQS FIFO queues guarantee the order of messages, but they are designed for point-to-point communication rather than fan-out scenarios where messages need to be delivered to multiple subscribers concurrently.</span></p><p><span>By using Amazon SNS FIFO topics, the company can build an event-driven system that guarantees the order of events and delivers them concurrently to the leaderboard, matchmaking, and authentication services, meeting all the requirements effectively.</span></p><p>&nbsp;</p><hr /><h3 id='question-364-ensuring-encryption-and-access-control-for-sqs-and-sns-in-a-hospital-application'><span>Question #364 Ensuring encryption and access control for SQS and SNS in a hospital application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A hospital is designing a new application that gathers symptoms from patients. The hospital has decided to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) in the architecture. A solutions architect is reviewing the infrastructure design. Data must be encrypted at rest and in transit. Only authorized personnel of the hospital should be able to access the data.</span></p><p><strong><span>Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)</span></strong></p><p><span>A. Turn on server-side encryption on the SQS components. Update the default key policy to restrict key usage to a set of authorized principals.</span></p><p><span>B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.</span></p><p><span>C. Turn on encryption on the SNS components. Update the default key policy to restrict key usage to a set of authorized principals. Set a condition in the topic policy to allow only encrypted connections over TLS.</span></p><p><span>D. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.</span></p><p><span>E. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply an IAM policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.</span></p><hr /><p><strong><span>Answers:</span></strong></p><p><span>B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.</span></p><p><span>D. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Server-Side Encryption with AWS KMS</span></strong><span>:</span></p><ul><li><p><strong><span>SQS and SNS Encryption</span></strong><span>: Turning on server-side encryption for both SQS and SNS components using an AWS KMS customer managed key ensures that data is encrypted at rest. Using a customer managed key allows for fine-grained control over key usage and management.</span></p></li><li><p><strong><span>Key Policy</span></strong><span>: Applying a key policy to restrict key usage to a set of authorized principals ensures that only authorized personnel can access the data. This policy should specify which IAM users or roles are allowed to use the key.</span></p></li></ul></li><li><p><strong><span>Encryption in Transit</span></strong><span>:</span></p><ul><li><p><strong><span>TLS Encryption</span></strong><span>: Setting a condition in the queue policy (for SQS) and the topic policy (for SNS) to allow only encrypted connections over TLS ensures that data is encrypted in transit. This prevents unauthorized access to data while it is being transmitted.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Option A</span></strong><span>: This option suggests updating the default key policy for SQS, but it does not specify the use of a customer managed key or conditions for TLS encryption.</span></p></li><li><p><strong><span>Option C</span></strong><span>: This option suggests turning on encryption for SNS and updating the default key policy, but it does not specify the use of a customer managed key for SQS.</span></p></li><li><p><strong><span>Option E</span></strong><span>: This option suggests using an IAM policy to restrict key usage, but key policies are more appropriate for managing access to KMS keys.</span></p></li></ul></li></ol><p><span>By turning on server-side encryption for both SQS and SNS using AWS KMS customer managed keys, applying key policies to restrict key usage, and setting conditions for TLS encryption, the solutions architect can ensure that data is encrypted at rest and in transit, and that only authorized personnel can access the data. This approach meets the hospital&#39;s requirements with a comprehensive and secure solution.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-365-ensuring-the-ability-to-restore-an-amazon-rds-database-to-a-previous-state'><span>Question #365 Ensuring the ability to restore an Amazon RDS database to a previous state</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs a web application that is backed by Amazon RDS. A new database administrator caused data loss by accidentally editing information in a database table. To help recover from this type of incident, the company wants the ability to restore the database to its state from 5 minutes before any change within the last 30 days. Which feature should the solutions architect include in the design to meet this requirement?</span></p><p><span>A. Read replicas</span></p><p><span>B. Manual snapshots</span></p><p><span>C. Automated backups</span></p><p><span>D. Multi-AZ deployments</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Automated backups</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Automated Backups</span></strong><span>: Amazon RDS automated backups enable point-in-time recovery for your DB instance. This feature allows you to restore your database to any specific point in time during your retention period, up to a maximum of 35 days. This means you can recover your database to its state from 5 minutes before any change within the last 30 days, which meets the company&#39;s requirement.</span></p></li><li><p><strong><span>Point-in-Time Recovery</span></strong><span>: With automated backups, Amazon RDS continuously backs up your database and transaction logs. This allows you to perform point-in-time recovery, where you can restore the database to any second during the backup retention period.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Read Replicas</span></strong><span>: Read replicas are used to offload read traffic from the primary database instance and improve read scalability. They do not provide the ability to restore the database to a previous state.</span></p><p><span>B. </span><strong><span>Manual Snapshots</span></strong><span>: Manual snapshots are taken at a specific point in time and can be used to restore the database to that specific state. However, they do not provide continuous backups or the ability to restore to any point in time within the last 30 days.</span></p><p><span>D. </span><strong><span>Multi-AZ Deployments</span></strong><span>: Multi-AZ deployments provide high availability and failover support for Amazon RDS. While they improve fault tolerance, they do not provide the ability to restore the database to a previous state.</span></p><p><span>By including automated backups in the design, the company can ensure the ability to restore the Amazon RDS database to its state from 5 minutes before any change within the last 30 days, effectively meeting the requirement for data recovery.</span></p><p>&nbsp;</p><hr /><h3 id='question-366-controlling-access-to-premium-content-in-a-web-application'><span>Question #366 Controlling access to premium content in a web application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company&#39;s web application consists of an Amazon API Gateway API in front of an AWS Lambda function and an Amazon DynamoDB database. The Lambda function handles the business logic, and the DynamoDB table hosts the data. The application uses Amazon Cognito user pools to identify the individual users of the application. A solutions architect needs to update the application so that only users who have a subscription can access premium content.</span></p><p><strong><span>Which solution will meet this requirement with the LEAST operational overhead?</span></strong></p><p><span>A. Enable API caching and throttling on the API Gateway API.</span></p><p><span>B. Set up AWS WAF on the API Gateway API. Create a rule to filter users who have a subscription.</span></p><p><span>C. Apply fine-grained IAM permissions to the premium content in the DynamoDB table.</span></p><p><span>D. Implement API usage plans and API keys to limit the access of users who do not have a subscription.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Implement API usage plans and API keys to limit the access of users who do not have a subscription.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>API Usage Plans and API Keys</span></strong><span>:</span></p><ul><li><p><strong><span>Subscription Control</span></strong><span>: Implementing API usage plans and API keys allows you to control access to the API based on the user&#39;s subscription status. You can create different usage plans for different levels of access, such as free and premium.</span></p></li><li><p><strong><span>Low Operational Overhead</span></strong><span>: This approach integrates directly with API Gateway and requires minimal changes to the existing application logic. It leverages built-in API Gateway features to manage access without the need for additional infrastructure or complex configurations.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>API Caching and Throttling (Option A)</span></strong><span>: Enabling API caching and throttling helps manage API performance and protect against misuse, but it does not address the requirement to restrict access based on subscription status.</span></p></li><li><p><strong><span>AWS WAF (Option B)</span></strong><span>: AWS WAF is a web application firewall that can filter traffic based on rules. While it can be used to block or allow traffic, it is not the most straightforward solution for managing user subscriptions and would require more complex rule configurations.</span></p></li><li><p><strong><span>Fine-Grained IAM Permissions (Option C)</span></strong><span>: Applying fine-grained IAM permissions to DynamoDB is a more granular approach but involves managing IAM policies and roles for each user, which can be complex and operationally intensive.</span></p></li></ul></li></ol><p><span>By implementing API usage plans and API keys, the solutions architect can effectively control access to premium content based on user subscriptions with minimal operational overhead. This approach leverages API Gateway&#39;s built-in features for managing access and provides a scalable and maintainable solution.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-367-improving-performance-and-availability-for-a-udp-based-application-with-compliance-requirements'><span>Question #367 Improving performance and availability for a UDP-based application with compliance requirements</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is using Amazon Route 53 latency-based routing to route requests to its UDP-based application for users around the world. The application is hosted on redundant servers in the company&#39;s on-premises data centers in the United States, Asia, and Europe. The company&#39;s compliance requirements state that the application must be hosted on premises. The company wants to improve the performance and availability of the application. What should a solutions architect do to meet these requirements?</span></p><p><span>A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.</span></p><p><span>B. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.</span></p><p><span>C. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.</span></p><p><span>D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Global Accelerator</span></strong><span>: AWS Global Accelerator improves the availability and performance of your applications with global users by using the AWS global network. It provides static IP addresses that act as a fixed entry point to your application endpoints, such as Network Load Balancers (NLBs).</span></p></li><li><p><strong><span>Network Load Balancers (NLBs)</span></strong><span>: NLBs are designed to handle large volumes of traffic and can handle both TCP and UDP traffic, which makes them suitable for the company&#39;s UDP-based application.</span></p></li><li><p><strong><span>Latency-Based Routing</span></strong><span>: AWS Global Accelerator automatically routes traffic to the nearest and best-performing endpoint based on latency, which improves the performance for global users.</span></p></li><li><p><strong><span>Compliance Requirements</span></strong><span>: By using NLBs to address the on-premises endpoints and registering them with AWS Global Accelerator, the company can ensure that the application remains hosted on-premises while leveraging AWS infrastructure to improve performance and availability.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Application Load Balancers (ALBs)</span></strong><span>: ALBs are designed for HTTP and HTTPS traffic and do not support UDP traffic. Therefore, they are not suitable for the company&#39;s UDP-based application.</span></p><p><span>C. </span><strong><span>Route 53 and CloudFront</span></strong><span>: While Route 53 latency-based routing can direct traffic based on latency, using CloudFront as an origin for a UDP-based application is not appropriate since CloudFront is designed for HTTP/HTTPS traffic and does not support UDP.</span></p><p><span>D. </span><strong><span>Application Load Balancers (ALBs) and CloudFront</span></strong><span>: Similar to option B, ALBs do not support UDP traffic. Additionally, CloudFront does not support UDP, making this option unsuitable for the company&#39;s requirements.</span></p><p><span>By configuring Network Load Balancers in the three AWS Regions and using AWS Global Accelerator, the company can improve the performance and availability of its UDP-based application while ensuring compliance with the requirement to host the application on-premises.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-368-enforcing-password-complexity-and-rotation-for-iam-user-passwords'><span>Question #368 Enforcing password complexity and rotation for IAM user passwords</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords.</span></p><p><strong><span>What should the solutions architect do to accomplish this?</span></strong></p><p><span>A. Set an overall password policy for the entire AWS account.</span></p><p><span>B. Set a password policy for each IAM user in the AWS account.</span></p><p><span>C. Use third-party vendor software to set password requirements.</span></p><p><span>D. Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Set an overall password policy for the entire AWS account.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Overall Password Policy</span></strong><span>:</span></p><ul><li><p><strong><span>Centralized Management</span></strong><span>: Setting an overall password policy for the entire AWS account ensures that all IAM users adhere to the same complexity requirements and mandatory rotation periods. This approach provides a centralized and consistent way to enforce security policies.</span></p></li><li><p><strong><span>Ease of Implementation</span></strong><span>: AWS allows you to configure account-wide password policies directly in the IAM console. This includes setting requirements for password length, complexity (e.g., requiring numbers, symbols, and uppercase letters), and rotation periods.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Password Policy for Each IAM User (Option B)</span></strong><span>: Setting a password policy for each IAM user individually would be cumbersome and error-prone, as it requires manual configuration for each user.</span></p></li><li><p><strong><span>Third-Party Vendor Software (Option C)</span></strong><span>: Using third-party software adds unnecessary complexity and cost, given that AWS provides built-in capabilities to manage password policies.</span></p></li><li><p><strong><span>CloudWatch Rule (Option D)</span></strong><span>: Attaching a CloudWatch rule to the Create_newuser event to set the password requirements is not the most straightforward or efficient approach. AWS IAM already provides the necessary tools to enforce password policies without the need for custom event-driven automation.</span></p></li></ul></li></ol><p><span>By setting an overall password policy for the entire AWS account, the solutions architect can ensure that all new users comply with the specified complexity requirements and mandatory rotation periods, achieving the desired security posture with minimal effort.</span></p><p>&nbsp;</p><hr /><h3 id='question-369-improving-performance-and-scalability-for-scheduled-tasks-on-ec2-instances'><span>Question #369 Improving performance and scalability for scheduled tasks on EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has migrated an application to Amazon EC2 Linux instances. One of these EC2 instances runs several 1-hour tasks on a schedule. These tasks were written by different teams and have no common programming language. The company is concerned about performance and scalability while these tasks run on a single instance. A solutions architect needs to implement a solution to resolve these concerns. Which solution will meet these requirements with the LEAST operational overhead?</span></p><p><span>A. Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).</span></p><p><span>B. Convert the EC2 instance to a container. Use AWS App Runner to create the container on demand to run the tasks as jobs.</span></p><p><span>C. Copy the tasks into AWS Lambda functions. Schedule the Lambda functions by using Amazon EventBridge (Amazon CloudWatch Events).</span></p><p><span>D. Create an Amazon Machine Image (AMI) of the EC2 instance that runs the tasks. Create an Auto Scaling group with the AMI to run multiple copies of the instance.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Batch</span></strong><span>: AWS Batch is a fully managed service that enables you to run batch computing workloads on the AWS Cloud. It efficiently provisions and scales the optimal quantity and type of compute resources based on the volume and specific resource requirements of the batch jobs submitted. AWS Batch supports a wide variety of programming languages, making it suitable for running tasks written by different teams.</span></p></li><li><p><strong><span>EventBridge (CloudWatch Events)</span></strong><span>: Amazon EventBridge (formerly CloudWatch Events) can be used to schedule AWS Batch jobs. This allows you to run the tasks on a schedule without needing to manage the underlying infrastructure.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: AWS Batch abstracts the complexity of provisioning, managing, and scaling compute resources, reducing the operational overhead. It ensures that the tasks are run efficiently and can scale as needed.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>AWS App Runner</span></strong><span>: AWS App Runner is designed for running web applications and APIs. While it can run containers, it may not be the best fit for running scheduled batch tasks, and setting up the container environment may introduce additional operational overhead.</span></p><p><span>C. </span><strong><span>AWS Lambda</span></strong><span>: Lambda functions are suitable for short-lived, event-driven tasks with a maximum execution time of 15 minutes. Since the tasks run for 1 hour, Lambda is not suitable for this use case.</span></p><p><span>D. </span><strong><span>Auto Scaling Group with AMI</span></strong><span>: Creating an Auto Scaling group with an AMI to run multiple copies of the instance introduces additional complexity in managing the instances and ensuring that the tasks are distributed and executed correctly. This approach also does not address the need for efficient scheduling and scaling of tasks.</span></p><p><span>By using AWS Batch to run the tasks as jobs and scheduling them with Amazon EventBridge, the company can achieve the required performance and scalability with the least operational overhead, while supporting tasks written in different programming languages.</span></p><p>&nbsp;</p><hr /><h3 id='question-370-enabling-internet-communication-for-ec2-instances-in-private-subnets'><span>Question #370 Enabling internet communication for EC2 instances in private subnets</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs a public three-tier web application in a VPC. The application runs on Amazon EC2 instances across multiple Availability Zones. The EC2 instances that run in private subnets need to communicate with a license server over the internet. The company needs a managed solution that minimizes operational maintenance.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><span>A. Provision a NAT instance in a public subnet. Modify each private subnet&#39;s route table with a default route that points to the NAT instance.</span></p><p><span>B. Provision a NAT instance in a private subnet. Modify each private subnet&#39;s route table with a default route that points to the NAT instance.</span></p><p><span>C. Provision a NAT gateway in a public subnet. Modify each private subnet&#39;s route table with a default route that points to the NAT gateway.</span></p><p><span>D. Provision a NAT gateway in a private subnet. Modify each private subnet&#39;s route table with a default route that points to the NAT gateway.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Provision a NAT gateway in a public subnet. Modify each private subnet&#39;s route table with a default route that points to the NAT gateway.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>NAT Gateway in a Public Subnet</span></strong><span>:</span></p><ul><li><p><strong><span>Managed Solution</span></strong><span>: A NAT gateway is a managed service provided by AWS that allows instances in a private subnet to connect to the internet while preventing the internet from initiating connections with those instances. It requires minimal operational maintenance compared to NAT instances.</span></p></li><li><p><strong><span>Public Subnet Requirement</span></strong><span>: For a NAT gateway to function correctly, it must be provisioned in a public subnet, as it needs access to the internet gateway.</span></p></li><li><p><strong><span>Route Table Configuration</span></strong><span>: The route table for each private subnet should be modified to include a default route (0.0.0.0/0) that points to the NAT gateway. This allows instances in the private subnets to route outbound traffic through the NAT gateway to the internet.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>NAT Instance in a Public Subnet (Option A)</span></strong><span>: While a NAT instance can achieve similar functionality, it requires more operational maintenance, such as instance management, scaling, and patching.</span></p></li><li><p><strong><span>NAT Instance in a Private Subnet (Option B)</span></strong><span>: A NAT instance in a private subnet would not have direct access to the internet, which is required for it to function as a NAT.</span></p></li><li><p><strong><span>NAT Gateway in a Private Subnet (Option D)</span></strong><span>: A NAT gateway in a private subnet would not be able to connect to the internet, as it requires an internet gateway, which is only accessible from a public subnet.</span></p></li></ul></li></ol><p><span>By provisioning a NAT gateway in a public subnet and modifying the private subnet&#39;s route tables to point to the NAT gateway, the company can enable internet communication for EC2 instances in private subnets with a managed solution that minimizes operational maintenance.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-371-encrypting-eks-cluster-storage-with-a-customer-managed-key'><span>Question #371 Encrypting EKS cluster storage with a customer managed key</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs to create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host a digital media streaming application. The EKS cluster will use a managed node group that is backed by Amazon Elastic Block Store (Amazon EBS) volumes for storage. The company must encrypt all data at rest by using a customer managed key that is stored in AWS Key Management Service (AWS KMS). Which combination of actions will meet this requirement with the LEAST operational overhead? (Choose two.)</span></p><p><span>A. Use a Kubernetes plugin that uses the customer managed key to perform data encryption.</span></p><p><span>B. After creation of the EKS cluster, locate the EBS volumes. Enable encryption by using the customer managed key.</span></p><p><span>C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.</span></p><p><span>D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster.</span></p><p><span>E. Store the customer managed key as a Kubernetes secret in the EKS cluster. Use the customer managed key to encrypt the EBS volumes.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.</span></p><p><span>D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Enable EBS Encryption by Default</span></strong><span>:</span></p><ul><li><p><strong><span>Action C</span></strong><span>: Enabling EBS encryption by default in the AWS Region where the EKS cluster will be created and selecting the customer managed key as the default key ensures that all newly created EBS volumes are automatically encrypted using the specified KMS key. This minimizes operational overhead as it automates the encryption process for all EBS volumes used by the EKS cluster.</span></p></li></ul></li><li><p><strong><span>IAM Role with KMS Permissions</span></strong><span>:</span></p><ul><li><p><strong><span>Action D</span></strong><span>: Creating an IAM role that has a policy granting permission to use the customer managed key and associating this role with the EKS cluster ensures that the cluster has the necessary permissions to use the KMS key for encryption. This is required to allow the EKS cluster to interact with the KMS key for encrypting and decrypting data.</span></p></li></ul></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Kubernetes Plugin</span></strong><span>: Using a Kubernetes plugin for encryption would introduce additional operational complexity and overhead. It is more efficient to leverage AWS native encryption capabilities.</span></p><p><span>B. </span><strong><span>Manual Encryption of EBS Volumes</span></strong><span>: Manually locating and enabling encryption on EBS volumes after the creation of the EKS cluster adds unnecessary operational overhead and is prone to human error. It is better to enable encryption by default.</span></p><p><span>E. </span><strong><span>Kubernetes Secret</span></strong><span>: Storing the customer managed key as a Kubernetes secret and using it to encrypt EBS volumes is not a standard practice and could lead to security and management challenges. AWS KMS and IAM roles provide a more secure and manageable approach.</span></p><p><span>By enabling EBS encryption by default and using an IAM role with permissions to the customer managed key, the company can ensure that all data at rest is encrypted with minimal operational overhead.</span></p><p>&nbsp;</p><hr /><h3 id='question-372-migrating-an-oracle-database-with-gis-images-to-aws'><span>Question #372 Migrating an Oracle database with GIS images to AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code. When a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events.</span></p><p><strong><span>Which solution meets these requirements MOST cost-effectively?</span></strong></p><p><span>A. Store the images and geographic codes in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.</span></p><p><span>B. Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value.</span></p><p><span>C. Store the images and geographic codes in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) during times of high load.</span></p><p><span>D. Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon S3 for Image Storage</span></strong><span>:</span></p><ul><li><p><strong><span>Cost-Effective Storage</span></strong><span>: Amazon S3 is a highly cost-effective solution for storing large amounts of data, such as high-resolution GIS images. It provides high durability, availability, and scalability.</span></p></li><li><p><strong><span>High Availability and Scalability</span></strong><span>: S3 is designed to handle large-scale data storage and retrieval, making it suitable for scenarios where tens of thousands of images get updated frequently.</span></p></li></ul></li><li><p><strong><span>Amazon DynamoDB for Metadata</span></strong><span>:</span></p><ul><li><p><strong><span>Key-Value Store</span></strong><span>: DynamoDB is a highly scalable and low-latency NoSQL database service. By using the geographic code as the key and the S3 URL of the image as the value, the company can efficiently manage and query the metadata associated with each image.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: DynamoDB can handle high request rates and large amounts of data, making it ideal for the high update rates during natural disasters.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Oracle on Amazon RDS (Option A and D)</span></strong><span>: Running Oracle on Amazon RDS Multi-AZ can provide high availability, but it may not be as cost-effective or scalable as using S3 and DynamoDB for this use case. Storing large images directly in a relational database can lead to increased costs and complexity.</span></p></li><li><p><strong><span>DynamoDB with DAX (Option C)</span></strong><span>: While DynamoDB with DAX can improve read performance, storing large images directly in DynamoDB is not cost-effective. S3 is better suited for storing large binary objects.</span></p></li></ul></li></ol><p><span>By storing the images in Amazon S3 and using Amazon DynamoDB to store the geographic codes and image URLs, the company can achieve a highly available and scalable solution that is also cost-effective. This approach leverages the strengths of both S3 and DynamoDB to handle large-scale data storage and high update rates efficiently.</span></p><p>&nbsp;</p><hr /><h3 id='question-373-cost-effective-storage-solution-for-iot-data-with-specific-access-requirements'><span>Question #373 Cost-effective storage solution for IoT data with specific access requirements</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has an application that collects data from IoT sensors on automobiles. The data is streamed and stored in Amazon S3 through Amazon Kinesis Data Firehose. The data produces trillions of S3 objects each year. Each morning, the company uses the data from the previous 30 days to retrain a suite of machine learning (ML) models. Four times each year, the company uses the data from the previous 12 months to perform analysis and train other ML models. The data must be available with minimal delay for up to 1 year. After 1 year, the data must be retained for archival purposes.</span></p><p><strong><span>Which storage solution meets these requirements MOST cost-effectively?</span></strong></p><p><span>A. Use the S3 Intelligent-Tiering storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.</span></p><p><span>B. Use the S3 Intelligent-Tiering storage class. Configure S3 Intelligent-Tiering to automatically move objects to S3 Glacier Deep Archive after 1 year.</span></p><p><span>C. Use the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.</span></p><p><span>D. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>S3 Standard Storage Class</span></strong><span>:</span></p><ul><li><p><strong><span>Initial Storage</span></strong><span>: Using the S3 Standard storage class for the first 30 days ensures that the data is immediately available for daily ML model retraining with minimal delay.</span></p></li></ul></li><li><p><strong><span>Transition to S3 Standard-IA</span></strong><span>:</span></p><ul><li><p><strong><span>Cost Savings</span></strong><span>: After 30 days, the data can be transitioned to S3 Standard-Infrequent Access (S3 Standard-IA), which is designed for data that is accessed less frequently but still needs to be available quickly when needed. This provides significant cost savings while ensuring that the data remains accessible for quarterly analysis and ML model training.</span></p></li></ul></li><li><p><strong><span>Transition to S3 Glacier Deep Archive</span></strong><span>:</span></p><ul><li><p><strong><span>Archival Storage</span></strong><span>: After 1 year, the data can be transitioned to S3 Glacier Deep Archive, which is the most cost-effective storage class for long-term archival. This ensures that the data is retained for compliance or future reference at the lowest possible cost.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>S3 Intelligent-Tiering (Options A and B)</span></strong><span>: While S3 Intelligent-Tiering automatically moves data between two access tiers (frequent and infrequent access) based on changing access patterns, it may not be as cost-effective as a combination of S3 Standard, S3 Standard-IA, and S3 Glacier Deep Archive for this specific use case. Additionally, S3 Intelligent-Tiering does not automatically move objects to S3 Glacier Deep Archive.</span></p></li><li><p><strong><span>S3 Standard-IA (Option C)</span></strong><span>: Starting with S3 Standard-IA may not be ideal for data that needs to be accessed frequently in the first 30 days for daily ML model retraining.</span></p></li></ul></li></ol><p><span>By using S3 Standard for the first 30 days, transitioning to S3 Standard-IA for the next 11 months, and then moving the data to S3 Glacier Deep Archive after 1 year, the company can achieve a cost-effective storage solution that meets the access and retention requirements for their IoT data.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-374-designing-a-cost-effective-network-connectivity-solution-for-vpcs-and-on-premises-data-center'><span>Question #374 Designing a cost-effective network connectivity solution for VPCs and on-premises data center</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is running several business applications in three separate VPCs within the us-east-1 Region. The applications must be able to communicate between VPCs. The applications also must be able to consistently send hundreds of gigabytes of data each day to a latency-sensitive application that runs in a single on-premises data center. A solutions architect needs to design a network connectivity solution that maximizes cost-effectiveness. Which solution meets these requirements?</span></p><p><span>A. Configure three AWS Site-to-Site VPN connections from the data center to AWS. Establish connectivity by configuring one VPN connection for each VPC.</span></p><p><span>B. Launch a third-party virtual network appliance in each VPC. Establish an IPsec VPN tunnel between the data center and each virtual appliance.</span></p><p><span>C. Set up three AWS Direct Connect connections from the data center to a Direct Connect gateway in us-east-1. Establish connectivity by configuring each VPC to use one of the Direct Connect connections.</span></p><p><span>D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Direct Connect</span></strong><span>: Direct Connect provides a dedicated network connection from your premises to AWS. It offers consistent, low-latency performance, which is essential for latency-sensitive applications and transferring large amounts of data.</span></p></li><li><p><strong><span>Transit Gateway</span></strong><span>: AWS Transit Gateway allows you to connect multiple VPCs and on-premises networks through a single gateway. It simplifies network architecture and management by acting as a central hub for connectivity.</span></p></li><li><p><strong><span>Cost-Effectiveness</span></strong><span>: Setting up a single Direct Connect connection and using a transit gateway to connect all VPCs is more cost-effective than setting up multiple Direct Connect connections or VPN tunnels. It reduces the number of physical connections required and simplifies network management.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Three VPN Connections</span></strong><span>: Using Site-to-Site VPN connections for each VPC would introduce higher latency and potential performance issues compared to Direct Connect. VPN connections also incur additional costs for each connection and may not handle the required data volume efficiently.</span></p><p><span>B. </span><strong><span>Third-Party Virtual Network Appliance</span></strong><span>: Launching virtual network appliances in each VPC and establishing IPsec VPN tunnels adds complexity and operational overhead. It may also result in higher latency and lower performance compared to Direct Connect.</span></p><p><span>C. </span><strong><span>Three Direct Connect Connections</span></strong><span>: Setting up three Direct Connect connections is unnecessary and more expensive than using a single Direct Connect connection with a transit gateway. It also adds complexity to network management.</span></p><p><span>By setting up one AWS Direct Connect connection and using a transit gateway to connect the VPCs, the company can achieve the required low-latency, high-throughput connectivity between the VPCs and the on-premises data center in a cost-effective manner.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-375-designing-a-distributed-order-processing-application-with-minimal-operational-overhead'><span>Question #375 Designing a distributed order-processing application with minimal operational overhead</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An ecommerce company is building a distributed application that involves several serverless functions and AWS services to complete order-processing tasks. These tasks require manual approvals as part of the workflow. A solutions architect needs to design an architecture for the order-processing application. The solution must be able to combine multiple AWS Lambda functions into responsive serverless applications. The solution also must orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers.</span></p><p><strong><span>Which solution will meet these requirements with the LEAST operational overhead?</span></strong></p><p><span>A. Use AWS Step Functions to build the application.</span></p><p><span>B. Integrate all the application components in an AWS Glue job.</span></p><p><span>C. Use Amazon Simple Queue Service (Amazon SQS) to build the application.</span></p><p><span>D. Use AWS Lambda functions and Amazon EventBridge events to build the application.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Use AWS Step Functions to build the application.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Step Functions</span></strong><span>:</span></p><ul><li><p><strong><span>Orchestration</span></strong><span>: AWS Step Functions is a fully managed service that makes it easy to coordinate multiple AWS services into serverless workflows. It can orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers, making it ideal for complex workflows like order processing.</span></p></li><li><p><strong><span>Manual Approvals</span></strong><span>: Step Functions supports human interaction steps through the integration of Amazon SNS or Amazon SQS, which can be used to send notifications for manual approvals.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: Step Functions abstracts much of the complexity involved in building and managing workflows, providing a visual interface to design and monitor workflows, and handling retries, parallel execution, and error handling automatically.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Glue (Option B)</span></strong><span>: AWS Glue is primarily designed for ETL (extract, transform, load) jobs and is not suitable for orchestrating complex, stateful workflows involving manual approvals and multiple types of AWS services.</span></p></li><li><p><strong><span>Amazon SQS (Option C)</span></strong><span>: While SQS can be used for message queuing and decoupling components, it does not provide the orchestration capabilities required to build and manage complex workflows with manual approvals.</span></p></li><li><p><strong><span>AWS Lambda and EventBridge (Option D)</span></strong><span>: While Lambda functions and EventBridge can be used to build event-driven applications, they do not provide the same level of workflow orchestration and state management as AWS Step Functions. This approach would require more custom code and operational overhead to manage the workflow.</span></p></li></ul></li></ol><p><span>By using AWS Step Functions, the solutions architect can build a distributed order-processing application that combines multiple serverless functions and other AWS services with minimal operational overhead. Step Functions provides the necessary orchestration capabilities, including support for manual approvals, making it the most suitable solution for this use case.</span></p><p>&nbsp;</p><hr /><h3 id='question-376-resolving-database-connection-rejection-errors-for-amazon-rds-for-mysql'><span>Question #376 Resolving database connection rejection errors for Amazon RDS for MySQL</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has launched an Amazon RDS for MySQL DB instance. Most of the connections to the database come from serverless applications. Application traffic to the database changes significantly at random intervals. At times of high demand, users report that their applications experience database connection rejection errors. Which solution will resolve this issue with the LEAST operational overhead?</span></p><p><span>A. Create a proxy in RDS Proxy. Configure the users&#39; applications to use the DB instance through RDS Proxy.</span></p><p><span>B. Deploy Amazon ElastiCache for Memcached between the users&#39; applications and the DB instance.</span></p><p><span>C. Migrate the DB instance to a different instance class that has higher I/O capacity. Configure the users&#39; applications to use the new DB instance.</span></p><p><span>D. Configure Multi-AZ for the DB instance. Configure the users&#39; applications to switch between the DB instances.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Create a proxy in RDS Proxy. Configure the users&#39; applications to use the DB instance through RDS Proxy.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon RDS Proxy</span></strong><span>: RDS Proxy is a fully managed, highly available database proxy for Amazon RDS that makes applications more scalable, more resilient to database failures, and more secure. It pools and shares database connections to improve the efficiency of database connections.</span></p></li><li><p><strong><span>Handling Connection Spikes</span></strong><span>: RDS Proxy can handle unpredictable workloads and sudden spikes in traffic by pooling connections and reusing them efficiently. This reduces the overhead of establishing new connections and helps prevent connection rejection errors.</span></p></li><li><p><strong><span>Least Operational Overhead</span></strong><span>: Implementing RDS Proxy requires minimal changes to the application code (just updating the database endpoint to use the proxy). It provides a managed solution with automatic scaling and failover capabilities, reducing the need for manual intervention and operational overhead.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>ElastiCache for Memcached</span></strong><span>: While caching can improve read performance and reduce the load on the database, it does not address the issue of connection management and rejection errors due to high demand.</span></p><p><span>C. </span><strong><span>Migrating to a Higher I/O Instance Class</span></strong><span>: Upgrading the instance class may temporarily alleviate performance issues, but it does not address the underlying problem of connection management. Additionally, it may lead to higher costs and does not scale automatically with demand.</span></p><p><span>D. </span><strong><span>Multi-AZ Configuration</span></strong><span>: Multi-AZ deployments improve availability and failover capabilities but do not solve the problem of connection management and rejection errors. Multi-AZ is more focused on high availability and disaster recovery.</span></p><p><span>By using RDS Proxy, the company can efficiently manage database connections, handle fluctuating traffic patterns, and reduce connection rejection errors with the least operational overhead.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-377-ensuring-ec2-instances-report-to-an-auditing-system-upon-launch-and-termination'><span>Question #377 Ensuring EC2 instances report to an auditing system upon launch and termination</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated. Which solution achieves these goals MOST efficiently?</span></p><p><span>A. Use a scheduled AWS Lambda function and run a script remotely on all EC2 instances to send data to the audit system.</span></p><p><span>B. Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.</span></p><p><span>C. Use an EC2 Auto Scaling launch configuration to run a custom script through user data to send data to the audit system when instances are launched and terminated.</span></p><p><span>D. Run a custom script on the instance operating system to send data to the audit system. Configure the script to be invoked by the EC2 Auto Scaling group when the instance starts and is terminated.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>EC2 Auto Scaling Lifecycle Hooks</span></strong><span>: Lifecycle hooks allow you to perform custom actions as instances launch or terminate. By using lifecycle hooks, you can ensure that custom scripts are executed at specific points in the instance lifecycle, providing a reliable mechanism for reporting to the auditing system.</span></p></li><li><p><strong><span>Custom Script Execution</span></strong><span>: With lifecycle hooks, you can run a custom script that sends necessary data to the auditing system when an instance is launched and before it is terminated. This ensures that the auditing system receives the required information at both critical points.</span></p></li><li><p><strong><span>Efficiency and Reliability</span></strong><span>: Lifecycle hooks are designed to integrate seamlessly with the Auto Scaling process, making them an efficient and reliable solution for executing custom actions without additional overhead.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Scheduled AWS Lambda Function</span></strong><span>: Running a script remotely on all EC2 instances using a scheduled Lambda function may not guarantee immediate reporting upon instance launch and termination. It also introduces additional complexity and potential delays.</span></p><p><span>C. </span><strong><span>User Data Script</span></strong><span>: Using a launch configuration with user data to run a custom script only addresses the instance launch scenario and does not handle instance termination. Additionally, user data scripts may not be the most efficient way to ensure timely reporting.</span></p><p><span>D. </span><strong><span>Custom Script Invocation by Auto Scaling Group</span></strong><span>: While running a custom script on the instance operating system can work, configuring the script to be invoked by the Auto Scaling group for both start and termination events adds complexity. Lifecycle hooks provide a more straightforward and integrated solution.</span></p><p><span>By using EC2 Auto Scaling lifecycle hooks, the company can efficiently ensure that all instances report to the auditing system upon launch and termination, meeting the requirement with minimal operational overhead.</span></p><p>&nbsp;</p><hr /><h3 id='question-378-scalable-solution-for-a-real-time-multiplayer-game-with-udp-communication'><span>Question #378 Scalable solution for a real-time multiplayer game with UDP communication</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is developing a real-time multiplayer game that uses UDP for communications between the client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention.</span></p><p><strong><span>Which solution should a solutions architect recommend?</span></strong></p><p><span>A. Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage.</span></p><p><span>B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.</span></p><p><span>C. Use a Network Load Balancer for traffic distribution and Amazon Aurora Global Database for data storage.</span></p><p><span>D. Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Network Load Balancer (NLB)</span></strong><span>:</span></p><ul><li><p><strong><span>UDP Traffic Handling</span></strong><span>: A Network Load Balancer is designed to handle high volumes of traffic and supports both TCP and UDP protocols. Since the game uses UDP for communication, an NLB is the appropriate choice for traffic distribution.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: NLB can automatically scale to handle spikes in demand, ensuring that the game servers can adapt to varying loads throughout the day.</span></p></li></ul></li><li><p><strong><span>Amazon DynamoDB On-Demand</span></strong><span>:</span></p><ul><li><p><strong><span>Non-Relational Data Storage</span></strong><span>: DynamoDB is a fully managed NoSQL database service that is well-suited for storing non-relational data such as gamer scores.</span></p></li><li><p><strong><span>Automatic Scaling</span></strong><span>: DynamoDB on-demand mode automatically scales to accommodate the application&#39;s throughput and storage needs, eliminating the need for manual intervention. This ensures that the database can handle spikes in traffic without performance degradation.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon Route 53 and Aurora Serverless (Option A)</span></strong><span>: Route 53 is a DNS service and is not suitable for load balancing UDP traffic. Aurora Serverless is a relational database, which may not be ideal for storing non-relational data such as gamer scores.</span></p></li><li><p><strong><span>NLB and Aurora Global Database (Option C)</span></strong><span>: While NLB is suitable for UDP traffic, Aurora Global Database is a relational database and may not be the best fit for non-relational data storage.</span></p></li><li><p><strong><span>Application Load Balancer and DynamoDB Global Tables (Option D)</span></strong><span>: An Application Load Balancer (ALB) does not support UDP traffic, making it unsuitable for this use case. DynamoDB global tables are useful for multi-region replication but may not be necessary if the primary requirement is automatic scaling.</span></p></li></ul></li></ol><p><span>By using a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage, the solutions architect can ensure that the game server platform can handle UDP traffic and dynamically scale to meet varying demand with minimal operational overhead. This solution meets the requirements for real-time communication and scalable non-relational data storage.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-379-reducing-response-latency-for-a-lambda-function-connected-to-an-rds-database'><span>Question #379 Reducing response latency for a Lambda function connected to an RDS database</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a frontend application that uses an Amazon API Gateway API backend that is integrated with AWS Lambda. When the API receives requests, the Lambda function loads many libraries. Then the Lambda function connects to an Amazon RDS database, processes the data, and returns the data to the frontend application. The company wants to ensure that response latency is as low as possible for all its users with the fewest number of changes to the company&#39;s operations. Which solution will meet these requirements?</span></p><p><span>A. Establish a connection between the frontend application and the database to make queries faster by bypassing the API.</span></p><p><span>B. Configure provisioned concurrency for the Lambda function that handles the requests.</span></p><p><span>C. Cache the results of the queries in Amazon S3 for faster retrieval of similar datasets.</span></p><p><span>D. Increase the size of the database to increase the number of connections Lambda can establish at one time.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Configure provisioned concurrency for the Lambda function that handles the requests.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Provisioned Concurrency</span></strong><span>: AWS Lambda&#39;s provisioned concurrency ensures that your function is prepared to handle a certain number of requests with very low latency. When provisioned concurrency is enabled, AWS Lambda keeps the specified number of instances of your function initialized and ready to respond immediately. This helps to reduce the cold start latency, which can be significant when the Lambda function loads many libraries.</span></p></li><li><p><strong><span>Minimal Operational Changes</span></strong><span>: Configuring provisioned concurrency involves minimal changes to the existing setup. It does not require modifications to the application architecture or database configuration, making it the least disruptive option.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Bypassing the API</span></strong><span>: Establishing a direct connection between the frontend application and the database bypasses the API Gateway and Lambda, which could lead to security and scalability issues. It also involves significant changes to the application architecture.</span></p><p><span>C. </span><strong><span>Caching Results in Amazon S3</span></strong><span>: Caching query results in Amazon S3 may help in some cases, but it introduces additional complexity in managing the cache and ensuring data consistency. It also does not address the cold start latency issue of the Lambda function.</span></p><p><span>D. </span><strong><span>Increasing Database Size</span></strong><span>: Increasing the size of the database to handle more connections may help with database performance, but it does not address the Lambda cold start latency. Additionally, it may lead to increased costs and does not guarantee lower response latency.</span></p><p><span>By configuring provisioned concurrency for the Lambda function, the company can ensure that the function is always ready to handle requests with minimal latency, thereby improving the overall response time for the frontend application with minimal operational changes.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-380-automating-start-and-stop-of-ec2-and-rds-instances-to-minimize-cost'><span>Question #380 Automating start and stop of EC2 and RDS instances to minimize cost</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance.</span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Scale the EC2 instances by using elastic resize. Scale the DB instances to zero outside of business hours.</span></p><p><span>B. Explore AWS Marketplace for partner solutions that will automatically start and stop the EC2 instances and DB instances on a schedule.</span></p><p><span>C. Launch another EC2 instance. Configure a crontab schedule to run shell scripts that will start and stop the existing EC2 instances and DB instances on a schedule.</span></p><p><span>D. Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Lambda and Amazon EventBridge</span></strong><span>:</span></p><ul><li><p><strong><span>Serverless Solution</span></strong><span>: Using AWS Lambda for this task eliminates the need to manage additional infrastructure, aligning with the requirement to minimize infrastructure maintenance.</span></p></li><li><p><strong><span>Scheduled Events</span></strong><span>: Amazon EventBridge (formerly CloudWatch Events) can be used to create scheduled events that trigger the Lambda function at specified times, such as outside business hours. This provides a cost-effective and automated way to start and stop instances.</span></p></li><li><p><strong><span>Cost Efficiency</span></strong><span>: This approach ensures that you only pay for the Lambda function execution time and the minimal cost associated with EventBridge, which is highly cost-effective compared to running additional EC2 instances.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Elastic Resize and Scaling to Zero (Option A)</span></strong><span>: EC2 instances cannot be scaled to zero, and while RDS instances can be stopped, this option does not provide a comprehensive solution for both EC2 and RDS instances.</span></p></li><li><p><strong><span>AWS Marketplace Solutions (Option B)</span></strong><span>: While there are partner solutions available in the AWS Marketplace, they may introduce additional costs and complexity compared to a native AWS solution.</span></p></li><li><p><strong><span>Crontab on EC2 (Option C)</span></strong><span>: Launching another EC2 instance to manage the scheduling introduces unnecessary infrastructure and cost. Additionally, managing crontab schedules and shell scripts adds operational overhead.</span></p></li></ul></li></ol><p><span>By creating an AWS Lambda function and using Amazon EventBridge to invoke it on a schedule, the company can automatically start and stop EC2 instances and RDS DB instances outside of business hours with minimal cost and infrastructure maintenance. This solution leverages serverless technologies to achieve the desired automation efficiently.</span></p><hr /><h3 id='question-381-speeding-up-the-reporting-process-for-a-postgresql-database-with-minimal-changes-to-application-code'><span>Question #381 Speeding up the reporting process for a PostgreSQL database with minimal changes to application code</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a three-tier web application that includes a PostgreSQL database. The database stores the metadata from documents. The company searches the metadata for key terms to retrieve documents that the company reviews in a report each month. The documents are stored in Amazon S3. The documents are usually written only once, but they are updated frequently. The reporting process takes a few hours with the use of relational queries. The reporting process must not prevent any document modifications or the addition of new documents. A solutions architect needs to implement a solution to speed up the reporting process. Which solution will meet these requirements with the LEAST amount of change to the application code?</span></p><p><span>A. Set up a new Amazon DocumentDB (with MongoDB compatibility) cluster that includes a read replica. Scale the read replica to generate the reports.</span></p><p><span>B. Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.</span></p><p><span>C. Set up a new Amazon RDS for PostgreSQL Multi-AZ DB instance. Configure the reporting module to query the secondary RDS node so that the reporting module does not affect the primary node.</span></p><p><span>D. Set up a new Amazon DynamoDB table to store the documents. Use a fixed write capacity to support new document entries. Automatically scale the read capacity to support the reports.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Aurora PostgreSQL with Aurora Replica</span></strong><span>: Amazon Aurora is a fully managed relational database that is compatible with PostgreSQL. Aurora Replicas can be used to offload read traffic from the primary instance, which is ideal for running intensive reporting queries without impacting the primary database&#39;s performance.</span></p></li><li><p><strong><span>Minimal Changes to Application Code</span></strong><span>: By using Aurora PostgreSQL, the existing application code that interacts with the PostgreSQL database will require minimal changes. The reporting module can be directed to query the Aurora Replica, ensuring that the reporting process does not interfere with the primary database operations.</span></p></li><li><p><strong><span>Performance and Scalability</span></strong><span>: Aurora is designed for high performance and scalability, making it suitable for handling large volumes of read queries efficiently. Aurora Replicas can be scaled as needed to meet the reporting demands.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Amazon DocumentDB</span></strong><span>: DocumentDB is a NoSQL database compatible with MongoDB. Migrating to DocumentDB would require significant changes to the application code and data model, which is not aligned with the requirement of minimal changes.</span></p><p><span>C. </span><strong><span>RDS Multi-AZ</span></strong><span>: RDS Multi-AZ deployments provide high availability and failover support but do not allow read queries on the secondary node. Therefore, this option does not meet the requirement to offload read queries for reporting.</span></p><p><span>D. </span><strong><span>Amazon DynamoDB</span></strong><span>: DynamoDB is a NoSQL database, and migrating to it would require significant changes to the application code and data model. It is not designed for relational queries, which are essential for the reporting process.</span></p><p><span>By setting up an Amazon Aurora PostgreSQL DB cluster with an Aurora Replica, the company can speed up the reporting process with minimal changes to the application code, ensuring that document modifications and new additions are not affected.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-382-improving-security-of-data-in-transit-for-a-three-tier-application'><span>Question #382 Improving security of data in transit for a three-tier application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a three-tier application on AWS that ingests sensor data from its users&#39; devices. The traffic flows through a Network Load Balancer (NLB), then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier. The application tier makes calls to a database.</span></p><p><strong><span>What should a solutions architect do to improve the security of the data in transit?</span></strong></p><p><span>A. Configure a TLS listener. Deploy the server certificate on the NLB.</span></p><p><span>B. Configure AWS Shield Advanced. Enable AWS WAF on the NLB.</span></p><p><span>C. Change the load balancer to an Application Load Balancer (ALB). Enable AWS WAF on the ALB.</span></p><p><span>D. Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances by using AWS Key Management Service (AWS KMS).</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Configure a TLS listener. Deploy the server certificate on the NLB.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>TLS Listener on Network Load Balancer</span></strong><span>:</span></p><ul><li><p><strong><span>Data in Transit Encryption</span></strong><span>: Configuring a TLS listener on the Network Load Balancer (NLB) and deploying the server certificate ensures that all data in transit between the clients and the NLB is encrypted. This is crucial for securing sensitive data as it travels over the network.</span></p></li><li><p><strong><span>End-to-End Encryption</span></strong><span>: By terminating TLS at the NLB, you can ensure that the data is encrypted from the user&#39;s device to the NLB. You can also re-encrypt the traffic between the NLB and the EC2 instances if needed, ensuring end-to-end encryption.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Shield Advanced and WAF (Option B)</span></strong><span>: While AWS Shield Advanced and AWS WAF provide protection against DDoS attacks and web application threats, they do not directly address the encryption of data in transit.</span></p></li><li><p><strong><span>Application Load Balancer and WAF (Option C)</span></strong><span>: Changing to an Application Load Balancer (ALB) and enabling AWS WAF can provide additional security features, but it is not necessary for improving data in transit encryption specifically. The NLB with a TLS listener can achieve the required encryption.</span></p></li><li><p><strong><span>EBS Volume Encryption (Option D)</span></strong><span>: Encrypting the Amazon Elastic Block Store (EBS) volumes on the EC2 instances using AWS Key Management Service (KMS) secures data at rest, not data in transit. This option does not address the requirement to improve the security of data in transit.</span></p></li></ul></li></ol><p><span>By configuring a TLS listener on the NLB and deploying the server certificate, the solutions architect can ensure that the data in transit is encrypted, thereby improving the security of the data as it flows through the three-tier application. This solution directly addresses the requirement to secure data in transit.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-383-migrating-a-commercial-off-the-shelf-application-to-aws-with-existing-licenses'><span>Question #383 Migrating a commercial off-the-shelf application to AWS with existing licenses</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is planning to migrate a commercial off-the-shelf application from its on-premises data center to AWS. The software has a software licensing model using sockets and cores with predictable capacity and uptime requirements. The company wants to use its existing licenses, which were purchased earlier this year. Which Amazon EC2 pricing option is the MOST cost-effective?</span></p><p><span>A. Dedicated Reserved Hosts</span></p><p><span>B. Dedicated Hosts</span></p><p><span>C. Dedicated Reserved Instances</span></p><p><span>D. Dedicated On-Demand Instances</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Dedicated Reserved Hosts</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Dedicated Hosts</span></strong><span>: Dedicated Hosts are physical servers with EC2 instance capacity that is fully dedicated to your use. This allows you to use your existing software licenses that are bound to physical sockets and cores. </span></p></li><li><p><strong><span>Reserved Hosts</span></strong><span>: By reserving Dedicated Hosts, you can benefit from significant cost savings compared to On-Demand pricing. Reserved Hosts offer a reservation pricing model that provides a discount for committing to use the host for a one- or three-year term.</span></p></li><li><p><strong><span>Predictable Capacity and Uptime</span></strong><span>: Since the company has predictable capacity and uptime requirements, reserving Dedicated Hosts ensures that the required capacity is always available while taking advantage of cost savings.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Dedicated Hosts</span></strong><span>: While Dedicated Hosts allow you to use your existing licenses, using them without reservations (On-Demand) would be more expensive compared to Reserved Hosts.</span></p><p><span>C. </span><strong><span>Dedicated Reserved Instances</span></strong><span>: Dedicated Reserved Instances provide a reservation pricing model but do not offer the same level of control over physical sockets and cores as Dedicated Hosts, which is essential for the company&#39;s licensing model.</span></p><p><span>D. </span><strong><span>Dedicated On-Demand Instances</span></strong><span>: Dedicated On-Demand Instances provide dedicated physical servers but at a higher cost compared to Reserved Hosts. They do not offer the cost savings associated with reservations.</span></p><p><span>By choosing Dedicated Reserved Hosts, the company can use its existing licenses, ensure compliance with the licensing model, and achieve the most cost-effective solution for its predictable capacity and uptime requirements.</span></p><p>&nbsp;</p><hr /><h3 id='question-384-cost-effective-and-highly-available-storage-solution-for-ec2-instances'><span>Question #384 Cost-effective and highly available storage solution for EC2 instances</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company runs an application on Amazon EC2 Linux instances across multiple Availability Zones. The application needs a storage layer that is highly available and Portable Operating System Interface (POSIX)-compliant. The storage layer must provide maximum data durability and must be shareable across the EC2 instances. The data in the storage layer will be accessed frequently for the first 30 days and will be accessed infrequently after that time.</span></p><p><strong><span>Which solution will meet these requirements MOST cost-effectively?</span></strong></p><p><span>A. Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Glacier.</span></p><p><span>B. Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Standard-Infrequent Access (S3 Standard-IA).</span></p><p><span>C. Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).</span></p><p><span>D. Use the Amazon Elastic File System (Amazon EFS) One Zone storage class. Create a lifecycle management policy to move infrequently accessed data to EFS One Zone-Infrequent Access (EFS One Zone-IA).</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Elastic File System (EFS)</span></strong><span>:</span></p><ul><li><p><strong><span>POSIX Compliance</span></strong><span>: EFS is a fully managed, scalable, and elastic file system that is POSIX-compliant, making it suitable for applications that require a shared file system accessible from multiple EC2 instances.</span></p></li><li><p><strong><span>High Availability and Durability</span></strong><span>: EFS provides high availability and durability by storing data across multiple Availability Zones.</span></p></li><li><p><strong><span>Lifecycle Management</span></strong><span>: EFS supports lifecycle management policies that automatically move infrequently accessed files to a lower-cost storage class, such as EFS Standard-Infrequent Access (EFS Standard-IA), after a specified period (e.g., 30 days).</span></p></li></ul></li><li><p><strong><span>Cost-Effectiveness</span></strong><span>:</span></p><ul><li><p><strong><span>EFS Standard and EFS Standard-IA</span></strong><span>: Using EFS with a lifecycle management policy ensures that frequently accessed data remains in the EFS Standard storage class, while infrequently accessed data is moved to EFS Standard-IA, reducing storage costs over time.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon S3 (Options A and B)</span></strong><span>: While Amazon S3 is a cost-effective storage solution, it is not POSIX-compliant and does not provide the shared file system capabilities required for the application.</span></p></li><li><p><strong><span>EFS One Zone (Option D)</span></strong><span>: EFS One Zone storage classes provide lower-cost storage by storing data in a single Availability Zone. However, this option does not meet the requirement for high availability across multiple Availability Zones.</span></p></li></ul></li></ol><p><span>By using Amazon EFS with a lifecycle management policy to move infrequently accessed data to EFS Standard-IA, the company can achieve a highly available, durable, and POSIX-compliant storage solution that is also cost-effective. This approach ensures that the storage layer meets the application&#39;s requirements while optimizing costs based on data access patterns.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-385-configuring-security-groups-and-network-acls-for-a-vpc-design'><span>Question #385 Configuring security groups and network ACLs for a VPC design</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A solutions architect is creating a new VPC design. There are two public subnets for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web servers use only HTTPS. The solutions architect has already created a security group for the load balancer allowing port 443 from 0.0.0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks. Which additional configuration strategy should the solutions architect use to meet these requirements?</span></p><p><span>A. Create a security group for the web servers and allow port 443 from 0.0.0.0/0. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.</span></p><p><span>B. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.</span></p><p><span>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.</span></p><p><span>D. Create a network ACL for the web servers and allow port 443 from the load balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Security Groups</span></strong><span>: Security groups are stateful and provide fine-grained control over inbound and outbound traffic to AWS resources. They are suitable for defining least-privilege access policies.</span></p></li><li><p><strong><span>Least Access Required</span></strong><span>:</span></p><ul><li><p><strong><span>Web Servers</span></strong><span>: The web servers should only accept HTTPS traffic on port 443 from the load balancer. Allowing port 443 from the load balancer&#39;s security group ensures that only the load balancer can communicate with the web servers.</span></p></li><li><p><strong><span>MySQL Servers</span></strong><span>: The MySQL servers should only accept traffic on port 3306 from the web servers. Allowing port 3306 from the web servers&#39; security group ensures that only the web servers can communicate with the MySQL servers.</span></p></li></ul></li><li><p><strong><span>Network ACLs</span></strong><span>: Network ACLs are stateless and provide an additional layer of security at the subnet level. However, they are less granular compared to security groups and are typically used for broader subnet-level controls.</span></p></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Security Group for Web Servers Allowing 0.0.0.0/0</span></strong><span>: Allowing port 443 from 0.0.0.0/0 for the web servers would expose them to the public internet, violating the principle of least privilege.</span></p><p><span>B. </span><strong><span>Network ACLs for Specific Ports</span></strong><span>: Using network ACLs to control access based on ports and IP ranges is less granular and less flexible compared to using security groups. It also introduces additional complexity in managing stateful connections.</span></p><p><span>D. </span><strong><span>Network ACLs for Load Balancer and Web Servers</span></strong><span>: Similar to option B, using network ACLs for specific ports and IP ranges is less efficient and more complex compared to using security groups. Network ACLs are better suited for broader subnet-level controls rather than fine-grained resource access.</span></p><p><span>By creating security groups with specific rules for the web servers and MySQL servers, the solutions architect can ensure that each resource has the least access required to perform its tasks, meeting the company&#39;s policy requirements efficiently.</span></p><p>&nbsp;</p><hr /><h3 id='question-386-improving-backend-performance-by-reducing-frequent-identical-database-calls'><span>Question #386 Improving backend performance by reducing frequent identical database calls</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2, and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns.</span></p><p><strong><span>Which action should be taken to improve the performance of the backend?</span></strong></p><p><span>A. Implement Amazon SNS to store the database calls.</span></p><p><span>B. Implement Amazon ElastiCache to cache the large datasets.</span></p><p><span>C. Implement an RDS for MySQL read replica to cache database calls.</span></p><p><span>D. Implement Amazon Kinesis Data Firehose to stream the calls to the database.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Implement Amazon ElastiCache to cache the large datasets.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon ElastiCache</span></strong><span>:</span></p><ul><li><p><strong><span>In-Memory Caching</span></strong><span>: Amazon ElastiCache is a fully managed in-memory caching service that supports Redis and Memcached. It is designed to improve application performance by reducing the load on the database through caching frequently accessed data in memory.</span></p></li><li><p><strong><span>Performance Improvement</span></strong><span>: By caching the large datasets that are frequently requested, ElastiCache can significantly reduce the number of database queries, thus improving the overall performance of the backend tier.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon SNS (Option A)</span></strong><span>: Amazon Simple Notification Service (SNS) is a messaging service for sending notifications. It is not designed for caching database calls or improving database performance.</span></p></li><li><p><strong><span>RDS Read Replica (Option C)</span></strong><span>: While RDS read replicas can help offload read traffic from the primary database, they do not provide the same performance benefits as an in-memory cache for frequently accessed identical datasets. Read replicas are more suitable for scaling read-heavy workloads rather than caching.</span></p></li><li><p><strong><span>Amazon Kinesis Data Firehose (Option D)</span></strong><span>: Kinesis Data Firehose is a service for streaming data to destinations such as S3, Redshift, or Elasticsearch. It is not relevant for caching database calls or improving the performance of backend queries.</span></p></li></ul></li></ol><p><span>By implementing Amazon ElastiCache to cache the large datasets, the company can reduce the load on the RDS for MySQL instance and improve the performance of the backend tier. This approach leverages in-memory caching to quickly serve frequently requested data, thereby minimizing the performance slowdowns caused by repeated identical database queries.</span></p><p>&nbsp;</p><hr /><h3 id='question-387-ensuring-least-privilege-for-a-deployment-engineer-using-aws-cloudformation'><span>Question #387 Ensuring least privilege for a deployment engineer using AWS CloudFormation</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege. Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.)</span></p><p><span>A. Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.</span></p><p><span>B. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.</span></p><p><span>C. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the AdministratorAccess IAM policy attached.</span></p><p><span>D. Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.</span></p><p><span>E. Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using that IAM role.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.</span></p><p><span>E. Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using that IAM role.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Principle of Least Privilege</span></strong><span>: The principle of least privilege dictates that users should be granted only the permissions necessary to perform their job functions, and no more. This minimizes the potential impact of accidental or malicious actions.</span></p></li><li><p><strong><span>IAM User with Specific Permissions</span></strong><span>:</span></p><ul><li><p><strong><span>Action D</span></strong><span>: Creating a new IAM user for the deployment engineer and adding the IAM user to a group with a policy that allows only AWS CloudFormation actions ensures that the user has the necessary permissions to manage CloudFormation stacks without granting broader permissions that are not required for their role.</span></p></li></ul></li><li><p><strong><span>IAM Role with Specific Permissions</span></strong><span>:</span></p><ul><li><p><strong><span>Action E</span></strong><span>: Creating an IAM role with explicit permissions for the AWS CloudFormation stack and allowing the deployment engineer to assume this role ensures that permissions are tightly controlled and can be audited. The role can be configured to allow specific actions and resources, further adhering to the principle of least privilege.</span></p></li></ul></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Root User Credentials</span></strong><span>: Using root user credentials is highly discouraged as it provides unrestricted access to the AWS account and violates the principle of least privilege. It also poses a significant security risk.</span></p><p><span>B. </span><strong><span>PowerUsers IAM Policy</span></strong><span>: The PowerUsers policy grants broad permissions that include the ability to create and manage resources but excludes some administrative tasks. This policy still provides more permissions than necessary for managing CloudFormation stacks.</span></p><p><span>C. </span><strong><span>AdministratorAccess IAM Policy</span></strong><span>: The AdministratorAccess policy grants full access to all AWS services and resources, which significantly exceeds the required permissions for managing CloudFormation stacks and violates the principle of least privilege.</span></p><p><span>By creating a new IAM user with specific permissions for CloudFormation actions and defining an IAM role with explicit permissions for the CloudFormation stack, the solutions architect ensures that the deployment engineer can perform their job activities while adhering to the principle of least privilege.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-388-fixing-connectivity-issues-between-web-and-database-tiers-in-a-vpc'><span>Question #388 Fixing connectivity issues between web and database tiers in a VPC</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is deploying a two-tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information.</span></p><p><span>The web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs, security groups, and route tables are still in their default states.</span></p><p><strong><span>What should a solutions architect recommend to fix the application?</span></strong></p><p><span>A. Add an explicit rule to the private subnet&#39;s network ACL to allow traffic from the web tier&#39;s EC2 instances.</span></p><p><span>B. Add a route in the VPC route table to allow traffic between the web tier&#39;s EC2 instances and the database tier.</span></p><p><span>C. Deploy the web tier&#39;s EC2 instances and the database tier&#39;s RDS instance into two separate VPCs, and configure VPC peering.</span></p><p><span>D. Add an inbound rule to the security group of the database tier&#39;s RDS instance to allow traffic from the web tier&#39;s security group.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>D. Add an inbound rule to the security group of the database tier&#39;s RDS instance to allow traffic from the web tier&#39;s security group.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Security Groups</span></strong><span>:</span></p><ul><li><p><strong><span>Default State</span></strong><span>: In the default state, security groups are stateful and do not allow inbound traffic unless explicitly permitted. This means the RDS instance&#39;s security group needs to allow inbound traffic from the web tier&#39;s security group.</span></p></li><li><p><strong><span>Allowing Traffic</span></strong><span>: Adding an inbound rule to the security group of the RDS instance to allow traffic from the web tier&#39;s security group will enable the web tier to connect to the database.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Network ACLs (Option A)</span></strong><span>: Network ACLs are stateless and operate at the subnet level. By default, they allow all inbound and outbound traffic. Since the issue is with connectivity between instances, adjusting network ACLs is not necessary.</span></p></li><li><p><strong><span>Route Tables (Option B)</span></strong><span>: Route tables control the routing of traffic within the VPC. The default route table already allows traffic within the VPC, so no changes are needed here.</span></p></li><li><p><strong><span>Separate VPCs and VPC Peering (Option C)</span></strong><span>: Deploying instances into separate VPCs and configuring VPC peering is unnecessary and overly complex for this scenario. The issue can be resolved within the existing VPC.</span></p></li></ul></li></ol><p><span>By adding an inbound rule to the security group of the database tier&#39;s RDS instance to allow traffic from the web tier&#39;s security group, the web application will be able to connect to the database, resolving the connectivity issue. This approach directly addresses the security group configuration, which is the most likely cause of the problem.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-389-optimizing-business-reporting-queries-for-an-rds-for-mysql-db-instance'><span>Question #389 Optimizing business reporting queries for an RDS for MySQL DB instance</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has a large dataset for its online advertising business stored in an Amazon RDS for MySQL DB instance in a single Availability Zone. The company wants business reporting queries to run without impacting the write operations to the production DB instance. Which solution meets these requirements?</span></p><p><span>A. Deploy RDS read replicas to process the business reporting queries.</span></p><p><span>B. Scale out the DB instance horizontally by placing it behind an Elastic Load Balancer.</span></p><p><span>C. Scale up the DB instance to a larger instance type to handle write operations and queries.</span></p><p><span>D. Deploy the DB instance in multiple Availability Zones to process the business reporting queries.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Deploy RDS read replicas to process the business reporting queries.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>RDS Read Replicas</span></strong><span>:</span></p><ul><li><p><strong><span>Action A</span></strong><span>: Deploying RDS read replicas is an effective solution for offloading read-heavy operations, such as business reporting queries, from the primary DB instance. Read replicas are designed to handle read traffic, allowing the primary instance to focus on write operations without being impacted by read queries.</span></p></li></ul></li><li><p><strong><span>Advantages of Read Replicas</span></strong><span>:</span></p><ul><li><p><strong><span>Performance</span></strong><span>: By directing business reporting queries to the read replicas, the write operations on the primary DB instance are not affected, ensuring optimal performance for both read and write operations.</span></p></li><li><p><strong><span>Scalability</span></strong><span>: Multiple read replicas can be deployed to handle increased read traffic, providing scalability for read-heavy workloads.</span></p></li></ul></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Elastic Load Balancer</span></strong><span>: Placing the DB instance behind an Elastic Load Balancer is not applicable for RDS instances. ELB is used for distributing traffic across multiple EC2 instances, not for database instances.</span></p><p><span>C. </span><strong><span>Scaling Up the DB Instance</span></strong><span>: Scaling up the DB instance to a larger instance type may temporarily handle the increased load, but it does not separate read and write operations. This approach does not provide a long-term solution for isolating business reporting queries from write operations.</span></p><p><span>D. </span><strong><span>Multi-AZ Deployment</span></strong><span>: Deploying the DB instance in multiple Availability Zones improves availability and failover capabilities but does not provide a separate endpoint for read operations. Multi-AZ deployments are designed for high availability rather than read scaling.</span></p><p><span>By deploying RDS read replicas, the company can ensure that business reporting queries run without impacting the write operations to the production DB instance, meeting the requirements effectively.</span></p><p>&nbsp;</p><hr /><h3 id='question-390-optimizing-customer-session-management-for-an-ecommerce-application'><span>Question #390 Optimizing customer session management for an ecommerce application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company hosts a three-tier ecommerce application on a fleet of Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). All ecommerce data is stored in an Amazon RDS for MariaDB Multi-AZ DB instance. The company wants to optimize customer session management during transactions. The application must store session data durably. Which solutions will meet these requirements? (Choose two.)</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Turn on the sticky sessions feature (session affinity) on the ALB.</span></p><p><span>B. Use an Amazon DynamoDB table to store customer session information.</span></p><p><span>C. Deploy an Amazon Cognito user pool to manage user session information.</span></p><p><span>D. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.</span></p><p><span>E. Use AWS Systems Manager Application Manager in the application to manage user session information.</span></p><p><strong><span>Correct answers:</span></strong></p><p><span>A. Turn on the sticky sessions feature (session affinity) on the ALB.</span></p><p><span>D. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Sticky Sessions on ALB (Option A)</span></strong><span>: Turning on the sticky sessions feature (session affinity) on the Application Load Balancer (ALB) ensures that a user’s session is consistently routed to the same EC2 instance. This can help maintain session continuity during a user’s interaction with the application. However, while this feature helps maintain session consistency, it does not provide durable storage for session data. </span></p></li><li><p><strong><span>Amazon ElastiCache for Redis (Option D)</span></strong><span>: Deploying an Amazon ElastiCache for Redis cluster to store customer session information provides a high-performance, in-memory data store that can be configured for persistence. Redis is well-suited for session management as it offers fast access to session data and can be configured to persist data to disk, ensuring durability.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Amazon DynamoDB</span></strong><span>: While DynamoDB provides a durable and highly available solution for session management, it may not offer the same level of performance as an in-memory store like Redis for session data, which often requires low-latency access.</span></p><p><span>C. </span><strong><span>Amazon Cognito User Pool</span></strong><span>: Amazon Cognito is primarily used for managing user authentication and access, not for storing arbitrary session data durably. It does not provide the same capabilities for session management as Redis or DynamoDB.</span></p><p><span>E. </span><strong><span>AWS Systems Manager Application Manager</span></strong><span>: AWS Systems Manager Application Manager is used for managing applications and their resources. It is not designed for managing or storing user session information.</span></p><p><span>By using sticky sessions on the ALB and deploying an Amazon ElastiCache for Redis cluster, the company can ensure that customer sessions are managed effectively with both session consistency and durable storage.</span></p><hr /><p>&nbsp;</p><h3 id='question-391-backup-strategy-for-a-three-tier-stateless-web-application'><span>Question #391 Backup strategy for a three-tier stateless web application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company&#39;s recovery point objective (RPO) is 2 hours.</span></p><p><span>The backup strategy must maximize scalability and optimize resource utilization for this environment.</span></p><p><strong><span>Which solution will meet these requirements?</span></strong></p><p><span>A. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO.</span></p><p><span>B. Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO.</span></p><p><span>C. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.</span></p><p><span>D. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Web and Application Tiers</span></strong><span>:</span></p><ul><li><p><strong><span>Stateless Nature</span></strong><span>: Since the web application is stateless and does not require temporary local storage on the EC2 instances, there is no need to take EBS snapshots of the EC2 instances. Instead, retaining the latest Amazon Machine Images (AMIs) of the web and application tiers is sufficient. AMIs can be used to quickly launch new instances in the Auto Scaling group when needed.</span></p></li></ul></li><li><p><strong><span>Database Tier</span></strong><span>:</span></p><ul><li><p><strong><span>RDS Automated Backups</span></strong><span>: Enabling automated backups in Amazon RDS for PostgreSQL ensures that the database can be backed up regularly. RDS automated backups and point-in-time recovery allow you to restore the database to any point within the backup retention period, meeting the RPO of 2 hours.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>EBS Snapshots (Options A, B, and D)</span></strong><span>: Taking EBS snapshots of the EC2 instances is unnecessary for a stateless application, as the instances do not require local storage. Additionally, taking EBS snapshots every 2 hours is not optimal for resource utilization and scalability.</span></p></li><li><p><strong><span>Snapshot Lifecycle Policy (Option B)</span></strong><span>: While a snapshot lifecycle policy can automate EBS snapshots, it is not needed for stateless EC2 instances. The focus should be on retaining AMIs and managing RDS backups.</span></p></li></ul></li></ol><p><span>By retaining the latest AMIs of the web and application tiers and enabling automated backups in Amazon RDS with point-in-time recovery, the company can achieve a scalable and resource-efficient backup strategy that meets the RPO of 2 hours. This solution leverages the stateless nature of the web application and the built-in backup capabilities of Amazon RDS.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-392-configuring-security-groups-for-a-public-web-application-on-aws'><span>Question #392 Configuring security groups for a public web application on AWS</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company wants to deploy a new public web application on AWS. The application includes a web server tier that uses Amazon EC2 instances. The application also includes a database tier that uses an Amazon RDS for MySQL DB instance. The application must be secure and accessible for global customers that have dynamic IP addresses. How should a solutions architect configure the security groups to meet these requirements?</span></p><p><span>A. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers.</span></p><p><span>B. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers.</span></p><p><span>C. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the IP addresses of the customers.</span></p><p><span>D. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from 0.0.0.0/0.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Security Group for Web Servers</span></strong><span>:</span></p><ul><li><p><strong><span>Port 443 (HTTPS)</span></strong><span>: The web servers need to be accessible over HTTPS (port 443) to ensure secure communication. Allowing inbound traffic on port 443 from </span><code>0.0.0.0/0</code><span> ensures that the web servers are accessible to all users globally, regardless of their dynamic IP addresses.</span></p></li><li><p><strong><span>Security</span></strong><span>: Allowing traffic from </span><code>0.0.0.0/0</code><span> on port 443 is a common practice for public web applications to ensure they are accessible to all users.</span></p></li></ul></li><li><p><strong><span>Security Group for DB Instance</span></strong><span>:</span></p><ul><li><p><strong><span>Port 3306 (MySQL)</span></strong><span>: The database tier should only accept connections from the web server tier. Configuring the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers ensures that only the web servers can communicate with the database.</span></p></li><li><p><strong><span>Security</span></strong><span>: This approach follows the principle of least privilege by restricting database access to only the web servers, enhancing the security of the database tier.</span></p></li></ul></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Allowing Traffic from Customer IP Addresses</span></strong><span>: Configuring the security group for the web servers to allow traffic only from specific IP addresses of the customers is not practical for global customers with dynamic IP addresses. It would require constant updates to the security group rules.</span></p><p><span>C. </span><strong><span>Allowing Database Access from Customer IP Addresses</span></strong><span>: Allowing inbound traffic on port 3306 from the IP addresses of customers is a significant security risk. The database should not be directly accessible from the internet.</span></p><p><span>D. </span><strong><span>Allowing Database Access from 0.0.0.0/0</span></strong><span>: Allowing inbound traffic on port 3306 from </span><code>0.0.0.0/0</code><span> exposes the database to the entire internet, which is highly insecure and not recommended.</span></p><p><span>By configuring the security group for the web servers to allow inbound traffic on port 443 from </span><code>0.0.0.0/0</code><span> and the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers, the solutions architect ensures that the application is both secure and accessible to global customers.</span></p><hr /><h3 id='question-393-capturing-and-redacting-pii-from-audio-files-stored-in-amazon-s3'><span>Question #393 Capturing and redacting PII from audio files stored in Amazon S3</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A payment processing company records all voice communication with its customers and stores the audio files in an Amazon S3 bucket. The company needs to capture the text from the audio files. The company must remove from the text any personally identifiable information (PII) that belongs to customers.</span></p><p><strong><span>What should a solutions architect do to meet these requirements?</span></strong></p><p><span>A. Process the audio files by using Amazon Kinesis Video Streams. Use an AWS Lambda function to scan for known PII patterns.</span></p><p><span>B. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start an Amazon Textract task to analyze the call recordings.</span></p><p><span>C. Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.</span></p><p><span>D. Create an Amazon Connect contact flow that ingests the audio files with transcription turned on. Embed an AWS Lambda function to scan for known PII patterns. Use Amazon EventBridge to start the contact flow when an audio file is uploaded to the S3 bucket.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon Transcribe with PII Redaction</span></strong><span>:</span></p><ul><li><p><strong><span>Transcription and PII Redaction</span></strong><span>: Amazon Transcribe is a fully managed service that converts speech to text. It has built-in support for PII redaction, which can automatically identify and redact sensitive information from the transcriptions.</span></p></li><li><p><strong><span>Automation</span></strong><span>: By configuring an Amazon Transcribe job with PII redaction turned on and invoking it via an AWS Lambda function when an audio file is uploaded to the S3 bucket, the process can be fully automated.</span></p></li><li><p><strong><span>Storage of Redacted Text</span></strong><span>: The output of the transcription job, which includes the redacted text, can be stored in a separate S3 bucket for further processing or analysis.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon Kinesis Video Streams (Option A)</span></strong><span>: Kinesis Video Streams is designed for processing video and audio streams in real-time, but it does not natively support transcription or PII redaction.</span></p></li><li><p><strong><span>Amazon Textract (Option B)</span></strong><span>: Amazon Textract is used for extracting text and data from scanned documents, not audio files. It is not suitable for transcribing audio recordings.</span></p></li><li><p><strong><span>Amazon Connect (Option D)</span></strong><span>: Amazon Connect is a cloud contact center service and is not designed for processing pre-recorded audio files. Additionally, the proposed solution involves unnecessary complexity with EventBridge and contact flows.</span></p></li></ul></li></ol><p><span>By configuring an Amazon Transcribe transcription job with PII redaction turned on and using an AWS Lambda function to trigger the transcription when an audio file is uploaded, the company can efficiently capture the text from the audio files and ensure that any PII is removed. This solution leverages the built-in capabilities of Amazon Transcribe to meet the requirements with minimal complexity.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-394-improving-database-performance-for-an-ecommerce-web-application'><span>Question #394 Improving database performance for an ecommerce web application</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company is running a multi-tier ecommerce web application in the AWS Cloud. The application runs on Amazon EC2 instances with an Amazon RDS for MySQL Multi-AZ DB instance. Amazon RDS is configured with the latest generation DB instance with 2,000 GB of storage in a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. The database performance affects the application during periods of high demand. A database administrator analyzes the logs in Amazon CloudWatch Logs and discovers that the application performance always degrades when the number of read and write IOPS is higher than 20,000. What should a solutions architect do to improve the application performance?</span></p><p><strong><span>Options:</span></strong></p><p><span>A. Replace the volume with a magnetic volume.</span></p><p><span>B. Increase the number of IOPS on the gp3 volume.</span></p><p><span>C. Replace the volume with a Provisioned IOPS SSD (io2) volume.</span></p><p><span>D. Replace the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes.</span></p><p><strong><span>Correct answer:</span></strong></p><p><span>D. Replace the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Replacing the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes (Option D)</span></strong><span>: By splitting the existing 2,000 GB gp3 volume into two 1,000 GB gp3 volumes, you can potentially distribute the IOPS load more effectively across the volumes. This approach can help increase the overall IOPS capacity and improve performance during high demand periods. Each gp3 volume can be provisioned with additional IOPS, and by using multiple volumes, you can achieve a higher aggregate IOPS limit.</span></p></li></ol><p><span>The other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>Replace the volume with a magnetic volume</span></strong><span>: Magnetic volumes (standard volumes) offer significantly lower performance compared to SSD volumes. This option would not address the performance issues and could potentially worsen the situation.</span></p><p><span>B. </span><strong><span>Increase the number of IOPS on the gp3 volume</span></strong><span>: While increasing IOPS on a gp3 volume can help, it appears that the performance degradation occurs specifically when IOPS exceed 20,000. There might be limitations or cost considerations that make this less effective than using multiple volumes.</span></p><p><span>C. </span><strong><span>Replace the volume with a Provisioned IOPS SSD (io2) volume</span></strong><span>: io2 volumes offer high performance and durability, but they are generally more expensive. If the performance issue can be resolved by splitting the gp3 volume into smaller volumes, this option may not be necessary and could incur higher costs.</span></p><p><span>By replacing the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes, the solutions architect can distribute the IOPS load more efficiently and improve the application performance during periods of high demand. This approach leverages the capabilities of gp3 volumes while addressing the identified performance bottleneck.</span></p><hr /><h3 id='question-395-identifying-iam-user-responsible-for-configuration-changes'><span>Question #395 Identifying IAM user responsible for configuration changes</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An IAM user made several configuration changes to AWS resources in their company&#39;s account during a production deployment last week. A solutions architect learned that a couple of security group rules are not configured as desired. The solutions architect wants to confirm which IAM user was responsible for making changes.</span></p><p><strong><span>Which service should the solutions architect use to find the desired information?</span></strong></p><p><span>A. Amazon GuardDuty</span></p><p><span>B. Amazon Inspector</span></p><p><span>C. AWS CloudTrail</span></p><p><span>D. AWS Config</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. AWS CloudTrail</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS CloudTrail</span></strong><span>:</span></p><ul><li><p><strong><span>Logging and Monitoring</span></strong><span>: AWS CloudTrail is a service that enables governance, compliance, and operational and risk auditing of your AWS account. It records AWS API calls for your account and delivers log files to an Amazon S3 bucket.</span></p></li><li><p><strong><span>Tracking Changes</span></strong><span>: CloudTrail logs provide detailed information about API calls, including the identity of the IAM user who made the call, the time of the call, the source IP address, and the request parameters. This makes it the ideal service to use for identifying which IAM user made specific configuration changes.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Amazon GuardDuty (Option A)</span></strong><span>: GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior to protect your AWS accounts and workloads. It does not provide detailed logs of configuration changes made by IAM users.</span></p></li><li><p><strong><span>Amazon Inspector (Option B)</span></strong><span>: Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS. It does not track configuration changes.</span></p></li><li><p><strong><span>AWS Config (Option D)</span></strong><span>: AWS Config provides a detailed view of the configuration of AWS resources in your account and how they are related. It can track changes to configurations over time but does not provide detailed information about which IAM user made the changes.</span></p></li></ul></li></ol><p><span>By using AWS CloudTrail, the solutions architect can review the log files to determine which IAM user was responsible for the configuration changes to the security group rules. CloudTrail provides the necessary information to audit and trace changes made to AWS resources.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-396-protecting-a-self-managed-dns-service-on-aws-against-ddos-attacks'><span>Question #396 Protecting a self-managed DNS service on AWS against DDoS attacks</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company has implemented a self-managed DNS service on AWS. The solution consists of the following:</span></p><ul><li><p><span>Amazon EC2 instances in different AWS Regions</span></p></li><li><p><span>Endpoints of a standard accelerator in AWS Global Accelerator</span></p></li></ul><p><span>The company wants to protect the solution against DDoS attacks. What should a solutions architect do to meet this requirement?</span></p><p><span>A. Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.</span></p><p><span>B. Subscribe to AWS Shield Advanced. Add the EC2 instances as resources to protect.</span></p><p><span>C. Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the accelerator.</span></p><p><span>D. Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the EC2 instances.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>A. Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS Shield Advanced</span></strong><span>:</span></p><ul><li><p><strong><span>DDoS Protection</span></strong><span>: AWS Shield Advanced provides enhanced DDoS protection for applications running on AWS. It offers additional protections beyond the standard AWS Shield, including advanced attack mitigation, near real-time visibility into attacks, and cost protection against scaling during attacks.</span></p></li></ul></li><li><p><strong><span>Global Accelerator</span></strong><span>:</span></p><ul><li><p><strong><span>Action A</span></strong><span>: By subscribing to AWS Shield Advanced and adding the AWS Global Accelerator as a resource to protect, the company can leverage the enhanced DDoS protection capabilities provided by Shield Advanced. This includes protection for the endpoints managed by the Global Accelerator, which in turn protects the EC2 instances behind these endpoints.</span></p></li></ul></li><li><p><strong><span>Comprehensive Protection</span></strong><span>:</span></p><ul><li><p><strong><span>Global Protection</span></strong><span>: Since the solution includes EC2 instances in different AWS Regions and endpoints of a standard accelerator in AWS Global Accelerator, protecting the accelerator ensures comprehensive protection of the entire solution. Shield Advanced will mitigate DDoS attacks targeting the accelerator endpoints, effectively protecting the underlying EC2 instances.</span></p></li></ul></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>B. </span><strong><span>Shield Advanced for EC2 Instances</span></strong><span>: While adding EC2 instances as resources to protect with AWS Shield Advanced provides protection, it does not address the protection of the accelerator endpoints, which are the primary entry points for traffic.</span></p><p><span>C. </span><strong><span>WAF Web ACL for Accelerator</span></strong><span>: Creating an AWS WAF web ACL with a rate-based rule and associating it with the accelerator can help mitigate some types of attacks, but WAF is not specifically designed for DDoS protection. It is better suited for application layer protection.</span></p><p><span>D. </span><strong><span>WAF Web ACL for EC2 Instances</span></strong><span>: Similar to option C, associating a WAF web ACL with EC2 instances provides application layer protection but does not offer comprehensive DDoS protection.</span></p><p><span>By subscribing to AWS Shield Advanced and adding the accelerator as a resource to protect, the company can ensure that the self-managed DNS service is protected against DDoS attacks, leveraging the comprehensive protection capabilities of Shield Advanced.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-397-running-a-scheduled-daily-job-to-process-sales-records'><span>Question #397 Running a scheduled daily job to process sales records</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>An ecommerce company needs to run a scheduled daily job to aggregate and filter sales records for analytics. The company stores the sales records in an Amazon S3 bucket. Each object can be up to 10 GB in size. Based on the number of sales events, the job can take up to an hour to complete. The CPU and memory usage of the job are constant and are known in advance.</span></p><p><span>A solutions architect needs to minimize the amount of operational effort that is needed for the job to run.</span></p><p><strong><span>Which solution meets these requirements?</span></strong></p><p><span>A. Create an AWS Lambda function that has an Amazon EventBridge notification. Schedule the EventBridge event to run once a day.</span></p><p><span>B. Create an AWS Lambda function. Create an Amazon API Gateway HTTP API, and integrate the API with the function. Create an Amazon EventBridge scheduled event that calls the API and invokes the function.</span></p><p><span>C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.</span></p><p><span>D. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type and an Auto Scaling group with at least one EC2 instance. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Amazon ECS with AWS Fargate</span></strong><span>:</span></p><ul><li><p><strong><span>Serverless Container Management</span></strong><span>: AWS Fargate is a serverless compute engine for containers that works with Amazon ECS. It allows you to run containers without having to manage the underlying infrastructure.</span></p></li><li><p><strong><span>Minimal Operational Effort</span></strong><span>: Using Fargate reduces the operational effort required, as there is no need to manage EC2 instances or Auto Scaling groups. Fargate automatically provisions the necessary resources to run the containers.</span></p></li><li><p><strong><span>Scheduled Tasks</span></strong><span>: By creating an EventBridge scheduled event, you can automate the execution of the ECS task to run the job daily.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>AWS Lambda (Options A and B)</span></strong><span>: Lambda functions have a maximum execution time of 15 minutes, which is not sufficient for a job that can take up to an hour to complete. Additionally, Lambda functions are not ideal for processing large files up to 10 GB in size due to memory and runtime limitations.</span></p></li><li><p><strong><span>Amazon ECS with EC2 Launch Type (Option D)</span></strong><span>: While this option can meet the requirements, it involves managing EC2 instances and Auto Scaling groups, which increases the operational effort compared to using Fargate.</span></p></li></ul></li></ol><p><span>By using Amazon ECS with the AWS Fargate launch type and scheduling the task with Amazon EventBridge, the company can run the daily job with minimal operational effort. This solution leverages serverless container management to handle the compute resources automatically, ensuring that the job runs efficiently and reliably.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><h3 id='question-398-transferring-600-tb-of-data-to-aws-within-2-weeks'><span>Question #398 Transferring 600 TB of data to AWS within 2 weeks</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A company needs to transfer 600 TB of data from its on-premises network-attached storage (NAS) system to the AWS Cloud. The data transfer must be complete within 2 weeks. The data is sensitive and must be encrypted in transit. The company&#39;s internet connection can support an upload speed of 100 Mbps. Which solution meets these requirements MOST cost-effectively?</span></p><p><span>A. Use Amazon S3 multi-part upload functionality to transfer the files over HTTPS.</span></p><p><span>B. Create a VPN connection between the on-premises NAS system and the nearest AWS Region. Transfer the data over the VPN connection.</span></p><p><span>C. Use the AWS Snow Family console to order several AWS Snowball Edge Storage Optimized devices. Use the devices to transfer the data to Amazon S3.</span></p><p><span>D. Set up a 10 Gbps AWS Direct Connect connection between the company location and the nearest AWS Region. Transfer the data over a VPN connection into the Region to store the data in Amazon S3.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Use the AWS Snow Family console to order several AWS Snowball Edge Storage Optimized devices. Use the devices to transfer the data to Amazon S3.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>Data Transfer Speed</span></strong><span>:</span></p><ul><li><p><strong><span>Internet Connection Limitation</span></strong><span>: With an upload speed of 100 Mbps, transferring 600 TB of data over the internet would take significantly longer than 2 weeks. Let&#39;s calculate the time required:</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n5967" cid="n5967" mdtype="math_block" data-math-tag-before="0" data-math-tag-after="0" data-math-labels="[]"><div class="md-rawblock-container md-math-container" tabindex="-1"><mjx-container class="MathJax" jax="SVG" display="true" style="position: relative;"><svg xmlns="http://www.w3.org/2000/svg" width="78.308ex" height="5.294ex" role="img" focusable="false" viewBox="0 -1460 34612.3 2340" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" style="vertical-align: -1.991ex;"><defs><path id="MJX-1-TEX-N-54" d="M36 443Q37 448 46 558T55 671V677H666V671Q667 666 676 556T685 443V437H645V443Q645 445 642 478T631 544T610 593Q593 614 555 625Q534 630 478 630H451H443Q417 630 414 618Q413 616 413 339V63Q420 53 439 50T528 46H558V0H545L361 3Q186 1 177 0H164V46H194Q264 46 283 49T309 63V339V550Q309 620 304 625T271 630H244H224Q154 630 119 601Q101 585 93 554T81 486T76 443V437H36V443Z"></path><path id="MJX-1-TEX-N-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path id="MJX-1-TEX-N-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-1-TEX-N-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path id="MJX-1-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-1-TEX-N-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path id="MJX-1-TEX-N-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path id="MJX-1-TEX-N-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path id="MJX-1-TEX-N-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path id="MJX-1-TEX-N-20" d=""></path><path id="MJX-1-TEX-N-44" d="M130 622Q123 629 119 631T103 634T60 637H27V683H228Q399 682 419 682T461 676Q504 667 546 641T626 573T685 470T708 336Q708 210 634 116T442 3Q429 1 228 0H27V46H60Q102 47 111 49T130 61V622ZM593 338Q593 439 571 501T493 602Q439 637 355 637H322H294Q238 637 234 628Q231 624 231 344Q231 62 232 59Q233 49 248 48T339 46H350Q456 46 515 95Q561 133 577 191T593 338Z"></path><path id="MJX-1-TEX-N-55" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q57 680 180 680Q315 680 324 683H335V637H302Q262 636 251 634T233 622L232 418V291Q232 189 240 145T280 67Q325 24 389 24Q454 24 506 64T571 183Q575 206 575 410V598Q569 608 565 613T541 627T489 637H472V683H481Q496 680 598 680T715 683H724V637H707Q634 633 622 598L621 399Q620 194 617 180Q617 179 615 171Q595 83 531 31T389 -22Q304 -22 226 33T130 192Q129 201 128 412V622Z"></path><path id="MJX-1-TEX-N-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path><path id="MJX-1-TEX-N-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path><path id="MJX-1-TEX-N-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path><path id="MJX-1-TEX-N-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path id="MJX-1-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-1-TEX-N-A0" d=""></path><path id="MJX-1-TEX-N-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path><path id="MJX-1-TEX-N-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path id="MJX-1-TEX-N-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path id="MJX-1-TEX-N-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path id="MJX-1-TEX-N-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path id="MJX-1-TEX-N-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path><path id="MJX-1-TEX-N-79" d="M69 -66Q91 -66 104 -80T118 -116Q118 -134 109 -145T91 -160Q84 -163 97 -166Q104 -168 111 -168Q131 -168 148 -159T175 -138T197 -106T213 -75T225 -43L242 0L170 183Q150 233 125 297Q101 358 96 368T80 381Q79 382 78 382Q66 385 34 385H19V431H26L46 430Q65 430 88 429T122 428Q129 428 142 428T171 429T200 430T224 430L233 431H241V385H232Q183 385 185 366L286 112Q286 113 332 227L376 341V350Q376 365 366 373T348 383T334 385H331V431H337H344Q351 431 361 431T382 430T405 429T422 429Q477 429 503 431H508V385H497Q441 380 422 345Q420 343 378 235T289 9T227 -131Q180 -204 113 -204Q69 -204 44 -177T19 -116Q19 -89 35 -78T69 -66Z"></path><path id="MJX-1-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-1-TEX-N-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path><path id="MJX-1-TEX-N-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path><path id="MJX-1-TEX-N-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path id="MJX-1-TEX-N-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path id="MJX-1-TEX-N-63" d="M370 305T349 305T313 320T297 358Q297 381 312 396Q317 401 317 402T307 404Q281 408 258 408Q209 408 178 376Q131 329 131 219Q131 137 162 90Q203 29 272 29Q313 29 338 55T374 117Q376 125 379 127T395 129H409Q415 123 415 120Q415 116 411 104T395 71T366 33T318 2T249 -11Q163 -11 99 53T34 214Q34 318 99 383T250 448T370 421T404 357Q404 334 387 320Z"></path><path id="MJX-1-TEX-N-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path id="MJX-1-TEX-N-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path id="MJX-1-TEX-N-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><use data-c="54" xlink:href="#MJX-1-TEX-N-54"></use><use data-c="69" xlink:href="#MJX-1-TEX-N-69" transform="translate(722,0)"></use><use data-c="6D" xlink:href="#MJX-1-TEX-N-6D" transform="translate(1000,0)"></use><use data-c="65" xlink:href="#MJX-1-TEX-N-65" transform="translate(1833,0)"></use></g><g data-mml-node="mo" transform="translate(2554.8,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="mfrac" transform="translate(3610.6,0)"><g data-mml-node="mtext" transform="translate(797,676)"><use data-c="54" xlink:href="#MJX-1-TEX-N-54"></use><use data-c="6F" xlink:href="#MJX-1-TEX-N-6F" transform="translate(722,0)"></use><use data-c="74" xlink:href="#MJX-1-TEX-N-74" transform="translate(1222,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(1611,0)"></use><use data-c="6C" xlink:href="#MJX-1-TEX-N-6C" transform="translate(2111,0)"></use><use data-c="20" xlink:href="#MJX-1-TEX-N-20" transform="translate(2389,0)"></use><use data-c="44" xlink:href="#MJX-1-TEX-N-44" transform="translate(2639,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(3403,0)"></use><use data-c="74" xlink:href="#MJX-1-TEX-N-74" transform="translate(3903,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(4292,0)"></use></g><g data-mml-node="mtext" transform="translate(220,-686)"><use data-c="55" xlink:href="#MJX-1-TEX-N-55"></use><use data-c="70" xlink:href="#MJX-1-TEX-N-70" transform="translate(750,0)"></use><use data-c="6C" xlink:href="#MJX-1-TEX-N-6C" transform="translate(1306,0)"></use><use data-c="6F" xlink:href="#MJX-1-TEX-N-6F" transform="translate(1584,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(2084,0)"></use><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(2584,0)"></use><use data-c="20" xlink:href="#MJX-1-TEX-N-20" transform="translate(3140,0)"></use><use data-c="53" xlink:href="#MJX-1-TEX-N-53" transform="translate(3390,0)"></use><use data-c="70" xlink:href="#MJX-1-TEX-N-70" transform="translate(3946,0)"></use><use data-c="65" xlink:href="#MJX-1-TEX-N-65" transform="translate(4502,0)"></use><use data-c="65" xlink:href="#MJX-1-TEX-N-65" transform="translate(4946,0)"></use><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(5390,0)"></use></g><rect width="6146" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(10274.3,0)"><use data-c="3D" xlink:href="#MJX-1-TEX-N-3D"></use></g><g data-mml-node="mfrac" transform="translate(11330.1,0)"><g data-mml-node="mrow" transform="translate(220,710)"><g data-mml-node="mn"><use data-c="36" xlink:href="#MJX-1-TEX-N-36"></use><use data-c="30" xlink:href="#MJX-1-TEX-N-30" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-1-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mtext" transform="translate(1500,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use><use data-c="54" xlink:href="#MJX-1-TEX-N-54" transform="translate(250,0)"></use><use data-c="42" xlink:href="#MJX-1-TEX-N-42" transform="translate(972,0)"></use></g><g data-mml-node="mo" transform="translate(3402.2,0)"><use data-c="D7" xlink:href="#MJX-1-TEX-N-D7"></use></g><g data-mml-node="mn" transform="translate(4402.4,0)"><use data-c="38" xlink:href="#MJX-1-TEX-N-38"></use></g><g data-mml-node="mtext" transform="translate(4902.4,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use><use data-c="62" xlink:href="#MJX-1-TEX-N-62" transform="translate(250,0)"></use><use data-c="69" xlink:href="#MJX-1-TEX-N-69" transform="translate(806,0)"></use><use data-c="74" xlink:href="#MJX-1-TEX-N-74" transform="translate(1084,0)"></use><use data-c="73" xlink:href="#MJX-1-TEX-N-73" transform="translate(1473,0)"></use><use data-c="2F" xlink:href="#MJX-1-TEX-N-2F" transform="translate(1867,0)"></use><use data-c="62" xlink:href="#MJX-1-TEX-N-62" transform="translate(2367,0)"></use><use data-c="79" xlink:href="#MJX-1-TEX-N-79" transform="translate(2923,0)"></use><use data-c="74" xlink:href="#MJX-1-TEX-N-74" transform="translate(3451,0)"></use><use data-c="65" xlink:href="#MJX-1-TEX-N-65" transform="translate(3840,0)"></use></g></g><g data-mml-node="mrow" transform="translate(2726.7,-686)"><g data-mml-node="mn"><use data-c="31" xlink:href="#MJX-1-TEX-N-31"></use><use data-c="30" xlink:href="#MJX-1-TEX-N-30" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-1-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mtext" transform="translate(1500,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use><use data-c="4D" xlink:href="#MJX-1-TEX-N-4D" transform="translate(250,0)"></use><use data-c="62" xlink:href="#MJX-1-TEX-N-62" transform="translate(1167,0)"></use><use data-c="70" xlink:href="#MJX-1-TEX-N-70" transform="translate(1723,0)"></use><use data-c="73" xlink:href="#MJX-1-TEX-N-73" transform="translate(2279,0)"></use></g></g><rect width="9386.4" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(21234.3,0)"><use data-c="2248" xlink:href="#MJX-1-TEX-N-2248"></use></g><g data-mml-node="mn" transform="translate(22290.1,0)"><use data-c="34" xlink:href="#MJX-1-TEX-N-34"></use><use data-c="38" xlink:href="#MJX-1-TEX-N-38" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-1-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mo" transform="translate(23790.1,0)"><use data-c="2C" xlink:href="#MJX-1-TEX-N-2C"></use></g><g data-mml-node="mn" transform="translate(24234.8,0)"><use data-c="30" xlink:href="#MJX-1-TEX-N-30"></use><use data-c="30" xlink:href="#MJX-1-TEX-N-30" transform="translate(500,0)"></use><use data-c="30" xlink:href="#MJX-1-TEX-N-30" transform="translate(1000,0)"></use></g><g data-mml-node="mtext" transform="translate(25734.8,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use><use data-c="73" xlink:href="#MJX-1-TEX-N-73" transform="translate(250,0)"></use><use data-c="65" xlink:href="#MJX-1-TEX-N-65" transform="translate(644,0)"></use><use data-c="63" xlink:href="#MJX-1-TEX-N-63" transform="translate(1088,0)"></use><use data-c="6F" xlink:href="#MJX-1-TEX-N-6F" transform="translate(1532,0)"></use><use data-c="6E" xlink:href="#MJX-1-TEX-N-6E" transform="translate(2032,0)"></use><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(2588,0)"></use><use data-c="73" xlink:href="#MJX-1-TEX-N-73" transform="translate(3144,0)"></use></g><g data-mml-node="mo" transform="translate(29550.6,0)"><use data-c="2248" xlink:href="#MJX-1-TEX-N-2248"></use></g><g data-mml-node="mn" transform="translate(30606.3,0)"><use data-c="35" xlink:href="#MJX-1-TEX-N-35"></use><use data-c="35" xlink:href="#MJX-1-TEX-N-35" transform="translate(500,0)"></use><use data-c="2E" xlink:href="#MJX-1-TEX-N-2E" transform="translate(1000,0)"></use><use data-c="36" xlink:href="#MJX-1-TEX-N-36" transform="translate(1278,0)"></use></g><g data-mml-node="mtext" transform="translate(32384.3,0)"><use data-c="A0" xlink:href="#MJX-1-TEX-N-A0"></use><use data-c="64" xlink:href="#MJX-1-TEX-N-64" transform="translate(250,0)"></use><use data-c="61" xlink:href="#MJX-1-TEX-N-61" transform="translate(806,0)"></use><use data-c="79" xlink:href="#MJX-1-TEX-N-79" transform="translate(1306,0)"></use><use data-c="73" xlink:href="#MJX-1-TEX-N-73" transform="translate(1834,0)"></use></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>Time</mtext><mo>=</mo><mfrac><mtext>Total Data</mtext><mtext>Upload Speed</mtext></mfrac><mo>=</mo><mfrac><mrow><mn>600</mn><mtext>&nbsp;TB</mtext><mo>×</mo><mn>8</mn><mtext>&nbsp;bits/byte</mtext></mrow><mrow><mn>100</mn><mtext>&nbsp;Mbps</mtext></mrow></mfrac><mo>≈</mo><mn>480</mn><mo>,</mo><mn>000</mn><mtext>&nbsp;seconds</mtext><mo>≈</mo><mn>55.6</mn><mtext>&nbsp;days</mtext></math></mjx-assistive-mml></mjx-container></div></div><p><span>This exceeds the 2-week requirement.</span></p></li></ul></li><li><p><strong><span>AWS Snowball Edge</span></strong><span>:</span></p><ul><li><p><strong><span>Action C</span></strong><span>: Using AWS Snowball Edge Storage Optimized devices is a cost-effective and efficient solution for transferring large amounts of data. Snowball Edge devices can securely transfer data to AWS by physically shipping the devices, bypassing the limitations of the internet connection.</span></p></li><li><p><strong><span>Encryption</span></strong><span>: Snowball Edge devices provide encryption in transit and at rest, ensuring the sensitive data is protected during the transfer process.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>Option A</span></strong><span>: Using Amazon S3 multi-part upload over HTTPS would be secure but not feasible within the given time frame due to the internet connection speed.</span></p></li><li><p><strong><span>Option B</span></strong><span>: Creating a VPN connection would face the same limitations as option A regarding data transfer speed.</span></p></li><li><p><strong><span>Option D</span></strong><span>: Setting up a 10 Gbps AWS Direct Connect connection would be expensive and likely not feasible within the 2-week time frame due to the time required to provision and set up the connection.</span></p></li></ul></li></ol><p><span>By using AWS Snowball Edge Storage Optimized devices, the company can securely transfer the 600 TB of data to AWS within the required 2-week period, making it the most cost-effective and practical solution.</span></p><hr /><h3 id='question-399-protecting-a-web-application-from-http-flood-attacks-with-minimal-operational-overhead'><span>Question #399 Protecting a web application from HTTP flood attacks with minimal operational overhead</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A financial company hosts a web application on AWS. The application uses an Amazon API Gateway Regional API endpoint to give users the ability to retrieve current stock prices. The company&#39;s security team has noticed an increase in the number of API requests. The security team is concerned that HTTP flood attacks might take the application offline.</span></p><p><span>A solutions architect must design a solution to protect the application from this type of attack.</span></p><p><strong><span>Which solution meets these requirements with the LEAST operational overhead?</span></strong></p><p><span>A. Create an Amazon CloudFront distribution in front of the API Gateway Regional API endpoint with a maximum TTL of 24 hours.</span></p><p><span>B. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.</span></p><p><span>C. Use Amazon CloudWatch metrics to monitor the Count metric and alert the security team when the predefined rate is reached.</span></p><p><span>D. Create an Amazon CloudFront distribution with Lambda@Edge in front of the API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>B. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>AWS WAF with Rate-Based Rule</span></strong><span>:</span></p><ul><li><p><strong><span>Rate-Based Rule</span></strong><span>: AWS WAF (Web Application Firewall) allows you to create rate-based rules, which can limit the number of requests from a single IP address over a specified period. This is effective in mitigating HTTP flood attacks.</span></p></li><li><p><strong><span>Integration with API Gateway</span></strong><span>: By associating the WAF web ACL with the API Gateway stage, you can protect the API endpoint from being overwhelmed by excessive requests.</span></p></li><li><p><strong><span>Minimal Operational Overhead</span></strong><span>: AWS WAF is a managed service that requires minimal operational effort to set up and maintain. It provides a straightforward way to implement rate limiting without the need for custom code or additional infrastructure.</span></p></li></ul></li><li><p><strong><span>Other Options</span></strong><span>:</span></p><ul><li><p><strong><span>CloudFront with TTL (Option A)</span></strong><span>: While CloudFront can help with caching and reducing the load on the API Gateway, it does not provide specific protection against HTTP flood attacks. Additionally, setting a maximum TTL of 24 hours may not be suitable for real-time stock prices.</span></p></li><li><p><strong><span>CloudWatch Metrics (Option C)</span></strong><span>: Monitoring with CloudWatch metrics can alert the security team to potential issues, but it does not provide automatic protection or mitigation against HTTP flood attacks.</span></p></li><li><p><strong><span>CloudFront with Lambda@Edge (Option D)</span></strong><span>: Using Lambda@Edge to block requests based on rate limiting involves more operational overhead compared to using AWS WAF. It requires writing and maintaining custom Lambda functions and managing the deployment of these functions at the edge locations.</span></p></li></ul></li></ol><p><span>By creating a Regional AWS WAF web ACL with a rate-based rule and associating it with the API Gateway stage, the company can effectively protect the web application from HTTP flood attacks with minimal operational overhead. This solution leverages AWS WAF&#39;s built-in capabilities to provide automated and scalable protection against excessive request rates.</span></p><p>&nbsp;</p><p>&nbsp;</p><hr /><h3 id='question-400-sending-alerts-for-new-weather-events-in-a-dynamodb-table'><span>Question #400 Sending alerts for new weather events in a DynamoDB table</span></h3><p><strong><span>Topic 1</span></strong></p><p><span>A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application. What should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?</span></p><p><span>A. Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.</span></p><p><span>B. Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.</span></p><p><span>C. Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.</span></p><p><span>D. Add a custom attribute to each record to flag new items. Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe.</span></p><hr /><p><strong><span>Answer:</span></strong></p><p><span>C. Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.</span></p><hr /><p><strong><span>Explanation:</span></strong></p><ol start='' ><li><p><strong><span>DynamoDB Streams</span></strong><span>:</span></p><ul><li><p><strong><span>Action C</span></strong><span>: Enabling DynamoDB Streams on the table allows capturing changes to the table, such as inserts, updates, and deletes. By using DynamoDB Streams, the company can set up triggers (AWS Lambda functions) that process these changes without affecting the performance of the current application.</span></p></li><li><p><strong><span>SNS Integration</span></strong><span>: The Lambda function can be configured to publish messages to a single Amazon SNS topic whenever a new weather event is recorded. The internal teams can then subscribe to this SNS topic to receive alerts.</span></p></li></ul></li><li><p><strong><span>Operational Overhead</span></strong><span>:</span></p><ul><li><p><strong><span>Minimal Overhead</span></strong><span>: Using DynamoDB Streams with Lambda and SNS requires minimal operational overhead. The solution leverages managed services (DynamoDB Streams, AWS Lambda, and SNS) that automatically handle scaling, monitoring, and maintenance.</span></p></li></ul></li></ol><p><span>Other options have the following drawbacks:</span></p><p><span>A. </span><strong><span>DynamoDB Transactions</span></strong><span>: Using DynamoDB transactions to notify internal teams is not a typical use case for transactions. Transactions are designed for atomic operations on multiple items but not for triggering notifications.</span></p><p><span>B. </span><strong><span>Current Application Publishing to SNS</span></strong><span>: Having the current application publish messages to multiple SNS topics could potentially affect the performance of the application. Additionally, managing multiple SNS topics adds complexity.</span></p><p><span>D. </span><strong><span>Cron Job and Custom Attribute</span></strong><span>: Adding a custom attribute and using a cron job to scan the table every minute introduces additional operational overhead and latency. Scanning the table frequently can also impact the performance and cost.</span></p><p><span>By enabling DynamoDB Streams and using Lambda triggers to publish to an SNS topic, the company can efficiently send alerts to internal teams with minimal impact on the current application&#39;s performance and minimal operational overhead.</span></p><p>&nbsp;</p><hr /><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><hr /><p>&nbsp;</p></div></div>
</body>
</html>